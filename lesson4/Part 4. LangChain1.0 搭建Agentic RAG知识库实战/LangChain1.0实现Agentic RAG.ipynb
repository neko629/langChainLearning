{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>LangChain 1.0 搭建Agentic RAG应用实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第一阶段、Native RAG基础流程介绍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、RAG基础概念\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**RAG** = **R**etrieval（检索） + **A**ugmented（增强） + **G**eneration（生成）\n",
    "\n",
    "&emsp;&emsp;RAG即检索增强生成，为LLM提供了从某些数据源检索到的信息，并基于此修正生成的答案。RAG 基本上是Search + LLM 提示，可以通过大模型回答查询，并将搜索所找到的信息作为大模型的上下文。查询和检索到的上下文都会被注入到发送到 LLM 的提示语中。\n",
    "\n",
    "&emsp;&emsp;一个简单完整的RAG系统如下图：用户进行了提问，提出的问题会先去知识库里进行检索答案，检索到相似度最高的前n个答案，然后和用户的提问一起放入到Prompt里，交给大语言模型，大语言模型根据用户的提问和给出检索的知识来进行整理总结，最终输出返回给用户结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251209201456231.png\" width=\"750\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、通用RAG基本工作流程（两阶段过程）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **阶段一：准备阶段（建立知识库）**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这个过程就像是为一个庞大的图书馆建立一本详尽的电子目录。首先，将原始文档（如PDF、网页）拆分成易于管理的知识片段。接着，通过大模型（Embedding模型）的“嵌入”能力，为每一段文字生成一个具有语义的“数字指纹”。最后，将这些“数字指纹”与其对应的原始文本一起，存入一个专门的向量数据库中。至此，杂乱无章的资料就变成了一个结构化的、可通过语义进行高效查询的知识库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **数据接入**：收集各种文档（PDF、Word、网页等）\n",
    "\n",
    "2. **文档解析**：提取文本内容\n",
    "\n",
    "3. **文档分割**：将长文档切分成小片段\n",
    "\n",
    "4. **向量化**：将文本转换为数学向量\n",
    "\n",
    "5. **存储**：将向量存入专门的数据库\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251209202826761.png\" width=\"850\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **阶段二：问答阶段（智能应答）**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当用户提出问题时，系统便开始工作。首先，它会用同样的技术将用户的问题也转换成一个“数字指纹”。然后，将这个指纹在之前建好的向量数据库中进行快速比对，找出语义上最相关、最匹配的若干知识片段（计算语义相似度）。最后，大模型将这些检索到的可靠知识作为“参考依据”，结合自己的通用能力，组织生成一个准确且详实的回答，从而有效避免了“凭空编造”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **用户提问**：输入问题\n",
    "\n",
    "2. **问题向量化**：将问题也转换成向量\n",
    "\n",
    "3. **相似度检索**：在向量数据库中寻找最相关的文档片段\n",
    "\n",
    "4. **构建增强提示**：将检索到的文档+原始问题组合成新的提示\n",
    "\n",
    "5. **生成答案**：大语言模型基于增强后的提示生成最终答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251209203037588.png\" width=\"850\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、企业RAG核心应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 企业知识库与智能问答\n",
    "\n",
    "**场景描述**：\n",
    "\n",
    "企业拥有大量内部文档（员工手册、产品文档、技术规范、会议纪要等），员工需要快速找到准确信息。\n",
    "\n",
    "**实际案例**：\n",
    "\n",
    "+ 新员工入职培训问答（新员工培训成本高）\n",
    "\n",
    "+ 产品技术规格查询（文档分散在不同系统中）\n",
    "\n",
    "+ 公司政策咨询（搜索效率低，关键词匹配不精准）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 专业客服与技术支持\n",
    "\n",
    "**场景描述**：\n",
    "为客户提供准确、一致的技术支持和问题解答。\n",
    "\n",
    "**RAG优势**：\n",
    "\n",
    "+ 基于最新产品文档和解决方案库（依赖客服人员的记忆）\n",
    "\n",
    "+ 提供标准化的准确回答（回答不一致，依赖个人经验）\n",
    "\n",
    "+ 减少培训时间，提高效率（处理复杂问题时响应慢）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想系统学习RAG基础知识的话，可以看【大模型RAG入门】课程内容学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第二阶段、LangChain框架搭建RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 环境准备与依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:33:00.365028Z",
     "start_time": "2025-12-09T12:33:00.241538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:33:18.486021Z",
     "start_time": "2025-12-09T12:33:17.997920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                                1.0.7\n",
      "langchain-chroma                         1.0.0\n",
      "langchain-classic                        1.0.0\n",
      "langchain-community                      0.4.1\n",
      "langchain-core                           1.0.5\n",
      "langchain-deepseek                       1.0.1\n",
      "langchain-experimental                   0.4.0\n",
      "langchain-mcp-adapters                   0.1.14\n",
      "langchain-openai                         1.0.3\n",
      "langchain-tavily                         0.2.13\n",
      "langchain-text-splitters                 1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:36:44.075016Z",
     "start_time": "2025-12-09T12:36:42.466933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型加载成功\n"
     ]
    }
   ],
   "source": [
    "## 加载模型\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载.env环境变量\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 使用 DeepSeek 模型（避免 OpenAI 地区限制问题）\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\", temperature=0)\n",
    "\n",
    "# 使用本地嵌入模型（不需要 API 调用）\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "print(\"✅ 模型加载成功\")\n",
    "# print(model.invoke(\"Hello, world!\"))\n",
    "# print(embeddings.embed_query(\"Hello, world!\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、文档加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:56:13.232013Z",
     "start_time": "2025-12-09T12:56:13.228948Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain框架介绍\n",
      "\n",
      "LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用。\n",
      "\n",
      "主要特性：\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain采用模块化架构，包含多个核心组件：\n",
      "- Models：支持各种LLM模型的集成\n",
      "- Prompts：提示词模板管理\n",
      "- Chains：将多个组件链接在一起\n",
      "- Agents：智能代理，能够使用工具完成任务\n",
      "- Memory：对话历史和上下文管理\n",
      "\n",
      "2. RAG技术\n",
      "检索增强生成（RAG）是LangChain的核心功能之一。RAG通过以下步骤工作：\n",
      "- 文档加载：从各种来源加载文档\n",
      "- 文档分割：将长文档切分成小块\n",
      "- 向量化：将文本转换为向量嵌入\n",
      "- 向量存储：存储到向量数据库中\n",
      "- 检索：根据查询找到相关文档\n",
      "- 生成：LLM基于检索内容生成答案\n",
      "\n",
      "3. 支持的模型\n",
      "LangChain支持多种LLM提供商：\n",
      "- OpenAI（GPT-3.5、GPT-4）\n",
      "- Anthropic（Claude）\n",
      "- Google（PaLM）\n",
      "- 开源模型（LLaMA、Mistral等）\n",
      "\n",
      "4. 应用场景\n",
      "LangChain可用于构建：\n",
      "- 问答系统\n",
      "- 聊天机器人\n",
      "- 文档分析工具\n",
      "- 代码助手\n",
      "- 数据分析助手\n",
      "\n",
      "5. 版本更新\n",
      "LangChain 1.0版本带来了重大改进：\n",
      "- 更稳定的API接口\n",
      "- 更好的性能优化\n",
      "- 增强的错误处理\n",
      "- 改进的文档和示例\n",
      "\n",
      "使用建议：\n",
      "- 合理设置chunk_size和chunk_overlap参数\n",
      "- 选择合适的嵌入模型\n",
      "- 根据应用场景调整检索参数\n",
      "- 使用合适的提示词模板\n",
      "\n",
      "LangChain是构建AI应用的理想选择，它简化了复杂的开发流程，让开发者能够专注于业务逻辑而不是底层实现细节。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 2.文档加载\n",
    "from langchain_community.document_loaders import TextLoader, Docx2txtLoader\n",
    "\n",
    "# 读取基础数据文档\n",
    "loader = TextLoader(\"../sample_document.txt\", encoding= \"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 读取敏感数据文档\n",
    "sensitive_loader = TextLoader(\"../sensitive_document.txt\", encoding= \"utf-8\")\n",
    "sensitive_documents = sensitive_loader.load()\n",
    "\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、文档切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:58:36.876508Z",
     "start_time": "2025-12-09T12:58:36.873215Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割后的文本块数量: 2\n",
      "LangChain框架介绍\n",
      "\n",
      "LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用。\n",
      "\n",
      "主要特性：\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain采用模块化架构，包含多个核心组件：\n",
      "- Models：支持各种LLM模型的集成\n",
      "- Prompts：提示词模板管理\n",
      "- Chains：将多个组件链接在一起\n",
      "- Agents：智能代理，能够使用工具完成任务\n",
      "- Memory：对话历史和上下文管理\n",
      "\n",
      "2. RAG技术\n",
      "检索增强生成（RAG）是LangChain的核心功能之一。RAG通过以下步骤工作：\n",
      "- 文档加载：从各种来源加载文档\n",
      "- 文档分割：将长文档切分成小块\n",
      "- 向量化：将文本转换为向量嵌入\n",
      "- 向量存储：存储到向量数据库中\n",
      "- 检索：根据查询找到相关文档\n",
      "- 生成：LLM基于检索内容生成答案\n"
     ]
    }
   ],
   "source": [
    "## 3.文档切分\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 定义文档切分器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,                      # 切分文本块大小\n",
    "    chunk_overlap=50,                    # 文本块重叠大小\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]   # 按照换行符、空格等符号进行切分\n",
    ")\n",
    "\n",
    "# 基础数据文档切分\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# 敏感数据文档切分\n",
    "sensitive_texts = text_splitter.split_documents(sensitive_documents)\n",
    "\n",
    "print(f\"分割后的文本块数量: {len(texts)}\")\n",
    "print(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、文档向量存储与检索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:00:26.621859Z",
     "start_time": "2025-12-09T13:00:25.936741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: rank_bm25 in /root/miniconda3/envs/langchain/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: faiss-cpu in /root/miniconda3/envs/langchain/lib/python3.11/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/langchain/lib/python3.11/site-packages (from rank_bm25) (2.3.5)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/langchain/lib/python3.11/site-packages (from faiss-cpu) (25.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25 faiss-cpu # 或 faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 创建向量存储（Faiss向量数据库）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:25:17.295272Z",
     "start_time": "2025-12-09T13:25:14.163486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 普通数据向量数据库创建并保存成功\n",
      "✅ 敏感数据向量数据库创建并保存成功\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# ================================1.普通数据入库=================================\n",
    "# 创建并保存向量数据库，用于普通数据的检索\n",
    "vector_store = FAISS.from_documents(texts, embeddings)\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "# 从本地加载向量数据库\n",
    "vector_store = FAISS.load_local(\n",
    "    \"faiss_index\",                        # 本地索引文件路径名称\n",
    "    embeddings,                           # 嵌入模型\n",
    "    allow_dangerous_deserialization=True  # 必须要加这个参数，否则会报错，允许反序列化\n",
    ")\n",
    "print(\"✅ 普通数据向量数据库创建并保存成功\")\n",
    "\n",
    "# =================================2.敏感数据入库=================================\n",
    "\n",
    "# 创建并保存向量数据库，用于敏感数据的检索\n",
    "sensitive_vector_store = FAISS.from_documents(sensitive_texts, embeddings)\n",
    "sensitive_vector_store.save_local(\"sensitive_faiss_index\")\n",
    "\n",
    "# 从本地加载向量数据库\n",
    "sensitive_vector_store = FAISS.load_local(\n",
    "    \"sensitive_faiss_index\",                # 本地索引文件路径名称\n",
    "    embeddings,                             # 嵌入模型\n",
    "    allow_dangerous_deserialization=True    # 必须要加这个参数，否则会报错，允许反序列化\n",
    ")\n",
    "print(\"✅ 敏感数据向量数据库创建并保存成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 加载并创建检索器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:27:59.869521Z",
     "start_time": "2025-12-09T13:27:59.865362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 普通数据检索器建立成功\n",
      "✅ 敏感数据检索器建立成功\n"
     ]
    }
   ],
   "source": [
    "# 定义BM25Retriever，是一种基于关键词匹配的检索器\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "# 定义EnsembleRetriever，是一种将多个检索器组合起来的检索器\n",
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "\n",
    "# ================================1.普通数据入库=================================\n",
    "\n",
    "# 1.创建BM25检索器\n",
    "bm25_retriever = BM25Retriever.from_documents(texts)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# 2.创建向量数据库检索器\n",
    "faiss_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",    # 相似度搜索\n",
    "    search_kwargs={\"k\": 3}       # 返回top3结果\n",
    ")\n",
    "\n",
    "# 3.创建混合检索器\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[faiss_retriever, bm25_retriever],  # 组合faiss和bm25检索器\n",
    "    weights=[0.5, 0.5]                             # 给faiss和bm25检索器设置权重，分别为0.5\n",
    ")\n",
    "print(\"✅ 普通数据检索器建立成功\")\n",
    "\n",
    "# =================================2.敏感数据入库=================================\n",
    "\n",
    "# 1.创建BM25检索器\n",
    "sensitive_bm25_retriever = BM25Retriever.from_documents(sensitive_texts)\n",
    "sensitive_bm25_retriever.k = 3\n",
    "\n",
    "# 2.创建向量数据库检索器\n",
    "sensitive_faiss_retriever = sensitive_vector_store.as_retriever(\n",
    "    search_type=\"similarity\",    # 相似度搜索\n",
    "    search_kwargs={\"k\":3}       # 返回top3结果\n",
    ")\n",
    "\n",
    "# 3.创建混合检索器\n",
    "sensitive_ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[sensitive_faiss_retriever, sensitive_bm25_retriever], # 组合faiss和bm25检索器\n",
    "    weights=[0.5, 0.5]                   # 给faiss和bm25检索器设置权重，分别为0.5\n",
    ")\n",
    "print(\"✅ 敏感数据检索器建立成功\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、 基础RAG链构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:29:43.372876Z",
     "start_time": "2025-12-09T13:29:35.383852Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/langchain/lib/python3.11/site-packages/pydantic/v1/main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容：LangChain框架介绍\n",
      "\n",
      "LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用。\n",
      "\n",
      "主要特性：\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain采用模块化架构，包含多个核心组件：\n",
      "- Models：支持各种LLM模型的集成\n",
      "- Prompts：提示词模板管理\n",
      "- Chains：将多个组件链接在一起\n",
      "- Agents：智能代理，能够使用工具完成任务\n",
      "- Memory：对话历史和上下文管理\n",
      "\n",
      "2. RAG技术\n",
      "检索增强生成（RAG）是LangChain的核心功能之一。RAG通过以下步骤工作：\n",
      "- 文档加载：从各种来源加载文档\n",
      "- 文档分割：将长文档切分成小块\n",
      "- 向量化：将文本转换为向量嵌入\n",
      "- 向量存储：存储到向量数据库中\n",
      "- 检索：根据查询找到相关文档\n",
      "- 生成：LLM基于检索内容生成答案\n",
      "\n",
      "3. 支持的模型\n",
      "LangChain支持多种LLM提供商：\n",
      "- OpenAI（GPT-3.5、GPT-4）\n",
      "- Anthropic（Claude）\n",
      "- Google（PaLM）\n",
      "- 开源模型（LLaMA、Mistral等）\n",
      "\n",
      "4. 应用场景\n",
      "LangChain可用于构建：\n",
      "- 问答系统\n",
      "- 聊天机器人\n",
      "- 文档分析工具\n",
      "- 代码助手\n",
      "- 数据分析助手\n",
      "\n",
      "5. 版本更新\n",
      "LangChain 1.0版本带来了重大改进：\n",
      "- 更稳定的API接口\n",
      "- 更好的性能优化\n",
      "- 增强的错误处理\n",
      "- 改进的文档和示例\n",
      "\n",
      "使用建议：\n",
      "- 合理设置chunk_size和chunk_overlap参数\n",
      "- 选择合适的嵌入模型\n",
      "- 根据应用场景调整检索参数\n",
      "- 使用合适的提示词模板\n",
      "\n",
      "LangChain是构建AI应用的理想选择，它简化了复杂的开发流程，让开发者能够专注于业务逻辑而不是底层实现细节。\n",
      "============================================================\n",
      "大模型回复内容：LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用，例如问答系统、聊天机器人、文档分析工具等。其主要特性包括模块化设计（包含Models、Prompts、Chains、Agents、Memory等核心组件）、支持检索增强生成（RAG）技术、集成多种LLM模型（如OpenAI、Anthropic、Google及开源模型），并持续更新优化（如1.0版本改进了API稳定性和性能）。\n"
     ]
    }
   ],
   "source": [
    "# 导入提示词ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 导入 RunnablePassthrough，用于将输入传递给下一个组件\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# 导入 StrOutputParser，用于将模型输出解析为字符串\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1.格式化文档的辅助函数\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 2.创建提示模板\n",
    "template = \"\"\"你是一个专业的问答助手。请根据以下提供的上下文信息来回答用户的问题。\n",
    "如果上下文中没有相关信息，请诚实地告诉用户你不知道，不要编造答案。\n",
    "\n",
    "上下文信息：\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\n",
    "回答:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 3.创建检索链,文本检索阶段，用于将文本检索结果格式化为字符串\n",
    "chain =  ensemble_retriever | format_docs\n",
    "\n",
    "# 调用检索链，执行文本检索\n",
    "retrieval = chain.invoke(\"LangChain是什么？\")\n",
    "print(f\"检索到的内容：{retrieval}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 4.创建大模型回答检索链，大模型生成阶段\n",
    "retrieval_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 调用大模型回答检索链，执行大模型生成\n",
    "content = retrieval_chain.invoke(\"LangChain是什么？\")\n",
    "print(f\"大模型回复内容：{content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第三阶段、Agentic RAG概述介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一. Agentic RAG 是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**Agentic RAG（代理增强检索生成）** 它突破了传统 RAG 的\"单次检索+生成\"模式，将**检索过程完全代理化（Agent-based）**，使 LLM 能够自主规划、迭代优化检索策略，并在多轮交互中动态调整知识获取方式。是 LangChain 1.0 引入的**下一代检索增强生成范式**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;是一种将**Agent（智能体）的推理能力**引入RAG流程的架构。它不再只是简单地执行“检索 -> 生成”的固定流水线，而是让一个由LLM驱动的智能体拥有**自主权**，能够根据问题的复杂程度，动态决定：\n",
    "\n",
    "- 是否需要检索？\n",
    "\n",
    "- 去哪里检索（内部知识库、互联网、API）？\n",
    "\n",
    "- 检索到的内容是否足够回答问题？\n",
    "\n",
    "- 如果不足，是否需要修改查询词重新检索？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**核心定义**：Agentic RAG 通过将检索工具（Search、Database Query、API 调用）作为智能体的\"感知-行动\"循环的一部分，使 LLM 具备**主动发现、评估、迭代和综合**知识的能力，而非被动接收检索结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251209213807766.png\" width=\"850\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**应用场景分析**："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种Agentic架构适用于需要动态决策的复杂场景：\n",
    "\n",
    "- **技术支持系统**：根据用户问题的复杂度，自动决定是直接回答还是检索知识库\n",
    "\n",
    "- **智能客服**：处理多步骤的客户请求，如\"查询订单→验证身份→处理退款\"\n",
    "\n",
    "- **研究助手**：对于开放性研究问题，自动规划信息检索和分析步骤\n",
    "\n",
    "- **数据分析**：结合SQL查询工具、可视化工具和解释工具，自动完成数据分析任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 解决了什么问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Agentic RAG 主要解决传统 RAG 的五大核心痛点："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* 强制表格居中、自动换行并适应单元格宽度 */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* 允许表格根据内容收缩 */\n",
    "    max-width: 100%; /* 防止表格溢出单元格 */\n",
    "    table-layout: fixed; /* 固定布局算法，对长文本换行至关重要 */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* 允许自动换行 */\n",
    "    word-wrap: break-word; /* 对长单词或URL进行强制换行 */\n",
    "    text-align: left; /* 默认内容左对齐 */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* 表头文本居中 */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| **传统 RAG 痛点** | **Agentic RAG 解决方案** | **改善指标** |\n",
    "| :---: | :---: | :---: |\n",
    "| **检索与生成脱节** | 检索作为 Agent 的主动行为，与推理深度整合 | 回答准确率 ↑ 35-50% |\n",
    "| **单次检索局限性** | 多轮检索、迭代优化、查询重构能力 | 复杂问题覆盖率 ↑ 80% |\n",
    "| **缺乏置信度评估** | Agent 自主评估检索结果质量，决定是否需要补充检索 | 幻觉率 ↓ 60% |\n",
    "| **静态知识库限制** | 动态工具调用 + 多源知识融合（数据库+API+文档） | 知识时效性 ↑ 100% |\n",
    "| **无法进行逻辑推理** | ReAct 框架下检索与推理交替进行 | 多跳推理能力 ↑ 3倍 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**典型案例验证**\n",
    "\n",
    "&emsp;&emsp; \"传统 RAG 在处理\"2023年诺贝尔经济学奖得主的主要理论如何影响中国数字经济政策？\"这类问题时，仅能检索到零散信息，而 Agentic RAG 通过 3 轮检索（诺贝尔奖官网→中国经济政策数据库→学术影响分析）和 2 轮推理，将回答准确率从 42% 提升至 91%。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**角色定位**\n",
    "\n",
    "&emsp;&emsp;在整个Agent系统中，Agentic RAG不仅是**大脑（Router/Planner）与工具（Retriever）的结合体**。它处于**决策层**，负责协调“知识”与“推理”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、 与普通 RAG 的关系和区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 核心区别对比表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* 强制表格居中、自动换行并适应单元格宽度 */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* 允许表格根据内容收缩 */\n",
    "    max-width: 100%; /* 防止表格溢出单元格 */\n",
    "    table-layout: fixed; /* 固定布局算法，对长文本换行至关重要 */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* 允许自动换行 */\n",
    "    word-wrap: break-word; /* 对长单词或URL进行强制换行 */\n",
    "    text-align: left; /* 默认内容左对齐 */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* 表头文本居中 */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| **维度** | **普通 RAG** | **Agentic RAG** | **架构差异** |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **检索范式** | 单次检索，检索与生成线性分离 | 多轮迭代检索，检索与生成深度耦合 | **被动 → 主动** |\n",
    "| **决策主体** | 检索器独立决策，LLM 被动接收 | LLM 作为 Agent 主动规划检索策略 | **分离 → 统一** |\n",
    "| **知识整合** | 检索结果直接拼接生成 | Agent 评估、筛选、综合多源知识 | **简单拼接 → 智能综合** |\n",
    "| **推理能力** | 依赖 Prompt 工程，无法多跳推理 | 支持 ReAct 推理链，检索-推理交替 | **单步 → 多跳** |\n",
    "| **工具使用** | 仅限于向量数据库检索 | 支持多样化工具（API、DB、Web Search） | **单一 → 多元** |\n",
    "| **状态管理** | 无状态，每次检索独立 | 基于 AgentState 的有状态迭代 | **无状态 → 有状态** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**LangChain 术语体系验证**："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp; \"在 LangChain 1.0 中，普通 RAG 是 `RetrievalQA` 链，而 Agentic RAG 是 `Agent` 与 `ToolRetriever` 的结合，前者是 Chain 模式，后者是 Agent 模式。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;相比于传统的线性RAG，Agentic RAG是**从“静态检索”到“动态推理”的范式转变**，是目前构建生产级复杂问答系统的最佳实践。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关键区别点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **主动规划能力**：Agentic RAG 中 LLM 会生成\"检索计划\"，如：\"首先搜索X，如果结果不足则搜索Y，最后调用API验证\"\n",
    "\n",
    "2. **置信度评估**：Agent 会评估检索结果的 `recall_score` 和 `precision_score`，决定是否需要补充检索\n",
    "\n",
    "3. **工具链整合**：可组合多个检索工具（Vector DB + Web Search + Database Query）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第三阶段、检索Retrieval逻辑封装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 Tool与Middleware的区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在 LangChain 1.0 的 Agent 体系中，「Tool」与「Middleware」虽然都可扩展 Agent 的能力，但它们适用的场景完全不同，当我们需要对一些业务逻辑进行扩展和封装时，那么就需要判断是封装在Tool工具里还是封装在Middleware中间件里。判断标准核心在于：\n",
    "是否需要让 LLM 通过决策（reasoning → act）来显式调用这段逻辑？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* 强制表格居中、自动换行并适应单元格宽度 */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* 允许表格根据内容收缩 */\n",
    "    max-width: 100%; /* 防止表格溢出单元格 */\n",
    "    table-layout: fixed; /* 固定布局算法，对长文本换行至关重要 */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* 允许自动换行 */\n",
    "    word-wrap: break-word; /* 对长单词或URL进行强制换行 */\n",
    "    text-align: left; /* 默认内容左对齐 */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* 表头文本居中 */\n",
    "}\n",
    "</style>\n",
    "\n",
    "|    维度    | **Tool（工具）** | **Middleware（中间件）** |\n",
    "|:--------:| :---: | :---: |\n",
    "| **作用对象** | 封装**具体业务功能**（RAG检索、API调用） | 封装**执行流程控制**（日志、重试、限流） |\n",
    "| **调用方式** | 由**LLM自主决策**调用（通过function calling） | 在Agent执行**固定节点自动触发**（before/after模型调用） |\n",
    "| **设计目的** | 扩展Agent的**能力边界** | 增强Agent的**可靠性、安全性、可观测性** |\n",
    "| **状态访问** | 接收参数，返回结果 | 可直接读写**AgentState**，控制执行流（如jump_to=\"end\"） |\n",
    "| **执行概率** | 0% ~ 100% (不确定) | 100% (确定) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请在设计功能判断封装场景时，问自己以下三个问题：\n",
    "1. 谁来决定“做不做”？(Who decides?)\n",
    "* 需要 LLM 根据上下文判断是否执行\n",
    "→\n",
    " Tool\n",
    "    * 例子：搜索互联网、查询天气、计算器。因为用户可能只是打招呼，不需要搜索。\n",
    "* 业务流程规定必须执行\n",
    "→\n",
    " Middleware / Node\n",
    "    * 例子：权限校验、敏感词过滤、日志记录、固定的知识库召回（如客服系统）。\n",
    "2. 参数从哪里来？(Where do args come from?)\n",
    "* 参数需要从用户的自然语言中提取\n",
    "→\n",
    " Tool\n",
    "    * 例子：用户说“帮我查下特斯拉的股价”，Tool 需要提取“特斯拉”作为参数。\n",
    "* 参数是系统上下文或环境变量\n",
    "→\n",
    " Middleware / Node\n",
    "    * 例子：用户的 UserID、当前的 SessionID、数据库连接配置。这些不需要 LLM 去“猜”。\n",
    "3. 失败了怎么办？(Error Handling)\n",
    "* 失败了需要 LLM 换个方式重试\n",
    "→\n",
    " Tool\n",
    "    * 例子：搜索不到结果，LLM 可以尝试换个关键词再次调用 Tool。\n",
    "* 失败了直接抛异常或走系统降级\n",
    "→\n",
    " Middleware / Node\n",
    "    * 例子：数据库连接断开、API 鉴权失败。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;所以在Agentic RAG中，我们需要将检索逻辑封装在Tool工具里，而不是封装在Middleware中间件里。这样做的原因是，检索逻辑是一种需要显式调用的业务逻辑，而不是一种需要在每个请求中都执行的中间件逻辑。而Middleware中间件更多地关注于在请求处理过程中的一些通用操作，如日志记录、性能监控等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 将RAG封装为Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;将RAG检索功能封装为Tool是构建Agentic RAG系统的关键步骤。这个过程的本质是将原本独立的RAG链转换为Agent可以理解和调用的标准化工具。下面我们详细分析这个过程的逻辑和实现细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**封装逻辑说明**：\n",
    "\n",
    "1. **功能抽象**：将复杂的RAG检索逻辑抽象为一个简单的函数接口`rag_search(query: str) -> str`。这个函数接收用户查询作为输入，返回检索结果作为输出，屏蔽了内部文档加载、向量检索、答案生成等复杂细节。\n",
    "\n",
    "2. **标准化描述**：通过Tool的`description`参数提供详细的功能说明。这个描述至关重要，因为它直接决定了LLM是否能正确理解Tool的用途并在合适的场景下调用它。一个好的Tool描述应该包含：\n",
    "\n",
    "  - Tool的核心功能\n",
    "\n",
    "  - 适用的查询类型\n",
    "\n",
    "  - 返回结果的格式\n",
    "\n",
    "  - 使用限制和注意事项\n",
    "\n",
    "3. **命名规范**：Tool的`name`应该具有明确的业务含义，使用小写字母和下划线，便于LLM理解和调用。例如`internal_knowledge_base`比`rag_tool_1`更具描述性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义网络搜索工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T16:57:17.640257Z",
     "start_time": "2025-12-09T16:57:15.524058Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '介绍一下LangChain这个框架',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://docs.feishu.cn/v/wiki/HnPWwsFruihI0tkvz9HcG3G8nrc/a1',\n",
       "   'title': 'LangChain：让LLM更强大的开源框架 - 飞书文档',\n",
       "   'content': '**LangChain **是一个开源的框架，它可以让AI开发人员把像GPT-4这样的大型语言模型（LLM）和外部数据结合起来。它提供了**Python **或**JavaScript（TypeScript） **的包。 你',\n",
       "   'score': 0.99998915,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://python.langchain.com.cn/docs/get_started/introduction',\n",
       "   'title': 'LangChain 介绍',\n",
       "   'content': '# LangChain 介绍 **LangChain** 是一个用于开发由语言模型驱动的应用程序的框架。它使得应用程序能够： * **LangChain 库**：Python 和 JavaScript 库。包含了各种组件的接口和集成，一个基本的运行时，用于将这些组件组合成链和代理，以及现成的链和代理的实现。 * **LangChain 模板**：一系列易于部署的参考架构，用于各种任务。 * **LangServe**：一个用于将 LangChain 链部署为 REST API 的库。 * **LangSmith**：一个开发者平台，让你可以调试、测试、评估和监控基于任何 LLM 框架构建的链，并且与 LangChain 无缝集成。 * **开发**：在 LangChain/LangChain.js 中编写你的应用程序。使用模板作为参考，快速开始。 * **生产化**：使用 LangSmith 来检查、测试和监控你的链，这样你可以不断改进并有信心地部署。 * **部署**：使用 LangServe 将任何链转换为 API。 ## LangChain 库\\u200b LangChain 包的主要价值主张是： 1. **组件**：用于处理语言模型的可组合工具和集成。无论你是否使用 LangChain 框架的其余部分，组件都是模块化的，易于使用 LangChain 库本身由几个不同的包组成。 * **`langchain-core`**：基础抽象和 LangChain 表达式语言。 * **`langchain-community`**：第三方集成。 * **`langchain`**：构成应用程序认知架构的链、代理和检索策略。 我们建议你按照我们的 快速入门 指南，通过构建你的第一个 LangChain 应用程序来熟悉框架。 阅读我们的 安全 最佳实践，确保你在安全地使用 LangChain 进行开发。 这些文档主要关注 Python LangChain 库。点击这里 查看 JavaScript LangChain 库的文档。 ## LangChain 表达式语言 (LCEL)\\u200b\") * **概述**：LCEL 及其优点 * **接口**：LCEL 对象的标准接口 * **如何**：LCEL 的关键特性 LangChain 为以下模块提供了标准的、可扩展的接口和集成： LangChain 是一个丰富的工具生态系统的一部分，这些工具与我们的框架集成，并在其基础上构建。查看我们不断增长的 集成 列表。 使用 LangChain 的最佳实践。 ### API 参考\\u200b 前往参考部分，查看 LangChain 和 LangChain Experimental Python 包中所有类和方法的完整文档。 * LangChain 库 * LangChain 表达式语言 (LCEL) + 集成 + API 参考',\n",
       "   'score': 0.9999856,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.83,\n",
       " 'request_id': '2407344b-8f0a-400e-997e-6664644b5524'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# 定义网络搜索工具tool，默认name为tavily_search\n",
    "web_search = TavilySearch(max_results=2)\n",
    "\n",
    "web_search.invoke(\"介绍一下LangChain这个框架\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义基础数据知识库工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:01:51.424879Z",
     "start_time": "2025-12-09T17:01:48.926721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain框架介绍\n",
      "\n",
      "LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用。\n",
      "\n",
      "主要特性：\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain采用模块化架构，包含多个核心组件：\n",
      "- Models：支持各种LLM模型的集成\n",
      "- Prompts：提示词模板管理\n",
      "- Chains：将多个组件链接在一起\n",
      "- Agents：智能代理，能够使用工具完成任务\n",
      "- Memory：对话历史和上下文管理\n",
      "\n",
      "2. RAG技术\n",
      "检索增强生成（RAG）是LangChain的核心功能之一。RAG通过以下步骤工作：\n",
      "- 文档加载：从各种来源加载文档\n",
      "- 文档分割：将长文档切分成小块\n",
      "- 向量化：将文本转换为向量嵌入\n",
      "- 向量存储：存储到向量数据库中\n",
      "- 检索：根据查询找到相关文档\n",
      "- 生成：LLM基于检索内容生成答案\n",
      "\n",
      "3. 支持的模型\n",
      "LangChain支持多种LLM提供商：\n",
      "- OpenAI（GPT-3.5、GPT-4）\n",
      "- Anthropic（Claude）\n",
      "- Google（PaLM）\n",
      "- 开源模型（LLaMA、Mistral等）\n",
      "\n",
      "4. 应用场景\n",
      "LangChain可用于构建：\n",
      "- 问答系统\n",
      "- 聊天机器人\n",
      "- 文档分析工具\n",
      "- 代码助手\n",
      "- 数据分析助手\n",
      "\n",
      "5. 版本更新\n",
      "LangChain 1.0版本带来了重大改进：\n",
      "- 更稳定的API接口\n",
      "- 更好的性能优化\n",
      "- 增强的错误处理\n",
      "- 改进的文档和示例\n",
      "\n",
      "使用建议：\n",
      "- 合理设置chunk_size和chunk_overlap参数\n",
      "- 选择合适的嵌入模型\n",
      "- 根据应用场景调整检索参数\n",
      "- 使用合适的提示词模板\n",
      "\n",
      "LangChain是构建AI应用的理想选择，它简化了复杂的开发流程，让开发者能够专注于业务逻辑而不是底层实现细节。\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "# 定义工具输入参数\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "# 定义工具输入参数\n",
    "class QAWithRetrievalArgs(BaseModel):\n",
    "    query: str = Field(description=\"用户的问题\")\n",
    "\n",
    "def query_retrieval_knowledge(query: str) -> str:\n",
    "    \"\"\"\n",
    "    一个基于LangChain知识库检索的问答工具。\n",
    "    专门用于回答与 LangChain 相关的技术问题。\n",
    "\n",
    "    ⚠️ 重要：此工具仅适用于 LangChain 相关问题！\n",
    "    如果问题与 LangChain 无关，请使用网络搜索工具。\n",
    "    \"\"\"\n",
    "    # 定义 LangChain 相关关键词\n",
    "    langchain_keywords = [\n",
    "        'langchain', 'langgraph', 'langsmith', 'lcel',\n",
    "        'chain', 'agent', 'retriever', 'embedding', 'vector',\n",
    "        'rag', 'prompt', 'llm', 'chatmodel', 'runnable',\n",
    "        '链', '代理', '检索器', '向量', '提示词', '模型'\n",
    "    ]\n",
    "\n",
    "    # 检查查询是否包含 LangChain 相关关键词\n",
    "    query_lower = query.lower()\n",
    "    is_langchain_related = any(keyword in query_lower for keyword in langchain_keywords)\n",
    "\n",
    "    # 如果查询与 LangChain 无关，返回提示\n",
    "    if not is_langchain_related:\n",
    "        return (\n",
    "            \"❌ 检测到此问题与 LangChain 知识库无关。\\n\"\n",
    "            \"建议：请使用网络搜索工具 (tavily_search_results_json) 来查找答案。\\n\"\n",
    "            f\"原始问题：{query}\"\n",
    "        )\n",
    "\n",
    "    # 如果相关，则进行检索，返回检索文档内容\n",
    "    retrieval_chain = ensemble_retriever | format_docs\n",
    "    docs = retrieval_chain.invoke(query)\n",
    "\n",
    "    # 检查检索结果质量\n",
    "    if not docs or len(docs.strip()) < 50:\n",
    "        return (\n",
    "            f\"⚠️ 知识库中未找到关于 '{query}' 的充分信息。\\n\"\n",
    "            \"建议：可以尝试使用网络搜索工具获取更多信息。\"\n",
    "        )\n",
    "\n",
    "    return docs\n",
    "\n",
    "# 定义工具StructuredTool\n",
    "qa_tool = StructuredTool.from_function(\n",
    "    func=query_retrieval_knowledge,        # 工具函数\n",
    "    name=\"query_retrieval_knowledge\",      # 工具名称\n",
    "    description=(\n",
    "        \"🎯 专用于回答 LangChain 技术相关问题的知识库检索工具。\\n\"\n",
    "        \"适用范围：LangChain、LangGraph、LangSmith、LCEL、Agent、RAG、Retriever、Embedding、Prompt 等相关技术。\\n\"\n",
    "        \"⚠️ 限制：仅包含 LangChain 相关文档，不适用于其他领域问题（如烹饪、历史、科学等）。\\n\"\n",
    "        \"如果问题与 LangChain 无关，请使用网络搜索工具 tavily_search_results_json。\"\n",
    "    ),                                      # 工具描述\n",
    "    args_schema=QAWithRetrievalArgs,        # 工具输入参数\n",
    "    return_direct=False                     # 是否直接返回工具输出，而不是作为消息内容\n",
    ")\n",
    "\n",
    "result = qa_tool.invoke(\"LangChain这个框架是什么？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 定义敏感数据知识库工具\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:05:17.998067Z",
     "start_time": "2025-12-09T17:05:15.770325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 [高风险操作] 敏感知识库 RAG 检索\n",
      "   数据类别: confidential\n",
      "   查询内容: 查询一下2024年Q4财务报告数据\n",
      "   正在检索敏感知识库...\n",
      "🔴 机密级 检索结果\n",
      "======================================================================\n",
      "\n",
      "📋 检索到的敏感信息：\n",
      "\n",
      "三、运营岗位薪资\n",
      "- 运营专员：10K-15K\n",
      "- 运营经理：15K-25K\n",
      "- 高级运营经理：25K-35K\n",
      "- 运营总监：35K-50K\n",
      "\n",
      "四、薪酬福利\n",
      "- 五险一金：按国家标准缴纳\n",
      "- 年终奖：2-6个月薪资（根据绩效）\n",
      "- 股权激励：核心员工可获得期权\n",
      "- 其他福利：\n",
      "  * 带薪年假：10-20天\n",
      "  * 节日福利：每年5000元\n",
      "  * 健康体检：每年一次\n",
      "  * 团建活动：每季度一次\n",
      "\n",
      "五、绩效考核\n",
      "- 考核周期：季度考核 + 年度考核\n",
      "- 考核等级：S（10%）、A（20%）、B（60%）、C（10%）\n",
      "- 晋升机制：连续两次A或一次S可申请晋升\n",
      "- 淘汰机制：连续两次C将被淘汰\n",
      "\n",
      "====================\n",
      "\n",
      "【敏感】用户数据分析报告\n",
      "====================\n",
      "报告类型：用户行为分析\n",
      "密级：敏感\n",
      "统计周期：2024年全年\n",
      "\n",
      "一、用户规模\n",
      "- 注册用户总数：50万\n",
      "- 活跃用户数：30万（月活）\n",
      "- 付费用户数：4万\n",
      "- 付费转化率：8%\n",
      "\n",
      "【机密】2024年Q4财务报告\n",
      "====================\n",
      "报告日期：2024年12月31日\n",
      "报告类型：季度财务报告\n",
      "密级：机密\n",
      "编制部门：财务部\n",
      "\n",
      "一、营收数据\n",
      "- 总营收：5000万元人民币\n",
      "- 同比增长：25%\n",
      "- 环比增长：15%\n",
      "- 主要收入来源：软件服务占60%，咨询服务占30%，其他占10%\n",
      "\n",
      "二、利润数据\n",
      "- 净利润：1200万元\n",
      "- 毛利润：2250万元\n",
      "- 毛利率：45%\n",
      "- 净利率：24%\n",
      "- 营业利润率：28%\n",
      "\n",
      "三、现金流数据\n",
      "- 经营性现金流：800万元\n",
      "- 投资性现金流：-300万元（主要用于设备采购和研发投入）\n",
      "- 筹资性现金流：200万元\n",
      "- 期末现金余额：1500万元\n",
      "\n",
      "四、重要客户分析\n",
      "- A公司：年度合同额1500万元，占总营收30%，合作3年，续约率100%\n",
      "- B公司：年度合同额1000万元，占总营收20%，新客户，增长潜力大\n",
      "- C公司：年度合同额800万元，占总营收16%，合同即将到期需重点维护\n",
      "- 其他客户：合计1700万元，占总营收34%\n",
      "\n",
      "====================\n",
      "\n",
      "二、并购与投资计划\n",
      "1. C公司收购谈判\n",
      "   - 目标估值：5000万元\n",
      "   - 谈判进度：尽职调查阶段\n",
      "   - 预计完成时间：2025年Q2\n",
      "   - 收购理由：技术互补，客户资源整合\n",
      "   - 风险评估：中等风险，需关注技术团队稳定性\n",
      "\n",
      "2. D公司战略投资\n",
      "   - 投资金额：1000万元\n",
      "   - 持股比例：20%\n",
      "   - 投资目的：布局上游供应链\n",
      "\n",
      "三、组织优化计划\n",
      "1. 人力成本优化\n",
      "   - 优化比例：20%\n",
      "   - 涉及部门：运营部（优化30人）、市场部（优化20人）\n",
      "   - 预计节省：800万元/年\n",
      "   - 实施时间：Q1完成\n",
      "   - 补偿方案：N+2补偿标准\n",
      "\n",
      "2. 组织架构调整\n",
      "   - 新设AI事业部\n",
      "   - 合并市场部和销售部\n",
      "   - 强化研发中心\n",
      "\n",
      "====================\n",
      "\n",
      "【机密】客户关系管理数据\n",
      "====================\n",
      "数据类型：VIP客户档案\n",
      "密级：机密\n",
      "更新日期：2024年12月\n",
      "\n",
      "二、用户画像\n",
      "- 年龄分布：\n",
      "  * 18-25岁：20%\n",
      "  * 25-35岁：60%\n",
      "  * 35-45岁：15%\n",
      "  * 45岁以上：5%\n",
      "\n",
      "- 地域分布：\n",
      "  * 一线城市：70%（北上广深）\n",
      "  * 二线城市：20%\n",
      "  * 其他城市：10%\n",
      "\n",
      "- 职业分布：\n",
      "  * 互联网从业者：40%\n",
      "  * 金融从业者：25%\n",
      "  * 企业管理者：20%\n",
      "  * 其他：15%\n",
      "\n",
      "三、用户行为\n",
      "- 平均使用时长：45分钟/天\n",
      "- 平均访问频次：3次/天\n",
      "- 核心功能使用率：\n",
      "  * 数据分析：85%\n",
      "  * 报表生成：70%\n",
      "  * 协作功能：60%\n",
      "\n",
      "四、用户留存\n",
      "- 次日留存率：65%\n",
      "- 7日留存率：45%\n",
      "- 30日留存率：30%\n",
      "- 流失原因分析：\n",
      "  * 功能不满足需求：40%\n",
      "  * 价格因素：30%\n",
      "  * 竞品吸引：20%\n",
      "  * 其他：10%\n",
      "\n",
      "五、用户价值\n",
      "- ARPU（平均每用户收入）：1250元/年\n",
      "- LTV（用户生命周期价值）：3750元\n",
      "- CAC（用户获取成本）：800元\n",
      "- LTV/CAC比率：4.7（健康水平）\n",
      "\n",
      "======================================================================\n",
      "\n",
      "⚠️ 安全警告：\n",
      "- 以上为🔴 机密级信息，请妥善保管，不得外泄！\n",
      "- 访问已记录，将用于安全审计\n",
      "- 如需分享，请确保接收方具有相应权限\n",
      "- 查询时间：2025-12-11 15:47:43\n"
     ]
    }
   ],
   "source": [
    "# 定义高风险知识库敏感数据查询工具\n",
    "class SensitiveKnowledgeQueryArgs(BaseModel):\n",
    "    query: str = Field(description=\"查询的敏感主题或关键词\")\n",
    "    data_category: str = Field(\n",
    "        description=\"数据类别：confidential(机密), internal(内部), sensitive(敏感)\",\n",
    "        default=\"confidential\"\n",
    "    )\n",
    "\n",
    "def query_sensitive_knowledge(query: str, data_category: str = \"confidential\") -> str:\n",
    "    \"\"\"\n",
    "    ⚠️ 高风险操作：基于 RAG 的敏感知识库检索\n",
    "\n",
    "    使用向量检索 + BM25 混合检索敏感文档。\n",
    "    包含机密文档、内部资料、敏感信息等。\n",
    "\n",
    "    风险等级：🔴 高风险\n",
    "    - 访问机密文档和敏感信息\n",
    "    - 可能涉及商业机密、个人隐私\n",
    "    - 需要权限验证和人工审核批准\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔴 [高风险操作] 敏感知识库 RAG 检索\")\n",
    "    print(f\"   数据类别: {data_category}\")\n",
    "    print(f\"   查询内容: {query}\")\n",
    "\n",
    "    # 1.定义敏感数据类别标签\n",
    "    sensitive_categories = {\n",
    "        \"confidential\": \"🔴 机密级\",\n",
    "        \"internal\": \"🟡 内部级\",\n",
    "        \"sensitive\": \"🟠 敏感级\"\n",
    "    }\n",
    "\n",
    "    # 2.获取类别标签\n",
    "    category_label = sensitive_categories.get(data_category, \"未知级别\")\n",
    "\n",
    "    # 3.使用敏感数据混合检索器进行 RAG 检索\n",
    "    print(f\"   正在检索敏感知识库...\")\n",
    "    retrieval_chain = sensitive_ensemble_retriever | format_docs\n",
    "    docs = retrieval_chain.invoke(query)\n",
    "\n",
    "    # 检查检索结果质量\n",
    "    if not docs or len(docs.strip()) < 50:\n",
    "        return (\n",
    "            f\"⚠️ 敏感知识库中未找到关于 '{query}' 的相关信息。\\n\"\n",
    "            f\"数据类别：{category_label}\\n\"\n",
    "            f\"提示：请确认查询关键词是否准确，或尝试使用不同的关键词。\\n\"\n",
    "            f\"可查询的类别：机密(confidential)、内部(internal)、敏感(sensitive)\"\n",
    "        )\n",
    "\n",
    "    # 根据数据类别过滤结果（可选：基于文档内容中的密级标记）\n",
    "    # 这里简单处理，返回所有检索结果\n",
    "\n",
    "    # 格式化输出\n",
    "    output = f\"{category_label} 检索结果\\n\"\n",
    "    output += \"=\"*70 + \"\\n\\n\"\n",
    "    output += \"📋 检索到的敏感信息：\\n\\n\"\n",
    "    output += docs\n",
    "    output += \"\\n\\n\" + \"=\"*70\n",
    "    output += f\"\\n\\n⚠️ 安全警告：\\n\"\n",
    "    output += f\"- 以上为{category_label}信息，请妥善保管，不得外泄！\\n\"\n",
    "    output += f\"- 访问已记录，将用于安全审计\\n\"\n",
    "    output += f\"- 如需分享，请确保接收方具有相应权限\\n\"\n",
    "    output += f\"- 查询时间：{__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# 定义工具StructuredTool.from_function\n",
    "sensitive_knowledge_tool = StructuredTool.from_function(\n",
    "    func=query_sensitive_knowledge,         # 工具函数\n",
    "    name=\"query_sensitive_knowledge\",       # 工具名称\n",
    "    description=(\n",
    "        \"🔴 高风险操作：敏感知识库查询工具\\n\"\n",
    "        \"用于查询知识库中的机密文档、内部资料、敏感信息等受限数据。\\n\"\n",
    "        \"⚠️ 警告：此操作需要人工审核批准！\\n\"\n",
    "        \"适用场景：\\n\"\n",
    "        \"- 查询财务数据、战略规划等机密信息\\n\"\n",
    "        \"- 访问技术文档、人事信息等内部资料\\n\"\n",
    "        \"- 获取用户数据、客户信息等敏感数据\\n\"\n",
    "        \"安全提示：仅在必要时使用，确保有相应权限。\"\n",
    "    ),                                      # 工具描述\n",
    "    args_schema=SensitiveKnowledgeQueryArgs,        # 工具输入参数\n",
    "    return_direct=False                     # 是否直接返回工具输出，而不是作为消息内容\n",
    ")\n",
    "\n",
    "result = sensitive_knowledge_tool.invoke(\"查询一下2024年Q4财务报告数据\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:05:50.982859Z",
     "start_time": "2025-12-09T17:05:50.980833Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义工具列表，将工具添加到列表中\n",
    "tools = [qa_tool, web_search, sensitive_knowledge_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Agent执行工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:12:22.459474Z",
     "start_time": "2025-12-09T17:12:02.384312Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 [AI 决策]: 调用工具 -> query_retrieval_knowledge\n",
      "   参数: {'query': 'LangChain支持哪些模型'}\n",
      "\n",
      "💬 [AI 回复]:\n",
      "根据查询结果，LangChain支持多种LLM提供商和模型。让我为您详细介绍一下：\n",
      "\n",
      "## LangChain支持的模型类型\n",
      "\n",
      "### 1. **主要LLM提供商**\n",
      "- **OpenAI**：GPT-3.5、GPT-4系列模型\n",
      "- **Anthropic**：Claude系列模型\n",
      "- **Google**：PaLM、Gemini系列模型\n",
      "- **开源模型**：LLaMA、Mistral、Falcon等\n",
      "\n",
      "### 2. **模型集成方式**\n",
      "LangChain通过统一的接口支持这些模型，使得开发者可以轻松切换不同的模型提供商，而无需重写大量代码。\n",
      "\n",
      "### 3. **具体模型类别**\n",
      "\n",
      "#### **聊天模型（Chat Models）**\n",
      "- OpenAI的ChatGPT系列\n",
      "- Anthropic的Claude系列\n",
      "- Google的Gemini系列\n",
      "- 开源的聊天优化模型\n",
      "\n",
      "#### **文本生成模型（LLMs）**\n",
      "- 传统的文本补全模型\n",
      "- 代码生成模型\n",
      "- 翻译模型\n",
      "\n",
      "#### **嵌入模型（Embedding Models）**\n",
      "- OpenAI的text-embedding-ada-002\n",
      "- 开源的sentence-transformers\n",
      "- 其他向量化模型\n",
      "\n",
      "### 4. **模型调用方式**\n",
      "LangChain提供了标准化的调用接口：\n",
      "```python\n",
      "# 示例代码\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "\n",
      "# 使用OpenAI模型\n",
      "llm = OpenAI(model_name=\"gpt-3.5-turbo\")\n",
      "chat_model = ChatOpenAI(model_name=\"gpt-4\")\n",
      "```\n",
      "\n",
      "### 5. **模型配置选项**\n",
      "- **温度（Temperature）**：控制生成文本的随机性\n",
      "- **最大令牌数（Max Tokens）**：限制生成文本的长度\n",
      "- **停止序列（Stop Sequences）**：定义生成停止的条件\n",
      "- **频率惩罚（Frequency Penalty）**：减少重复内容\n",
      "\n",
      "### 6. **本地模型支持**\n",
      "LangChain还支持在本地运行的模型：\n",
      "- 通过Hugging Face集成\n",
      "- 使用Ollama等本地推理服务器\n",
      "- 自定义模型包装器\n",
      "\n",
      "### 7. **多模型协同**\n",
      "LangChain支持在一个应用中同时使用多个模型，例如：\n",
      "- 使用一个模型进行检索\n",
      "- 使用另一个模型进行生成\n",
      "- 使用专门的模型进行特定任务\n",
      "\n",
      "### 8. **模型缓存**\n",
      "为了提高性能和降低成本，LangChain支持：\n",
      "- 内存缓存\n",
      "- Redis缓存\n",
      "- SQLite缓存\n",
      "\n",
      "**建议**：选择模型时需要考虑以下因素：\n",
      "1. 任务类型（聊天、代码生成、文档分析等）\n",
      "2. 性能要求\n",
      "3. 成本预算\n",
      "4. 隐私和安全需求\n",
      "5. 部署环境（云端或本地）\n",
      "\n",
      "您是否有特定的应用场景或对某个模型提供商更感兴趣？我可以为您提供更详细的信息。\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# 创建并运行 Agent\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "# 创建线程ID\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread-final\"}}\n",
    "\n",
    "# 创建Agent\n",
    "agent = create_agent(\n",
    "    tools=tools,                  # 工具列表\n",
    "    model=model,                  # 模型\n",
    "    debug=False,                  # 是否开启调试模式，开启后会打印详细信息\n",
    "    checkpointer=InMemorySaver(),  # 检查点保存器，用于保存和恢复Agent状态\n",
    "    context_schema=Context       # 上下文模式，定义了Agent在运行时的上下文信息\n",
    ")\n",
    "\n",
    "# 执行Agent，使用流式输出模式\n",
    "for event in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"LangChain支持哪些模型？\"}]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\",\n",
    "        context={\"user_role\": \"大模型工程师\"}\n",
    "    ):\n",
    "        if \"messages\" in event:\n",
    "            last_msg = event[\"messages\"][-1]\n",
    "            if last_msg.type == \"ai\":\n",
    "                if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                    tool_call = last_msg.tool_calls[0]\n",
    "                    print(f\"🤖 [AI 决策]: 调用工具 -> {tool_call['name']}\")\n",
    "                    print(f\"   参数: {tool_call.get('args', {})}\")\n",
    "                elif last_msg.content:\n",
    "                    print(f\"\\n💬 [AI 回复]:\\n{last_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 询问复杂问题，需要多个工具协作完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:16:18.245532Z",
     "start_time": "2025-12-09T17:15:03.704115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 [AI 决策]: 调用工具 -> query_retrieval_knowledge\n",
      "   参数: {'query': 'RAG和Agentic RAG的区别 使用场景'}\n",
      "🤖 [AI 决策]: 调用工具 -> tavily_search\n",
      "   参数: {'query': 'Agentic RAG vs RAG difference comparison use cases'}\n",
      "🤖 [AI 决策]: 调用工具 -> tavily_search\n",
      "   参数: {'query': '什么是Agentic RAG 与传统RAG的区别 架构特点'}\n",
      "🤖 [AI 决策]: 调用工具 -> tavily_search\n",
      "   参数: {'query': 'Agentic RAG use cases scenarios 应用场景 推荐'}\n",
      "\n",
      "💬 [AI 回复]:\n",
      "基于我获取的信息，我来为您详细比较RAG和Agentic RAG的区别，并推荐使用场景：\n",
      "\n",
      "## RAG vs Agentic RAG 详细对比\n",
      "\n",
      "### **传统RAG（检索增强生成）**\n",
      "\n",
      "**核心特点：**\n",
      "1. **线性流程**：检索 → 生成，一次性完成\n",
      "2. **静态检索**：基于单一查询进行检索\n",
      "3. **简单拼接**：将检索结果与问题简单拼接后生成答案\n",
      "4. **被动执行**：LLM作为生成器，没有决策能力\n",
      "\n",
      "**工作流程：**\n",
      "```\n",
      "用户查询 → 向量检索 → 获取相关文档 → 拼接提示词 → LLM生成答案\n",
      "```\n",
      "\n",
      "### **Agentic RAG（代理式RAG）**\n",
      "\n",
      "**核心特点：**\n",
      "1. **循环迭代**：支持多轮检索和生成\n",
      "2. **智能决策**：引入智能体（Agent）进行决策\n",
      "3. **动态调整**：根据反馈调整检索策略\n",
      "4. **工具使用**：能够使用各种工具完成任务\n",
      "5. **自主推理**：具备推理和规划能力\n",
      "\n",
      "**工作流程：**\n",
      "```\n",
      "用户查询 → 智能体分析 → 查询重写/分解 → 工具选择 → 检索执行 → \n",
      "结果评估 → 是否需要进一步检索？ → 是：继续循环 → 否：生成最终答案\n",
      "```\n",
      "\n",
      "## **主要区别对比表**\n",
      "\n",
      "| **特性** | **传统RAG** | **Agentic RAG** |\n",
      "|---------|------------|----------------|\n",
      "| **架构设计** | 线性、单向流程 | 循环、多轮交互 |\n",
      "| **决策能力** | 无自主决策 | 智能体自主决策 |\n",
      "| **查询处理** | 单一查询 | 查询重写、分解、优化 |\n",
      "| **检索策略** | 静态、一次性 | 动态、多轮、自适应 |\n",
      "| **工具使用** | 不支持 | 支持多种工具调用 |\n",
      "| **复杂度** | 相对简单 | 系统复杂度高 |\n",
      "| **灵活性** | 有限 | 高度灵活 |\n",
      "| **适用场景** | 简单问答 | 复杂任务处理 |\n",
      "\n",
      "## **推荐使用场景**\n",
      "\n",
      "### **传统RAG适用场景：**\n",
      "\n",
      "1. **简单问答系统**\n",
      "   - 客服机器人\n",
      "   - 知识库问答\n",
      "   - 文档查询系统\n",
      "\n",
      "2. **信息检索应用**\n",
      "   - 企业内部文档搜索\n",
      "   - 产品说明书查询\n",
      "   - 技术支持文档检索\n",
      "\n",
      "3. **基础内容生成**\n",
      "   - 基于文档的摘要生成\n",
      "   - 简单的报告撰写\n",
      "   - 标准化的内容生成\n",
      "\n",
      "4. **资源受限环境**\n",
      "   - 计算资源有限\n",
      "   - 响应时间要求高\n",
      "   - 部署和维护成本敏感\n",
      "\n",
      "### **Agentic RAG适用场景：**\n",
      "\n",
      "1. **复杂推理任务**\n",
      "   - 多步骤问题解决\n",
      "   - 需要逻辑推理的查询\n",
      "   - 跨文档信息整合\n",
      "\n",
      "2. **动态决策应用**\n",
      "   - 智能数据分析助手\n",
      "   - 业务决策支持系统\n",
      "   - 风险评估和预测\n",
      "\n",
      "3. **多工具协同工作**\n",
      "   - 代码生成和调试\n",
      "   - 数据分析和可视化\n",
      "   - 自动化工作流程\n",
      "\n",
      "4. **交互式学习系统**\n",
      "   - 个性化教育助手\n",
      "   - 技能培训系统\n",
      "   - 研究辅助工具\n",
      "\n",
      "5. **企业级复杂应用**\n",
      "   - 生成式BI（商业智能）\n",
      "   - 研发辅助提效\n",
      "   - 复杂业务流程自动化\n",
      "\n",
      "## **选择建议**\n",
      "\n",
      "### **选择传统RAG的情况：**\n",
      "- 任务相对简单直接\n",
      "- 查询模式相对固定\n",
      "- 对响应速度要求高\n",
      "- 部署和维护资源有限\n",
      "- 不需要复杂的推理和决策\n",
      "\n",
      "### **选择Agentic RAG的情况：**\n",
      "- 任务需要多步骤推理\n",
      "- 查询复杂且多变\n",
      "- 需要整合多个数据源\n",
      "- 需要动态调整检索策略\n",
      "- 系统需要自主决策能力\n",
      "- 预算充足，可以接受更高的复杂度\n",
      "\n",
      "## **发展趋势**\n",
      "\n",
      "随着AI应用的日益复杂，**Agentic RAG代表了RAG技术发展的必然趋势**。它将LLM从简单的\"生成器\"提升为能够自主思考、规划和执行的\"智能体\"，从而构建出更强大、更可靠、更接近人类智能的知识型AI系统。\n",
      "\n",
      "在实际应用中，可以根据具体需求灵活选择，甚至可以将两者结合使用，在简单任务中使用传统RAG，在复杂任务中切换到Agentic RAG模式。\n"
     ]
    }
   ],
   "source": [
    "# 执行Agent，使用流式输出模式\n",
    "for event in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"比较RAG和Agentic RAG的区别，并推荐使用场景\"}]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\",\n",
    "        context={\"user_role\": \"大模型工程师\"}\n",
    "    ):\n",
    "        if \"messages\" in event:\n",
    "            last_msg = event[\"messages\"][-1]\n",
    "            if last_msg.type == \"ai\":\n",
    "                if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                    tool_call = last_msg.tool_calls[0]\n",
    "                    print(f\"🤖 [AI 决策]: 调用工具 -> {tool_call['name']}\")\n",
    "                    print(f\"   参数: {tool_call.get('args', {})}\")\n",
    "                elif last_msg.content:\n",
    "                    print(f\"\\n💬 [AI 回复]:\\n{last_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当Agent执行时，我们可以观察到以下效果：\n",
    "\n",
    "1. **智能路由**：对于\"LangChain支持哪些模型？\"这类知识性问题，Agent会自动选择`query_retrieval_knowledge`工具\n",
    "\n",
    "2. **多工具协作**：对于复杂问题如\"比较RAG和Agentic RAG的区别，并推荐使用场景\"，Agent可能会：\n",
    "\n",
    "  - 首先调用知识库工具获取技术细节\n",
    "\n",
    "  - 然后基于检索到的信息进行分析和推理，是否符合预期，是否需要调用其他工具\n",
    "\n",
    "  - 所有检索到的信息都符合预期，最后给出综合性的回答和建议\n",
    "\n",
    "3. **错误处理**：如果Tool调用失败（如知识库中无相关内容），Agent会根据错误信息调整策略，可能尝试重新表述查询或告知用户限制\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第四阶段、构建Agentic RAG系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 Agentic RAG系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangChain 1.0引入了强大的中间件系统，允许在Agent执行的关键节点插入自定义逻辑。在创建Agentic RAG系统是将Tool与LLM智能体结合的核心环节。这个过程涉及提示词工程、Agent创建和执行器中间件配置三个关键步骤，每个步骤都对最终系统的表现有重要影响。在实现Agentic RAG系统时，需要注意以下几个方面：\n",
    "\n",
    "* 提示词工程：精心设计的提示词能够引导LLM生成符合预期的输出。在Agentic RAG系统中，提示词应包含必要的上下文信息，以便LLM能够理解用户意图并生成相关内容。\n",
    "\n",
    "* Agent创建：使用LangChain 1.0的Agent类创建智能体。在创建时，需要指定LLM模型、工具列表和中间件配置。\n",
    "\n",
    "* 执行器中间件配置：在执行器中配置中间件，以便在Agent执行过程中插入自定义逻辑。例如，在RAG系统中，中间件可以用于检索相关文档、生成上下文信息等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 定义中间件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本次实验将实现一个基于LangChain 1.0的Agentic RAG系统，该系统能够根据用户输入的问题，从知识库中检索相关信息，并使用LLM生成符合预期的回答。一共加入了以下几个组件：\n",
    "\n",
    "* 知识库：用于存储和检索相关信息的文档集合。\n",
    "\n",
    "* LLM模型：用于生成文本回答的语言模型。\n",
    "\n",
    "* 智能体（Agent）：负责接收用户输入、调用工具（如检索知识库）、执行LLM生成回答的组件。\n",
    "\n",
    "* 中间件（Middleware）：在智能体执行过程中插入自定义逻辑的组件，用于处理输入、输出、错误等情况。\n",
    "\n",
    "    * before_model(SummarizationMiddleware上下文压缩)：在LLM模型调用之前执行的中间件，用于压缩上下文信息，减少输入 tokens 数量。\n",
    "\n",
    "    * wrap_tool_model(ToolRetryMiddleware工具自动重试)：在调用工具（如知识库检索）时执行的中间件，用于自动重试工具调用，直到成功或达到最大重试次数。\n",
    "    \n",
    "    * after_model（ToolLoggingMiddleware 日志记录）：在LLM模型调用之后执行的中间件，用于记录模型输出和调用信息，方便调试和分析。\n",
    "\n",
    "    * after_model（ToolCallLimitMiddleware 工具调用次数限制）：在LLM模型调用之后执行的中间件，用于限制工具调用次数，防止无限循环调用。\n",
    "\n",
    "    * after_model（HumanInTheLoopMiddleware 人工干预）：在LLM模型调用之后执行的中间件，用于人工干预模型输出，如检查回答是否符合预期、修正错误等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 上下文压缩中间件（before_model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 核心作用：在上下文信息中压缩和提取关键信息，减少输入 tokens 数量，提高模型生成效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:22:31.792012Z",
     "start_time": "2025-12-09T17:22:31.752994Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "# 定义摘要中间件\n",
    "summarization_middleware = SummarizationMiddleware(\n",
    "    model=ChatDeepSeek(model=\"deepseek-chat\", temperature=0.1),    # 摘要模型\n",
    "    max_tokens_before_summary=500,      # 触发摘要的最大 tokens 数量\n",
    "    messages_to_keep=3,                 # 保留的对话历史消息数量\n",
    "    summary_prompt=\"请将以下对话历史进行摘要，保留关键决策点和技术细节：\\n\\n{messages}\\n\\n摘要:\"  # 摘要提示\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 自动工具重试中间件（wrap_tool_call）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 核心作用：当调用工具失败或者出错时，可以自动重试调用，直到达到最大重试次数或者成功为止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:23:16.280454Z",
     "start_time": "2025-12-09T17:23:16.277953Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ToolRetryMiddleware\n",
    "\n",
    "# 定义重试中间件\n",
    "retry_middleware = ToolRetryMiddleware(\n",
    "    max_retries=3,    # 最大重试次数\n",
    "    tools=[\"query_retrieval_knowledge\", \"tavily_search_results_json\",\"query_sensitive_knowledge\"],  # 要重试的工具列表\n",
    "    retry_on=(ConnectionError, RuntimeError),              # 要重试的异常类型\n",
    "    on_failure=\"return_message\",                           # 失败时的处理方式，这里是返回失败信息\n",
    "    backoff_factor=1.5                                     # 重试间隔因子，每次重试间隔会增加这个因子倍\n",
    ")"
   ]
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%%sql\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool 调用日志中间件（after_model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 核心作用：对Tool工具调用时收集调用信息，如调用次数、调用参数、调用结果等日志信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:20:09.602118Z",
     "start_time": "2025-12-09T17:20:09.591161Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tool 调用日志中间件\n",
    "\n",
    "功能：\n",
    "1. 记录所有工具调用的详细信息\n",
    "2. 性能统计和分析\n",
    "3. JSON 文件持久化\n",
    "4. 异常检测和告警\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Callable\n",
    "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse,   AgentState\n",
    "\n",
    "class ToolCallLogger:\n",
    "    \"\"\"工具调用日志记录器\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir: str = \"LangChain_AgenticRAG/logs\"):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.current_session_logs: List[Dict[str, Any]] = []\n",
    "        self.session_start_time = datetime.now()\n",
    "        self.tool_call_times: Dict[str, float] = {}  # 记录工具调用开始时间\n",
    "\n",
    "        # Token 使用统计\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "        self.total_tokens = 0\n",
    "        self.cache_hit_tokens = 0\n",
    "\n",
    "    def get_log_file_path(self) -> Path:\n",
    "        \"\"\"获取当前日志文件路径\"\"\"\n",
    "        date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "        return self.log_dir / f\"tool_calls_{date_str}.json\"\n",
    "\n",
    "    def log_tool_call(\n",
    "        self,\n",
    "        tool_name: str,\n",
    "        tool_input: Any,\n",
    "        tool_output: Any,\n",
    "        success: bool,\n",
    "        error: Optional[str] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        token_usage: int = 0,\n",
    "    ):\n",
    "        \"\"\"记录单次工具调用\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"tool_name\": tool_name,\n",
    "            \"input\": str(tool_input)[:500],  # 限制长度\n",
    "            \"output\": str(tool_output)[:1000] if success else None,\n",
    "            \"success\": success,\n",
    "            \"error\": error,\n",
    "            \"metadata\": metadata or {},\n",
    "            \"token_usage\": token_usage,\n",
    "        }\n",
    "\n",
    "        self.current_session_logs.append(log_entry)\n",
    "\n",
    "        # 实时写入文件\n",
    "        self._append_to_file(log_entry)\n",
    "\n",
    "        # 打印日志\n",
    "        status = \"✅\" if success else \"❌\"\n",
    "        if not success and error:\n",
    "            print(f\"   Error: {error}\")\n",
    "\n",
    "    def accumulate_tokens(\n",
    "        self,\n",
    "        input_tokens: int,\n",
    "        output_tokens: int,\n",
    "        total_tokens: int,\n",
    "        cache_hit: int = 0\n",
    "    ):\n",
    "        \"\"\"累计 token 使用量\"\"\"\n",
    "        self.total_input_tokens += input_tokens\n",
    "        self.total_output_tokens += output_tokens\n",
    "        self.total_tokens += total_tokens\n",
    "        self.cache_hit_tokens += cache_hit\n",
    "\n",
    "        print(f\"📊 [Token Usage] 输入: {input_tokens}, 输出: {output_tokens}, 总计: {total_tokens}\")\n",
    "        if cache_hit > 0:\n",
    "            print(f\"   缓存命中: {cache_hit} tokens\")\n",
    "\n",
    "    def _append_to_file(self, log_entry: Dict[str, Any]):\n",
    "        \"\"\"追加日志到文件\"\"\"\n",
    "        log_file = self.get_log_file_path()\n",
    "\n",
    "        # 读取现有日志\n",
    "        if log_file.exists():\n",
    "            with open(log_file, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    logs = json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    logs = []\n",
    "        else:\n",
    "            logs = []\n",
    "\n",
    "        # 添加新日志\n",
    "        logs.append(log_entry)\n",
    "\n",
    "        # 写回文件\n",
    "        with open(log_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(logs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"获取统计信息\"\"\"\n",
    "        if not self.current_session_logs:\n",
    "            return {\"message\": \"No logs yet\"}\n",
    "\n",
    "        total_calls = len(self.current_session_logs)\n",
    "        successful_calls = sum(1 for log in self.current_session_logs if log[\"success\"])\n",
    "        failed_calls = total_calls - successful_calls\n",
    "\n",
    "        # 统计工具使用次数\n",
    "        tool_counts = {}\n",
    "        for log in self.current_session_logs:\n",
    "            tool_name = log[\"tool_name\"]\n",
    "            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n",
    "\n",
    "        return {\n",
    "            \"total_calls\": total_calls,\n",
    "            \"successful_calls\": successful_calls,\n",
    "            \"failed_calls\": failed_calls,\n",
    "            \"success_rate\": f\"{(successful_calls/total_calls*100):.1f}%\" if total_calls > 0 else \"0%\",\n",
    "            \"tool_usage\": tool_counts,\n",
    "            \"token_usage\": {\n",
    "                \"total_input_tokens\": self.total_input_tokens,\n",
    "                \"total_output_tokens\": self.total_output_tokens,\n",
    "                \"total_tokens\": self.total_tokens,\n",
    "                \"cache_hit_tokens\": self.cache_hit_tokens\n",
    "            },\n",
    "            \"session_duration\": str(datetime.now() - self.session_start_time)\n",
    "        }\n",
    "\n",
    "    def print_statistics(self):\n",
    "        \"\"\"打印统计信息\"\"\"\n",
    "        stats = self.get_statistics()\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"📊 Tool Call Statistics\")\n",
    "        print(\"=\"*70)\n",
    "        for key, value in stats.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "\n",
    "class ToolLoggingMiddleware(AgentMiddleware):\n",
    "    \"\"\"\n",
    "    创建工具日志中间件\n",
    "    使用 @wrap_model_call 装饰器从 ModelRequest 获取消息历史\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir: str = \"LangChain_AgenticRAG/logs\"):\n",
    "        super().__init__()\n",
    "        self.logger = ToolCallLogger()\n",
    "\n",
    "\n",
    "    def after_model(self,state: AgentState, runtime) -> None:\n",
    "        \"\"\"\n",
    "        从 ModelRequest 中获取消息历史，记录工具调用信息\n",
    "\n",
    "        Args:\n",
    "            request: ModelRequest 包含 state (包括 messages)\n",
    "            handler: 处理函数，执行实际的模型调用\n",
    "\n",
    "        Returns:\n",
    "            ModelResponse 模型响应\n",
    "        \"\"\"\n",
    "        # 从 state 获取消息历史\n",
    "        messages = state.get(\"messages\", [])\n",
    "\n",
    "        # print(f\"🔍 [Tool Logging] 分析消息历史，{messages} 消息\")\n",
    "\n",
    "        # 检查消息历史中的工具调用和结果\n",
    "        for msg in messages:\n",
    "            # 检测 AI 消息并提取 token 使用信息\n",
    "            if hasattr(msg, 'type') and msg.type == 'ai':\n",
    "                # 优先从 usage_metadata 获取\n",
    "                if hasattr(msg, 'usage_metadata') and msg.usage_metadata:\n",
    "                    input_tokens = msg.usage_metadata.get('input_tokens', 0)\n",
    "                    output_tokens = msg.usage_metadata.get('output_tokens', 0)\n",
    "                    total_tokens = msg.usage_metadata.get('total_tokens', 0)\n",
    "\n",
    "                    # 获取缓存命中信息\n",
    "                    cache_hit = 0\n",
    "                    if 'input_token_details' in msg.usage_metadata:\n",
    "                        cache_hit = msg.usage_metadata['input_token_details'].get('cache_read', 0)\n",
    "\n",
    "                    # 累计 token\n",
    "                    self.logger.accumulate_tokens(input_tokens, output_tokens, total_tokens, cache_hit)\n",
    "\n",
    "                # 备选：从 response_metadata 获取\n",
    "                elif hasattr(msg, 'response_metadata') and msg.response_metadata:\n",
    "                    token_usage = msg.response_metadata.get('token_usage', {})\n",
    "                    if token_usage:\n",
    "                        input_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        output_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                        cache_hit = token_usage.get('prompt_cache_hit_tokens', 0)\n",
    "\n",
    "                        # 累计 token\n",
    "                        self.logger.accumulate_tokens(input_tokens, output_tokens, total_tokens, cache_hit)\n",
    "\n",
    "            # 检测 AI 消息中的工具调用请求\n",
    "            if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    # tool_call 可能是字典或对象，需要兼容两种方式\n",
    "                    if isinstance(tool_call, dict):\n",
    "                        tool_name = tool_call.get('name', 'unknown')\n",
    "                        tool_args = tool_call.get('args', {})\n",
    "                        tool_id = tool_call.get('id', 'unknown_id')\n",
    "                    else:\n",
    "                        tool_name = getattr(tool_call, 'name', 'unknown')\n",
    "                        tool_args = getattr(tool_call, 'args', {})\n",
    "                        tool_id = getattr(tool_call, 'id', 'unknown_id')\n",
    "\n",
    "                    # 记录工具调用开始时间\n",
    "                    if tool_id not in self.logger.tool_call_times:\n",
    "                        self.logger.tool_call_times[tool_id] = time.time()\n",
    "                        print(f\"\\n🔧 [Tool Logging] 检测到工具调用: {tool_name}\")\n",
    "                        print(f\"   工具ID: {tool_id}\")\n",
    "                        print(f\"   参数: {str(tool_args)[:200]}...\")\n",
    "\n",
    "            # 检测工具返回消息\n",
    "            if hasattr(msg, 'type') and msg.type == 'tool':\n",
    "                tool_name = getattr(msg, 'name', 'unknown')\n",
    "                tool_content = getattr(msg, 'content', '')\n",
    "                tool_call_id = getattr(msg, 'tool_call_id', 'unknown_id')\n",
    "                token_usage = getattr(msg, 'token_usage', 0)\n",
    "\n",
    "                # 判断是否成功\n",
    "                success = not tool_content.startswith('❌') and not tool_content.startswith('Error')\n",
    "                error_msg = tool_content if not success else None\n",
    "\n",
    "                # 记录日志\n",
    "                self.logger.log_tool_call(\n",
    "                    tool_name=tool_name,\n",
    "                    tool_input=\"[从消息历史提取]\",\n",
    "                    tool_output=tool_content,\n",
    "                    success=success,\n",
    "                    error=error_msg,\n",
    "                    metadata={\n",
    "                        \"tool_call_id\": tool_call_id,\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                        \"message_type\": msg.type\n",
    "                    },\n",
    "                    token_usage=token_usage\n",
    "                )\n",
    "        # 打印当前统计信息\n",
    "        self.logger.print_statistics()\n",
    "\n",
    "\n",
    "# 实例化日志中间件\n",
    "logging_middleware = ToolLoggingMiddleware(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 工具调用限制中间件（after_model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 核心作用：对工具调用设置最大次数限制，避免对工具的滥用。\n",
    "\n",
    "* **注意**：一个ToolCallLimitMiddleware里面的tool_name只能限制一个工具，如果想要限制多个工具的话就需要定义多个中间件来实现！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:27:13.482209Z",
     "start_time": "2025-12-09T17:27:13.479527Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ToolCallLimitMiddleware\n",
    "\n",
    "# 限制 query_retrieval_knowledge 工具调用次数\n",
    "retrieval_limit_middleware = ToolCallLimitMiddleware(\n",
    "    tool_name=\"query_retrieval_knowledge\",\n",
    "    run_limit=3,  # 每次运行最多调用 3 次\n",
    "    exit_behavior=\"continue\"  # 超限后继续执行，但阻止工具调用\n",
    ")\n",
    "\n",
    "# 限制 query_sensitive_knowledge 工具调用次数\n",
    "sensitive_limit_middleware = ToolCallLimitMiddleware(\n",
    "    tool_name=\"query_sensitive_knowledge\",\n",
    "    run_limit=3,  # 每次运行最多调用 3 次\n",
    "    exit_behavior=\"continue\"  # 超限后继续执行，但阻止工具调用\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. HITL 人工干预中间件（after_model）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 核心作用：监控敏感知识库查询时，可以通过人工干预进行审核，确保查询结果的准确性和安全性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:25:03.040690Z",
     "start_time": "2025-12-09T17:25:03.038441Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "\n",
    "# 创建官方 HITL 中间件，监控敏感知识库查询工具\n",
    "official_hitl_middleware = HumanInTheLoopMiddleware(\n",
    "    interrupt_on={\"query_sensitive_knowledge\": True},  # 监控敏感知识库查询工具\n",
    "    description_prefix=\"需要人工批准才能查询敏感知识库\"    # 提示前缀\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 动态提示词中间件（wrap_model_call）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 核心作用：能够根据检索次数来动态调整系统提示词，以提高检索效果。\n",
    "\n",
    "* **注意**：这里使用的装饰器dynamic_prompt，其实是wrap_model_call类型的中间件，包裹在model运行的生命周期里！\n",
    "\n",
    "* __执行时机__：在模型调用时动态修改 system prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:26:22.679137Z",
     "start_time": "2025-12-09T17:26:22.674146Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt\n",
    "\n",
    "@dynamic_prompt\n",
    "def rag_optimized_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"\n",
    "    根据检索状态动态生成提示词\n",
    "    核心逻辑：通过分析消息历史中的工具调用次数，确定当前所处的 RAG 阶段\n",
    "    \"\"\"\n",
    "    messages = request.messages if hasattr(request, 'messages') else []\n",
    "\n",
    "    # 统计所有工具调用中的知识库查询次数（包括检索和敏感查询）\n",
    "    retrieval_count = 0\n",
    "    for msg in messages:\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            for tool_call in msg.tool_calls:\n",
    "                name = tool_call.name if hasattr(tool_call, 'name') else tool_call.get('name')\n",
    "                # 统计知识库查询次数（包括检索和敏感查询）\n",
    "                if name == 'query_retrieval_knowledge' or name == 'tavily_search_results_json' or name == 'query_sensitive_knowledge':\n",
    "                    retrieval_count += 1\n",
    "\n",
    "    print(f\"DEBUG: 当前累计检索次数: {retrieval_count}\")\n",
    "\n",
    "    # 基础提示词\n",
    "    base_prompt = \"\"\"你是一个智能知识助手，能够自主检索信息并回答问题。\n",
    "\n",
    "    🔧 可用工具说明：\n",
    "    1. query_retrieval_knowledge: 专门用于 LangChain 技术问题（LangChain、LangGraph、Agent、RAG、Retriever 等）\n",
    "    2. tavily_search_results_json: 用于通用问题的网络搜索（烹饪、历史、科学、新闻等）\n",
    "    3. query_sensitive_knowledge: 🔴 高风险工具 - 查询敏感知识库（财务数据、战略规划、客户信息等机密资料）\n",
    "\n",
    "    ⚠️ 工具选择原则：\n",
    "    - 如果问题涉及 LangChain 相关技术 → 使用 query_retrieval_knowledge\n",
    "    - 如果问题与 LangChain 无关（如烹饪、历史、科学等） → 直接使用 tavily_search_results_json\n",
    "    - 如果问题涉及敏感数据查询（财务、战略、客户、人事等） → 使用 query_sensitive_knowledge\n",
    "    - 不要对非 LangChain 问题调用知识库检索工具\n",
    "\n",
    "    🔴 高风险工具使用注意事项：\n",
    "    - query_sensitive_knowledge 需要人工审核批准才能执行\n",
    "    - 仅在用户明确请求查询机密/敏感信息时使用\n",
    "    - 调用此工具后，系统会暂停等待管理员批准\n",
    "    - 适用场景：财务报告、战略规划、客户档案、人事薪资、技术文档等\n",
    "\n",
    "    请遵循以下流程：\n",
    "    1. 分析用户问题的类型和复杂度\n",
    "    2. 判断问题是否与 LangChain 相关，或是否涉及敏感数据\n",
    "    3. 选择合适的检索工具\n",
    "    4. 评估检索结果的质量（覆盖率、完整性、相关性）\n",
    "    5. 如果结果不足，主动进行补充检索\n",
    "    6. 综合所有信息生成最终回答\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始状态：未进行任何知识库查询\n",
    "    if retrieval_count == 0:\n",
    "        return base_prompt + \"\"\"\n",
    "\n",
    "        【当前状态：初始阶段】\n",
    "        ⚠️ 重要：你还没有进行任何检索！\n",
    "\n",
    "        请先判断问题类型：\n",
    "        - 如果是 LangChain 相关问题 → 使用 query_retrieval_knowledge\n",
    "        - 如果是其他领域问题 → 使用 tavily_search_results_json\n",
    "        - 如果涉及敏感数据查询 → 使用 query_sensitive_knowledge（需人工批准）\n",
    "\n",
    "        ❌ 禁止在没有检索的情况下直接回答问题。\n",
    "        \"\"\"\n",
    "\n",
    "    # 信息评估阶段：已进行 1-2 次知识库查询\n",
    "    elif retrieval_count < 3:\n",
    "        return base_prompt + f\"\"\"\n",
    "\n",
    "        【当前状态：信息评估（已检索 {retrieval_count} 次）】\n",
    "        请检查上一步工具返回的搜索结果：\n",
    "        1. 信息是否覆盖了用户问题的全部维度？\n",
    "        2. 多个来源的信息是否一致？\n",
    "\n",
    "        👉 决策路径：\n",
    "        - 如果信息不足或有歧义 -> 请换个关键词或角度进行补充检索。\n",
    "        - 如果信息已经充分 -> 请根据上下文生成最终回答。\n",
    "        \"\"\"\n",
    "\n",
    "    # 最终回答阶段：已进行 3 次及以上知识库查询\n",
    "    else:\n",
    "        return base_prompt + f\"\"\"\n",
    "\n",
    "        【当前状态：最终回答（已检索 {retrieval_count} 次）】\n",
    "        🛑 已达到最大检索次数限制，请停止检索！\n",
    "\n",
    "        请必须基于当前已有的所有信息，生成最终的回答。\n",
    "        如果检索到的信息仍不能完全回答问题，请诚实地说明信息的局限性或缺失部分。\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、 集成中间件到Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **注意**：after_model的注册顺序与最终执行顺序相反，是逆序执行，所以需要注意注册顺序，HITL人工干预中间件能够中断程序的要放在执行的最后，注册顺序为第一位置，下面顺序和截图都做过了修改！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:27:36.866493Z",
     "start_time": "2025-12-09T17:27:36.863932Z"
    }
   },
   "outputs": [],
   "source": [
    "# 中间件列表 (注意顺序)\n",
    "middlewares = [\n",
    "        \n",
    "    # before_model: 准备阶段，上下文压缩中间件\n",
    "    summarization_middleware,\n",
    "    \n",
    "    # wrap_model_call: 模型调用包裹，智能切换系统提示词\n",
    "    rag_optimized_prompt,\n",
    "    \n",
    "    # after_model: 后处理（逆序执行，所以倒着写）\n",
    "    official_hitl_middleware,        # 最后执行：人工审核（可能中断）\n",
    "    logging_middleware,              # 倒数第二：记录日志\n",
    "    sensitive_limit_middleware,      # 倒数第三：限制敏感工具\n",
    "    retrieval_limit_middleware,      # 最先执行：限制检索工具\n",
    "    \n",
    "    # wrap_tool_call: 工具调用包裹\n",
    "    retry_middleware,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251211153335790.png\" width=50%></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:28:09.725902Z",
     "start_time": "2025-12-09T17:28:09.708654Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# 创建并运行 Agent\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "# 配置线程 ID\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread-final\"}}\n",
    "\n",
    "# 创建 Agent\n",
    "agent = create_agent(\n",
    "    tools=tools,\n",
    "    model=model,\n",
    "    middleware=middlewares,\n",
    "    debug=False,                    # 关闭调试模式\n",
    "    checkpointer=InMemorySaver(),   # 内存检查点，用于存储状态\n",
    "    context_schema=Context         # 上下文模式，定义了状态的结构\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过`langgraph studio`可视化调试,观察Agent的运行状态和行为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251211154533768.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 测试HITL中间件触发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:30:04.291408Z",
     "start_time": "2025-12-09T17:30:04.281242Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入 Command 用于恢复执行\n",
    "from langgraph.types import Command\n",
    "# 导入 HITL 相关类\n",
    "from langchain.agents.middleware.human_in_the_loop import (\n",
    "    HITLResponse,\n",
    "    ApproveDecision,\n",
    "    EditDecision,\n",
    "    RejectDecision\n",
    ")\n",
    "\n",
    "def run_hitl_interactive_test():\n",
    "    \"\"\"\n",
    "    运行 HITL 人工干预交互式测试\n",
    "    参考 HITL_demo.py 的完整流程\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🚀 开始执行 Agentic RAG 测试 (HITL 人工干预模式)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 测试提示词：触发敏感知识库查询\n",
    "    user_input = \"帮我查询一下2024年Q4财务报告数据的详细内容。\"\n",
    "    print(f\"\\n[用户]: {user_input}\")\n",
    "\n",
    "    # === 第一步：初始执行 ===\n",
    "    print(\"\\n[系统]: 开始处理请求...\")\n",
    "\n",
    "    for event in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\",\n",
    "        context={\"user_role\": \"财务分析师\"}\n",
    "    ):\n",
    "        if \"messages\" in event:\n",
    "            last_msg = event[\"messages\"][-1]\n",
    "            if last_msg.type == \"ai\" and hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                print(f\"[AI 决策]: 准备调用工具 -> {last_msg.tool_calls[0]['name']}\")\n",
    "\n",
    "    # === 第二步：观察中断状态 ===\n",
    "    snapshot = agent.get_state(config)\n",
    "\n",
    "    print(f\"\\n--- 🛑 执行已暂停 (HITL Middleware 触发) ---\")\n",
    "    print(f\"下一步骤: {snapshot.next}\")\n",
    "    print(f\"任务数量: {len(snapshot.tasks) if snapshot.tasks else 0}\")\n",
    "\n",
    "    # 检查是否有待处理的任务（表示中断发生）\n",
    "    if snapshot.tasks:\n",
    "        last_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "            tool_call = last_message.tool_calls[0]\n",
    "\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(\"🔴 检测到高风险操作：敏感知识库查询\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"工具名称: {tool_call['name']}\")\n",
    "            print(f\"查询内容: {tool_call['args'].get('query', 'N/A')}\")\n",
    "            print(f\"数据类别: {tool_call['args'].get('data_category', 'confidential')}\")\n",
    "            print(f\"{'='*70}\")\n",
    "\n",
    "            # === 第三步：人工决策 ===\n",
    "            approval = input(\"\\n[管理员]: 是否批准此操作? (y/n/e[编辑]): \").strip().lower()\n",
    "\n",
    "            if approval == 'y':\n",
    "                # === 批准操作 ===\n",
    "                print(\"\\n[系统]: ✅ 操作已批准，继续执行...\")\n",
    "\n",
    "                hitl_response = HITLResponse(\n",
    "                    decisions=[ApproveDecision(type=\"approve\")]\n",
    "                )\n",
    "\n",
    "                # 第四步：恢复执行\n",
    "                for event in agent.stream(\n",
    "                    Command(resume=hitl_response),\n",
    "                    config=config,\n",
    "                    stream_mode=\"values\"\n",
    "                ):\n",
    "                    if \"messages\" in event:\n",
    "                        last_msg = event[\"messages\"][-1]\n",
    "                        if last_msg.type == \"tool\":\n",
    "                            print(f\"\\n[工具输出]:\\n{last_msg.content}\")\n",
    "                        elif last_msg.type == \"ai\" and last_msg.content:\n",
    "                            print(f\"\\n[AI 最终回复]: {last_msg.content}\")\n",
    "\n",
    "            elif approval == 'e':\n",
    "                # === 编辑操作 ===\n",
    "                print(\"\\n[系统]: ✏️  编辑模式...\")\n",
    "                print(f\"当前参数: {tool_call['args']}\")\n",
    "\n",
    "                new_query = input(f\"新查询内容 (当前: {tool_call['args'].get('query', '')}，留空保持不变): \").strip()\n",
    "                new_category = input(f\"新数据类别 (当前: {tool_call['args'].get('data_category', 'confidential')}，留空保持不变): \").strip()\n",
    "\n",
    "                updated_args = tool_call['args'].copy()\n",
    "                if new_query:\n",
    "                    updated_args['query'] = new_query\n",
    "                if new_category:\n",
    "                    updated_args['data_category'] = new_category\n",
    "\n",
    "                print(f\"\\n[系统]: 使用更新后的参数继续执行...\")\n",
    "                print(f\"更新后的参数: {updated_args}\")\n",
    "\n",
    "                hitl_response = HITLResponse(\n",
    "                    decisions=[EditDecision(\n",
    "                        type=\"edit\",\n",
    "                        edited_action={\n",
    "                            \"name\": tool_call['name'],\n",
    "                            \"args\": updated_args\n",
    "                        }\n",
    "                    )]\n",
    "                )\n",
    "\n",
    "                for event in agent.stream(\n",
    "                    Command(resume=hitl_response),\n",
    "                    config=config,\n",
    "                    stream_mode=\"values\"\n",
    "                ):\n",
    "                    if \"messages\" in event:\n",
    "                        last_msg = event[\"messages\"][-1]\n",
    "                        if last_msg.type == \"tool\":\n",
    "                            print(f\"\\n[工具输出]:\\n{last_msg.content}\")\n",
    "                        elif last_msg.type == \"ai\" and last_msg.content:\n",
    "                            print(f\"\\n[AI 最终回复]: {last_msg.content}\")\n",
    "\n",
    "            else:\n",
    "                # === 拒绝操作 ===\n",
    "                print(\"\\n[系统]: ❌ 操作被拒绝\")\n",
    "\n",
    "                rejection_reason = input(\"拒绝原因 (可选): \").strip() or \"操作被管理员拒绝，权限不足\"\n",
    "\n",
    "                hitl_response = HITLResponse(\n",
    "                    decisions=[RejectDecision(\n",
    "                        type=\"reject\",\n",
    "                        message=rejection_reason\n",
    "                    )]\n",
    "                )\n",
    "\n",
    "                for event in agent.stream(\n",
    "                    Command(resume=hitl_response),\n",
    "                    config=config,\n",
    "                    stream_mode=\"values\"\n",
    "                ):\n",
    "                    if \"messages\" in event:\n",
    "                        last_msg = event[\"messages\"][-1]\n",
    "                        if last_msg.type == \"ai\" and last_msg.content:\n",
    "                            print(f\"\\n[AI 回复]: {last_msg.content}\")\n",
    "                        elif last_msg.type == \"tool\":\n",
    "                            print(f\"\\n[工具消息]: {last_msg.content}\")\n",
    "\n",
    "                print(\"\\n[系统]: 流程已终止\")\n",
    "        else:\n",
    "            print(\"⚠️  没有检测到待处理的工具调用\")\n",
    "    else:\n",
    "        print(\"ℹ️  流程已完成，没有触发中断\")\n",
    "        if snapshot.values.get(\"messages\"):\n",
    "            last_msg = snapshot.values[\"messages\"][-1]\n",
    "            if last_msg.type == \"ai\" and last_msg.content:\n",
    "                print(f\"\\n[最终回复]: {last_msg.content}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✅ HITL 测试完成！\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 打印统计信息\n",
    "    print(\"\\n📊 中间件统计信息:\")\n",
    "    logging_middleware.logger.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:30:40.002806Z",
     "start_time": "2025-12-09T17:30:15.456731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 开始执行 Agentic RAG 测试 (HITL 人工干预模式)\n",
      "======================================================================\n",
      "\n",
      "[用户]: 帮我查询一下2024年Q4财务报告数据的详细内容。\n",
      "\n",
      "[系统]: 开始处理请求...\n",
      "DEBUG: 当前累计检索次数: 0\n",
      "[AI 决策]: 准备调用工具 -> query_sensitive_knowledge\n",
      "[AI 决策]: 准备调用工具 -> query_sensitive_knowledge\n",
      "📊 [Token Usage] 输入: 2783, 输出: 188, 总计: 2971\n",
      "   缓存命中: 128 tokens\n",
      "\n",
      "🔧 [Tool Logging] 检测到工具调用: query_sensitive_knowledge\n",
      "   工具ID: call_00_RSlD4OaFsVDRa0ujkBJ4q9GX\n",
      "   参数: {'query': '2024年Q4财务报告数据的详细内容', 'data_category': 'confidential'}...\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  message: No logs yet\n",
      "======================================================================\n",
      "\n",
      "--- 🛑 执行已暂停 (HITL Middleware 触发) ---\n",
      "下一步骤: ('HumanInTheLoopMiddleware.after_model',)\n",
      "任务数量: 1\n",
      "\n",
      "======================================================================\n",
      "🔴 检测到高风险操作：敏感知识库查询\n",
      "======================================================================\n",
      "工具名称: query_sensitive_knowledge\n",
      "查询内容: 2024年Q4财务报告数据的详细内容\n",
      "数据类别: confidential\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[管理员]: 是否批准此操作? (y/n/e[编辑]):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[系统]: ✅ 操作已批准，继续执行...\n",
      "\n",
      "[AI 最终回复]: 我理解您想要查询2024年Q4财务报告数据的详细内容。这是一个涉及敏感财务数据的查询请求，需要使用高风险工具。\n",
      "\n",
      "**重要提醒**：查询敏感财务数据需要人工审核批准。我将为您启动这个查询流程，但请注意：\n",
      "\n",
      "1. **需要管理员批准**：系统会暂停并等待管理员审核通过后才能执行\n",
      "2. **数据敏感性**：财务报告属于机密信息，访问权限受到严格控制\n",
      "3. **查询范围**：我将查询2024年第四季度的完整财务报告数据\n",
      "\n",
      "让我为您提交查询请求：\n",
      "\n",
      "[AI 最终回复]: 我理解您想要查询2024年Q4财务报告数据的详细内容。这是一个涉及敏感财务数据的查询请求，需要使用高风险工具。\n",
      "\n",
      "**重要提醒**：查询敏感财务数据需要人工审核批准。我将为您启动这个查询流程，但请注意：\n",
      "\n",
      "1. **需要管理员批准**：系统会暂停并等待管理员审核通过后才能执行\n",
      "2. **数据敏感性**：财务报告属于机密信息，访问权限受到严格控制\n",
      "3. **查询范围**：我将查询2024年第四季度的完整财务报告数据\n",
      "\n",
      "让我为您提交查询请求：\n",
      "\n",
      "🔴 [高风险操作] 敏感知识库 RAG 检索\n",
      "   数据类别: confidential\n",
      "   查询内容: 2024年Q4财务报告数据的详细内容\n",
      "   正在检索敏感知识库...\n",
      "\n",
      "[工具输出]:\n",
      "🔴 机密级 检索结果\n",
      "======================================================================\n",
      "\n",
      "📋 检索到的敏感信息：\n",
      "\n",
      "三、运营岗位薪资\n",
      "- 运营专员：10K-15K\n",
      "- 运营经理：15K-25K\n",
      "- 高级运营经理：25K-35K\n",
      "- 运营总监：35K-50K\n",
      "\n",
      "四、薪酬福利\n",
      "- 五险一金：按国家标准缴纳\n",
      "- 年终奖：2-6个月薪资（根据绩效）\n",
      "- 股权激励：核心员工可获得期权\n",
      "- 其他福利：\n",
      "  * 带薪年假：10-20天\n",
      "  * 节日福利：每年5000元\n",
      "  * 健康体检：每年一次\n",
      "  * 团建活动：每季度一次\n",
      "\n",
      "五、绩效考核\n",
      "- 考核周期：季度考核 + 年度考核\n",
      "- 考核等级：S（10%）、A（20%）、B（60%）、C（10%）\n",
      "- 晋升机制：连续两次A或一次S可申请晋升\n",
      "- 淘汰机制：连续两次C将被淘汰\n",
      "\n",
      "====================\n",
      "\n",
      "【敏感】用户数据分析报告\n",
      "====================\n",
      "报告类型：用户行为分析\n",
      "密级：敏感\n",
      "统计周期：2024年全年\n",
      "\n",
      "一、用户规模\n",
      "- 注册用户总数：50万\n",
      "- 活跃用户数：30万（月活）\n",
      "- 付费用户数：4万\n",
      "- 付费转化率：8%\n",
      "\n",
      "【机密】2024年Q4财务报告\n",
      "====================\n",
      "报告日期：2024年12月31日\n",
      "报告类型：季度财务报告\n",
      "密级：机密\n",
      "编制部门：财务部\n",
      "\n",
      "一、营收数据\n",
      "- 总营收：5000万元人民币\n",
      "- 同比增长：25%\n",
      "- 环比增长：15%\n",
      "- 主要收入来源：软件服务占60%，咨询服务占30%，其他占10%\n",
      "\n",
      "二、利润数据\n",
      "- 净利润：1200万元\n",
      "- 毛利润：2250万元\n",
      "- 毛利率：45%\n",
      "- 净利率：24%\n",
      "- 营业利润率：28%\n",
      "\n",
      "三、现金流数据\n",
      "- 经营性现金流：800万元\n",
      "- 投资性现金流：-300万元（主要用于设备采购和研发投入）\n",
      "- 筹资性现金流：200万元\n",
      "- 期末现金余额：1500万元\n",
      "\n",
      "四、重要客户分析\n",
      "- A公司：年度合同额1500万元，占总营收30%，合作3年，续约率100%\n",
      "- B公司：年度合同额1000万元，占总营收20%，新客户，增长潜力大\n",
      "- C公司：年度合同额800万元，占总营收16%，合同即将到期需重点维护\n",
      "- 其他客户：合计1700万元，占总营收34%\n",
      "\n",
      "====================\n",
      "\n",
      "二、并购与投资计划\n",
      "1. C公司收购谈判\n",
      "   - 目标估值：5000万元\n",
      "   - 谈判进度：尽职调查阶段\n",
      "   - 预计完成时间：2025年Q2\n",
      "   - 收购理由：技术互补，客户资源整合\n",
      "   - 风险评估：中等风险，需关注技术团队稳定性\n",
      "\n",
      "2. D公司战略投资\n",
      "   - 投资金额：1000万元\n",
      "   - 持股比例：20%\n",
      "   - 投资目的：布局上游供应链\n",
      "\n",
      "三、组织优化计划\n",
      "1. 人力成本优化\n",
      "   - 优化比例：20%\n",
      "   - 涉及部门：运营部（优化30人）、市场部（优化20人）\n",
      "   - 预计节省：800万元/年\n",
      "   - 实施时间：Q1完成\n",
      "   - 补偿方案：N+2补偿标准\n",
      "\n",
      "2. 组织架构调整\n",
      "   - 新设AI事业部\n",
      "   - 合并市场部和销售部\n",
      "   - 强化研发中心\n",
      "\n",
      "====================\n",
      "\n",
      "【机密】客户关系管理数据\n",
      "====================\n",
      "数据类型：VIP客户档案\n",
      "密级：机密\n",
      "更新日期：2024年12月\n",
      "\n",
      "二、用户画像\n",
      "- 年龄分布：\n",
      "  * 18-25岁：20%\n",
      "  * 25-35岁：60%\n",
      "  * 35-45岁：15%\n",
      "  * 45岁以上：5%\n",
      "\n",
      "- 地域分布：\n",
      "  * 一线城市：70%（北上广深）\n",
      "  * 二线城市：20%\n",
      "  * 其他城市：10%\n",
      "\n",
      "- 职业分布：\n",
      "  * 互联网从业者：40%\n",
      "  * 金融从业者：25%\n",
      "  * 企业管理者：20%\n",
      "  * 其他：15%\n",
      "\n",
      "三、用户行为\n",
      "- 平均使用时长：45分钟/天\n",
      "- 平均访问频次：3次/天\n",
      "- 核心功能使用率：\n",
      "  * 数据分析：85%\n",
      "  * 报表生成：70%\n",
      "  * 协作功能：60%\n",
      "\n",
      "四、用户留存\n",
      "- 次日留存率：65%\n",
      "- 7日留存率：45%\n",
      "- 30日留存率：30%\n",
      "- 流失原因分析：\n",
      "  * 功能不满足需求：40%\n",
      "  * 价格因素：30%\n",
      "  * 竞品吸引：20%\n",
      "  * 其他：10%\n",
      "\n",
      "五、用户价值\n",
      "- ARPU（平均每用户收入）：1250元/年\n",
      "- LTV（用户生命周期价值）：3750元\n",
      "- CAC（用户获取成本）：800元\n",
      "- LTV/CAC比率：4.7（健康水平）\n",
      "\n",
      "======================================================================\n",
      "\n",
      "⚠️ 安全警告：\n",
      "- 以上为🔴 机密级信息，请妥善保管，不得外泄！\n",
      "- 访问已记录，将用于安全审计\n",
      "- 如需分享，请确保接收方具有相应权限\n",
      "- 查询时间：2025-12-11 15:48:57\n",
      "DEBUG: 当前累计检索次数: 1\n",
      "\n",
      "[AI 最终回复]: 根据查询结果，我为您整理了2024年Q4财务报告的详细内容：\n",
      "\n",
      "## 📊 **2024年Q4财务报告（机密级）**\n",
      "\n",
      "### **一、基本信息**\n",
      "- **报告日期**：2024年12月31日\n",
      "- **报告类型**：季度财务报告\n",
      "- **密级**：机密\n",
      "- **编制部门**：财务部\n",
      "\n",
      "### **二、核心财务数据**\n",
      "\n",
      "#### **1. 营收数据**\n",
      "- **总营收**：5000万元人民币\n",
      "- **同比增长**：25%\n",
      "- **环比增长**：15%\n",
      "- **收入结构**：\n",
      "  - 软件服务：60%（3000万元）\n",
      "  - 咨询服务：30%（1500万元）\n",
      "  - 其他收入：10%（500万元）\n",
      "\n",
      "#### **2. 利润数据**\n",
      "- **净利润**：1200万元\n",
      "- **毛利润**：2250万元\n",
      "- **毛利率**：45%\n",
      "- **净利率**：24%\n",
      "- **营业利润率**：28%\n",
      "\n",
      "#### **3. 现金流数据**\n",
      "- **经营性现金流**：800万元\n",
      "- **投资性现金流**：-300万元（主要用于设备采购和研发投入）\n",
      "- **筹资性现金流**：200万元\n",
      "- **期末现金余额**：1500万元\n",
      "\n",
      "### **三、重要客户分析**\n",
      "\n",
      "#### **主要客户贡献**\n",
      "1. **A公司**：\n",
      "   - 年度合同额：1500万元\n",
      "   - 占总营收：30%\n",
      "   - 合作年限：3年\n",
      "   - 续约率：100%\n",
      "\n",
      "2. **B公司**：\n",
      "   - 年度合同额：1000万元\n",
      "   - 占总营收：20%\n",
      "   - 客户类型：新客户\n",
      "   - 备注：增长潜力大\n",
      "\n",
      "3. **C公司**：\n",
      "   - 年度合同额：800万元\n",
      "   - 占总营收：16%\n",
      "   - 备注：合同即将到期，需重点维护\n",
      "\n",
      "4. **其他客户**：\n",
      "   - 合计：1700万元\n",
      "   - 占总营收：34%\n",
      "\n",
      "### **四、关键财务指标分析**\n",
      "\n",
      "#### **盈利能力**\n",
      "- **毛利率45%**：表明产品/服务具有较强的定价能力和成本控制能力\n",
      "- **净利率24%**：在行业中属于较高水平，显示良好的盈利质量\n",
      "- **营业利润率28%**：运营效率较高\n",
      "\n",
      "#### **现金流状况**\n",
      "- **经营性现金流800万元**：主营业务现金流健康\n",
      "- **投资性现金流-300万元**：主要用于研发和设备投入，符合公司发展战略\n",
      "- **期末现金余额1500万元**：现金储备充足，抗风险能力强\n",
      "\n",
      "### **五、业绩亮点**\n",
      "1. **强劲增长**：同比增长25%，环比增长15%，显示业务持续扩张\n",
      "2. **利润改善**：净利率达到24%，盈利能力显著提升\n",
      "3. **客户结构优化**：前三大客户贡献66%收入，客户集中度合理\n",
      "4. **现金流健康**：经营性现金流为正，财务基础稳固\n",
      "\n",
      "### **六、风险提示**\n",
      "1. **客户依赖**：C公司合同即将到期，需加强客户关系维护\n",
      "2. **投资支出**：投资性现金流为负，需关注投资回报周期\n",
      "3. **行业竞争**：需持续投入研发以保持竞争优势\n",
      "\n",
      "---\n",
      "\n",
      "**⚠️ 安全提醒**：以上为机密财务信息，请妥善保管，仅限授权人员内部使用。如需进一步分析或与其他部门共享，请确保接收方具有相应权限。\n",
      "📊 [Token Usage] 输入: 2783, 输出: 188, 总计: 2971\n",
      "   缓存命中: 128 tokens\n",
      "📊 [Token Usage] 输入: 4177, 输出: 728, 总计: 4905\n",
      "   缓存命中: 384 tokens\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 1\n",
      "  successful_calls: 1\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1}\n",
      "  token_usage: {'total_input_tokens': 9743, 'total_output_tokens': 1104, 'total_tokens': 10847, 'cache_hit_tokens': 640}\n",
      "  session_duration: 0:22:18.513583\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "✅ HITL 测试完成！\n",
      "======================================================================\n",
      "\n",
      "📊 中间件统计信息:\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 1\n",
      "  successful_calls: 1\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1}\n",
      "  token_usage: {'total_input_tokens': 9743, 'total_output_tokens': 1104, 'total_tokens': 10847, 'cache_hit_tokens': 640}\n",
      "  session_duration: 0:22:18.518031\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_hitl_interactive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210130026313.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 测试普通 RAG 检索测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:31:41.010169Z",
     "start_time": "2025-12-09T17:31:41.003118Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_normal_rag_test():\n",
    "    \"\"\"\n",
    "    运行普通 RAG 检索测试\n",
    "    测试 query_retrieval_knowledge 工具的检索流程\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🚀 开始执行普通 RAG 检索测试\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 测试提示词：触发 LangChain 知识库检索\n",
    "    test_queries = [\n",
    "        \"LangChain 中的 Agent 是什么？它有哪些核心组件？\",\n",
    "        \"如何在 LangChain 中使用 RAG 进行问答？\",\n",
    "        \"LangGraph 和 LangChain 有什么区别？\"\n",
    "    ]\n",
    "\n",
    "    print(\"\\n可用的测试问题：\")\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"{i}. {query}\")\n",
    "\n",
    "    choice = input(\"\\n请选择测试问题 (1-3) 或输入自定义问题: \").strip()\n",
    "\n",
    "    if choice.isdigit() and 1 <= int(choice) <= len(test_queries):\n",
    "        user_input = test_queries[int(choice) - 1]\n",
    "    else:\n",
    "        user_input = choice if choice else test_queries[0]\n",
    "\n",
    "    print(f\"\\n[用户]: {user_input}\")\n",
    "    print(\"\\n[系统]: 开始处理请求...\\n\")\n",
    "\n",
    "    # 使用新的 thread_id 避免与 HITL 测试冲突\n",
    "    rag_config = {\"configurable\": {\"thread_id\": \"rag-test-thread\"}}\n",
    "\n",
    "    # 用于跟踪已打印的消息，避免重复\n",
    "    printed_message_ids = set()\n",
    "\n",
    "    # 执行 Agent 流程\n",
    "    for event in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=rag_config,\n",
    "        stream_mode=\"values\",\n",
    "        context={\"user_role\": \"开发者\"}\n",
    "    ):\n",
    "        if \"messages\" in event:\n",
    "            last_msg = event[\"messages\"][-1]\n",
    "\n",
    "            # 使用消息 ID 来避免重复打印\n",
    "            msg_id = getattr(last_msg, 'id', None)\n",
    "            if msg_id and msg_id in printed_message_ids:\n",
    "                continue\n",
    "\n",
    "            if msg_id:\n",
    "                printed_message_ids.add(msg_id)\n",
    "\n",
    "            # 显示 AI 的思考过程\n",
    "            if last_msg.type == \"ai\":\n",
    "                if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                    tool_call = last_msg.tool_calls[0]\n",
    "                    print(f\"🤖 [AI 决策]: 调用工具 -> {tool_call['name']}\")\n",
    "                    print(f\"   参数: {tool_call.get('args', {})}\")\n",
    "                elif last_msg.content:\n",
    "                    print(f\"\\n💬 [AI 回复]:\\n{last_msg.content}\")\n",
    "\n",
    "            # 显示工具执行结果\n",
    "            elif last_msg.type == \"tool\":\n",
    "                tool_name = getattr(last_msg, 'name', 'unknown')\n",
    "                print(f\"\\n🔧 [工具执行]: {tool_name}\")\n",
    "                print(f\"📄 [检索结果]:\\n{'-'*70}\")\n",
    "                # 只显示前500个字符，避免输出过长\n",
    "                content = last_msg.content\n",
    "                if len(content) > 500:\n",
    "                    print(f\"{content[:500]}...\\n(结果已截断，共 {len(content)} 字符)\")\n",
    "                else:\n",
    "                    print(content)\n",
    "                print(f\"{'-'*70}\\n\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✅ 普通 RAG 检索测试完成！\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # 打印统计信息\n",
    "    print(\"\\n📊 中间件统计信息:\")\n",
    "    logging_middleware.logger.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:33:31.707481Z",
     "start_time": "2025-12-09T17:31:47.488468Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 开始执行普通 RAG 检索测试\n",
      "======================================================================\n",
      "\n",
      "可用的测试问题：\n",
      "1. LangChain 中的 Agent 是什么？它有哪些核心组件？\n",
      "2. 如何在 LangChain 中使用 RAG 进行问答？\n",
      "3. LangGraph 和 LangChain 有什么区别？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "请选择测试问题 (1-3) 或输入自定义问题:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[用户]: LangGraph 和 LangChain 有什么区别？\n",
      "\n",
      "[系统]: 开始处理请求...\n",
      "\n",
      "DEBUG: 当前累计检索次数: 0\n",
      "🤖 [AI 决策]: 调用工具 -> query_retrieval_knowledge\n",
      "   参数: {'query': 'LangGraph 和 LangChain 有什么区别？'}\n",
      "📊 [Token Usage] 输入: 2778, 输出: 89, 总计: 2867\n",
      "   缓存命中: 2752 tokens\n",
      "\n",
      "🔧 [Tool Logging] 检测到工具调用: query_retrieval_knowledge\n",
      "   工具ID: call_00_fJrUlEYllpkC4V2gdwNYM4br\n",
      "   参数: {'query': 'LangGraph 和 LangChain 有什么区别？'}...\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 1\n",
      "  successful_calls: 1\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1}\n",
      "  token_usage: {'total_input_tokens': 12521, 'total_output_tokens': 1193, 'total_tokens': 13714, 'cache_hit_tokens': 3392}\n",
      "  session_duration: 0:23:11.839301\n",
      "======================================================================\n",
      "\n",
      "🔧 [工具执行]: query_retrieval_knowledge\n",
      "📄 [检索结果]:\n",
      "----------------------------------------------------------------------\n",
      "LangChain框架介绍\n",
      "\n",
      "LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用。\n",
      "\n",
      "主要特性：\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain采用模块化架构，包含多个核心组件：\n",
      "- Models：支持各种LLM模型的集成\n",
      "- Prompts：提示词模板管理\n",
      "- Chains：将多个组件链接在一起\n",
      "- Agents：智能代理，能够使用工具完成任务\n",
      "- Memory：对话历史和上下文管理\n",
      "\n",
      "2. RAG技术\n",
      "检索增强生成（RAG）是LangChain的核心功能之一。RAG通过以下步骤工作：\n",
      "- 文档加载：从各种来源加载文档\n",
      "- 文档分割：将长文档切分成小块\n",
      "- 向量化：将文本转换为向量嵌入\n",
      "- 向量存储：存储到向量数据库中\n",
      "- 检索：根据查询找到相关文档\n",
      "- 生成：LLM基于检索内容生成答案\n",
      "\n",
      "3. 支持的模型\n",
      "LangChain支持多种LLM提供商：\n",
      "- OpenAI（GPT-3.5、GPT-4）\n",
      "- Anthropic（Claude）\n",
      "- Google（PaLM）\n",
      "- 开源模型（LLaM...\n",
      "(结果已截断，共 791 字符)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "DEBUG: 当前累计检索次数: 1\n",
      "🤖 [AI 决策]: 调用工具 -> query_retrieval_knowledge\n",
      "   参数: {'query': 'LangGraph 是什么？LangGraph 功能特点'}\n",
      "📊 [Token Usage] 输入: 2778, 输出: 89, 总计: 2867\n",
      "   缓存命中: 2752 tokens\n",
      "📊 [Token Usage] 输入: 3284, 输出: 74, 总计: 3358\n",
      "   缓存命中: 2752 tokens\n",
      "\n",
      "🔧 [Tool Logging] 检测到工具调用: query_retrieval_knowledge\n",
      "   工具ID: call_00_fABS0F91lCS1Bkh9oZ9iEmuH\n",
      "   参数: {'query': 'LangGraph 是什么？LangGraph 功能特点'}...\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 2\n",
      "  successful_calls: 2\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1, 'query_retrieval_knowledge': 1}\n",
      "  token_usage: {'total_input_tokens': 18583, 'total_output_tokens': 1356, 'total_tokens': 19939, 'cache_hit_tokens': 8896}\n",
      "  session_duration: 0:23:16.790682\n",
      "======================================================================\n",
      "\n",
      "🔧 [工具执行]: query_retrieval_knowledge\n",
      "📄 [检索结果]:\n",
      "----------------------------------------------------------------------\n",
      "LangChain框架介绍\n",
      "\n",
      "LangChain是一个强大的开源框架，专门用于开发由大型语言模型（LLM）驱动的应用程序。它提供了一套完整的工具和组件，使开发者能够轻松构建复杂的AI应用。\n",
      "\n",
      "主要特性：\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain采用模块化架构，包含多个核心组件：\n",
      "- Models：支持各种LLM模型的集成\n",
      "- Prompts：提示词模板管理\n",
      "- Chains：将多个组件链接在一起\n",
      "- Agents：智能代理，能够使用工具完成任务\n",
      "- Memory：对话历史和上下文管理\n",
      "\n",
      "2. RAG技术\n",
      "检索增强生成（RAG）是LangChain的核心功能之一。RAG通过以下步骤工作：\n",
      "- 文档加载：从各种来源加载文档\n",
      "- 文档分割：将长文档切分成小块\n",
      "- 向量化：将文本转换为向量嵌入\n",
      "- 向量存储：存储到向量数据库中\n",
      "- 检索：根据查询找到相关文档\n",
      "- 生成：LLM基于检索内容生成答案\n",
      "\n",
      "3. 支持的模型\n",
      "LangChain支持多种LLM提供商：\n",
      "- OpenAI（GPT-3.5、GPT-4）\n",
      "- Anthropic（Claude）\n",
      "- Google（PaLM）\n",
      "- 开源模型（LLaM...\n",
      "(结果已截断，共 791 字符)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "DEBUG: 当前累计检索次数: 2\n",
      "🤖 [AI 决策]: 调用工具 -> tavily_search\n",
      "   参数: {'query': 'LangGraph vs LangChain 区别 对比', 'search_depth': 'advanced'}\n",
      "📊 [Token Usage] 输入: 2778, 输出: 89, 总计: 2867\n",
      "   缓存命中: 2752 tokens\n",
      "📊 [Token Usage] 输入: 3284, 输出: 74, 总计: 3358\n",
      "   缓存命中: 2752 tokens\n",
      "📊 [Token Usage] 输入: 4062, 输出: 87, 总计: 4149\n",
      "   缓存命中: 384 tokens\n",
      "\n",
      "🔧 [Tool Logging] 检测到工具调用: tavily_search\n",
      "   工具ID: call_00_Edur2u3WAIDO18v7RQmmpRmW\n",
      "   参数: {'query': 'LangGraph vs LangChain 区别 对比', 'search_depth': 'advanced'}...\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 4\n",
      "  successful_calls: 4\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1, 'query_retrieval_knowledge': 3}\n",
      "  token_usage: {'total_input_tokens': 28707, 'total_output_tokens': 1606, 'total_tokens': 30313, 'cache_hit_tokens': 14784}\n",
      "  session_duration: 0:23:37.361081\n",
      "======================================================================\n",
      "\n",
      "🔧 [工具执行]: tavily_search\n",
      "📄 [检索结果]:\n",
      "----------------------------------------------------------------------\n",
      "{\"query\": \"LangGraph vs LangChain 区别 对比\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://milvus.io/zh-hant/blog/langchain-vs-langgraph.md\", \"title\": \"LangChain vs LangGraph：開發人員的AI 框架選擇指南 - Milvus\", \"content\": \"Two of the most popular options today are LangChain and LangGraph — both open source and created by the LangChain team. LangChain focuses on component orchestration and workflow automation, making it a good fit for common use cases like retrieval-a...\n",
      "(结果已截断，共 2208 字符)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "DEBUG: 当前累计检索次数: 1\n",
      "🤖 [AI 决策]: 调用工具 -> tavily_search\n",
      "   参数: {'query': 'LangGraph 特性 状态图 节点 边 工作流', 'search_depth': 'advanced'}\n",
      "📊 [Token Usage] 输入: 3284, 输出: 74, 总计: 3358\n",
      "   缓存命中: 2752 tokens\n",
      "📊 [Token Usage] 输入: 4062, 输出: 87, 总计: 4149\n",
      "   缓存命中: 384 tokens\n",
      "📊 [Token Usage] 输入: 4319, 输出: 88, 总计: 4407\n",
      "   缓存命中: 2752 tokens\n",
      "\n",
      "🔧 [Tool Logging] 检测到工具调用: tavily_search\n",
      "   工具ID: call_00_GiRwm5ohzpH0PMsfrtThnDs6\n",
      "   参数: {'query': 'LangGraph 特性 状态图 节点 边 工作流', 'search_depth': 'advanced'}...\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 6\n",
      "  successful_calls: 6\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1, 'query_retrieval_knowledge': 4, 'tavily_search': 1}\n",
      "  token_usage: {'total_input_tokens': 40372, 'total_output_tokens': 1855, 'total_tokens': 42227, 'cache_hit_tokens': 20672}\n",
      "  session_duration: 0:23:56.294218\n",
      "======================================================================\n",
      "\n",
      "🔧 [工具执行]: tavily_search\n",
      "📄 [检索结果]:\n",
      "----------------------------------------------------------------------\n",
      "{\"query\": \"LangGraph 特性 状态图 节点 边 工作流\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://github.com/aneasystone/weekly-practice/blob/main/notes/week057-create-agents-with-langgraph/README.md\", \"title\": \"WEEK057 - 基于LangGraph 创建智能体应用\", \"content\": \"通过组合节点和边，我们可以创建复杂的循环工作流，随着节点的执行，不断更新状态。简而言之：节点用于执行动作，边用于指示下一步动作。\\n\\nLangGraph 的实现采用了 消息传递（Message passing） 的机制。其灵感源自 Google 的 Pregel 和 Apache 的 Beam 系统，当一个节点完成其操作后，它会沿着一条或多条边向其他节点发送消息。这些接收节点随后执行其功能，将生成的消息传递给下一组节点，如此...\n",
      "(结果已截断，共 3468 字符)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "DEBUG: 当前累计检索次数: 0\n",
      "\n",
      "💬 [AI 回复]:\n",
      "基于我获取的信息，现在我可以为您提供一个更全面和准确的 LangGraph 与 LangChain 对比分析：\n",
      "\n",
      "# LangGraph 与 LangChain 核心区别详解\n",
      "\n",
      "## 1. 基本定位差异\n",
      "\n",
      "### LangChain\n",
      "- **核心概念**：基于\"链\"（Chain）的框架\n",
      "- **设计理念**：顺序工作流，A → B → C 类型的线性流程\n",
      "- **适用场景**：快速原型、无状态任务、简单的输入-输出流程\n",
      "- **代码示例**：\n",
      "  ```python\n",
      "  const chain = pointA.pipe(pointB).pipe(pointC)\n",
      "  ```\n",
      "\n",
      "### LangGraph\n",
      "- **核心概念**：基于\"图\"（Graph）的框架\n",
      "- **设计理念**：有状态图结构，支持动态分支和循环\n",
      "- **适用场景**：有状态应用、复杂决策、多智能体协作\n",
      "- **代码示例**：定义状态图，包含节点和边\n",
      "\n",
      "## 2. 架构设计对比\n",
      "\n",
      "### LangChain 架构特点\n",
      "- **模块化设计**：Models、Prompts、Chains、Agents、Memory 等组件\n",
      "- **线性流程**：每个步骤按预定义顺序执行\n",
      "- **LCEL（LangChain Expression Language）**：用于组件编排\n",
      "- **主要用途**：RAG（检索增强生成）、问答系统、文档处理\n",
      "\n",
      "### LangGraph 架构特点\n",
      "- **图结构**：由节点（Nodes）、边（Edges）和状态（State）构成\n",
      "- **状态管理**：共享状态数据结构，代表应用程序当前快照\n",
      "- **消息传递机制**：灵感来自 Google 的 Pregel 和 Apache Beam 系统\n",
      "- **超步骤（Super-step）**：图节点的完整迭代，支持并行和顺序执行\n",
      "\n",
      "## 3. 核心组件详解\n",
      "\n",
      "### LangGraph 三大核心组件\n",
      "\n",
      "#### 1. 状态（State）\n",
      "- 共享数据结构，应用程序的当前快照\n",
      "- 通常是 `TypedDict` 或 Pydantic 的 `BaseModel` 类型\n",
      "- 为图中所有节点共享\n",
      "\n",
      "#### 2. 节点（Nodes）\n",
      "- 智能体的具体执行逻辑\n",
      "- 接收当前状态作为输入，执行计算，返回更新后的状态\n",
      "- 可以是任意 Python 函数，不限于调用大模型\n",
      "\n",
      "#### 3. 边（Edges）\n",
      "- 定义节点执行后的下一步动作\n",
      "- 可以是固定边或条件边\n",
      "- 条件边需要定义路由函数（Routing function）\n",
      "\n",
      "## 4. 功能特性对比\n",
      "\n",
      "### LangChain 核心功能\n",
      "- 组件编排和工作流自动化\n",
      "- 支持多种模型和工具集成\n",
      "- 内存管理\n",
      "- 提示模板\n",
      "- 文档加载和处理\n",
      "\n",
      "### LangGraph 高级功能\n",
      "- **循环和分支**：支持在应用程序中实现循环和条件语句\n",
      "- **持久性**：自动保存每一步的执行状态，支持任意点暂停和恢复\n",
      "- **人机协同**：支持在行动执行前中断，允许人工介入批准或编辑\n",
      "- **流支持**：每个节点都支持实时流式输出\n",
      "- **时间旅行**：支持错误恢复和状态回溯\n",
      "\n",
      "## 5. 适用场景分析\n",
      "\n",
      "### 使用 LangChain 的场景\n",
      "1. **简单问答系统**：输入问题 → 检索 → 生成答案\n",
      "2. **文档处理流水线**：文档加载 → 分割 → 嵌入 → 存储\n",
      "3. **快速原型开发**：需要快速验证想法\n",
      "4. **无状态应用**：每次请求独立，不需要维护状态\n",
      "\n",
      "### 使用 LangGraph 的场景\n",
      "1. **多智能体协作**：多个智能体需要协同工作\n",
      "2. **复杂决策流程**：需要条件分支和循环\n",
      "3. **有状态对话系统**：需要维护对话历史和上下文\n",
      "4. **工作流管理**：需要暂停、恢复、人工干预\n",
      "5. **游戏AI或模拟**：需要复杂的状态管理和决策树\n",
      "\n",
      "## 6. 技术实现差异\n",
      "\n",
      "### LangChain 实现方式\n",
      "```python\n",
      "# 典型的 LangChain 链\n",
      "chain = (\n",
      "    prompt_template \n",
      "    | llm \n",
      "    | output_parser\n",
      ")\n",
      "```\n",
      "\n",
      "### LangGraph 实现方式\n",
      "```python\n",
      "# 典型的 LangGraph 状态图\n",
      "from langgraph.graph import StateGraph, MessagesState\n",
      "\n",
      "graph_builder = StateGraph(MessagesState)\n",
      "\n",
      "# 定义节点\n",
      "graph_builder.add_node(\"node1\", node1_function)\n",
      "graph_builder.add_node(\"node2\", node2_function)\n",
      "\n",
      "# 定义边\n",
      "graph_builder.add_edge(\"node1\", \"node2\")\n",
      "graph_builder.set_entry_point(\"node1\")\n",
      "```\n",
      "\n",
      "## 7. 关系说明\n",
      "\n",
      "**重要**：LangGraph 和 LangChain 不是竞争对手，而是互补关系：\n",
      "\n",
      "1. **LangChain** 提供基础组件和 LCEL 编排\n",
      "2. **LangGraph** 在 LangChain 基础上扩展，处理更复杂的场景\n",
      "3. 两者可以无缝集成，LangGraph 并不强依赖于 LangChain\n",
      "\n",
      "## 8. 选择建议\n",
      "\n",
      "### 选择 LangChain 当：\n",
      "- 项目需要快速启动和原型验证\n",
      "- 工作流是线性的、无状态的\n",
      "- 主要使用 RAG 等常见模式\n",
      "- 不需要复杂的循环或分支逻辑\n",
      "\n",
      "### 选择 LangGraph 当：\n",
      "- 应用需要维护复杂状态\n",
      "- 需要多智能体协作\n",
      "- 工作流包含条件分支和循环\n",
      "- 需要人机协同或持久化功能\n",
      "- 应用规模超出线性模型的限制\n",
      "\n",
      "## 总结\n",
      "\n",
      "LangChain 是构建 LLM 应用的基础框架，适合大多数标准用例；而 LangGraph 是专门为处理有状态、复杂、多智能体场景而设计的扩展框架。两者都来自同一个团队，设计上相互补充，开发者可以根据具体需求选择合适的工具或组合使用两者。\n",
      "📊 [Token Usage] 输入: 4062, 输出: 87, 总计: 4149\n",
      "   缓存命中: 384 tokens\n",
      "📊 [Token Usage] 输入: 4319, 输出: 88, 总计: 4407\n",
      "   缓存命中: 2752 tokens\n",
      "📊 [Token Usage] 输入: 5509, 输出: 1243, 总计: 6752\n",
      "   缓存命中: 2752 tokens\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 8\n",
      "  successful_calls: 8\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1, 'query_retrieval_knowledge': 4, 'tavily_search': 3}\n",
      "  token_usage: {'total_input_tokens': 54262, 'total_output_tokens': 3273, 'total_tokens': 57535, 'cache_hit_tokens': 26560}\n",
      "  session_duration: 0:24:55.443572\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "✅ 普通 RAG 检索测试完成！\n",
      "======================================================================\n",
      "\n",
      "📊 中间件统计信息:\n",
      "\n",
      "======================================================================\n",
      "📊 Tool Call Statistics\n",
      "======================================================================\n",
      "  total_calls: 8\n",
      "  successful_calls: 8\n",
      "  failed_calls: 0\n",
      "  success_rate: 100.0%\n",
      "  tool_usage: {'query_sensitive_knowledge': 1, 'query_retrieval_knowledge': 4, 'tavily_search': 3}\n",
      "  token_usage: {'total_input_tokens': 54262, 'total_output_tokens': 3273, 'total_tokens': 57535, 'cache_hit_tokens': 26560}\n",
      "  session_duration: 0:24:55.448807\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_normal_rag_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 下面是通过LangSmith可视化调试的截图，可以清晰地看到Agent的运行状态和行为，包括状态的变化、工具的使用、模型的调用等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210130034612.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 也可以通过LangSmith可视化调试的截图，可以清晰地看到能将RAG检索到的文本块信息查询出来！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251211155958273.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 智能切换提示词中间件日志打印"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210175324959.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 上下文压缩中间件日志打印"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251211160005217.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第五阶段、LangSmith监控工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、 LangSmith核心概念详解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;大模型的行为往往存在不确定性，尤其在开发复杂的`AI Agent`应用程序时，过程中常包含众多子步骤。若希望掌握每一步的执行状态与结果，一方面可采用`Debug`方式实现实时控制，另一方面也可借助特定工具来观察和调试中间的交互流程。`Langsmith` 就是为应对这一挑战而设计的工具平台，由 `LangChain` 和 `LangGraph` 的团队创建。其核心目标是赋予LLM应用全面的可观测性，具体通过两大功能支柱实现：**一是提供覆盖全链路的跟踪、日志与实时分析能力；二是构建集成的监控与调试环境，让每一个中间步骤都清晰可见。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/image-20241022164041124.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Project** (项目)：蓝色方块代表整个项目，可能是一个单独的应用程序或服务。\n",
    "\n",
    "- **Traces** (轨迹)：绿色方块代表项目在不同条件或配置下的执行路径。每个轨迹可以是一个特定的用户会话、一个功能的执行，或者应用在特定输入下的行为。\n",
    "\n",
    "- **Runs** (运行)：每个轨迹下的黄色方块表示特定轨迹的单次执行。这些是执行的实例，每个实例都是轨迹在特定条件下的实际运行。\n",
    "\n",
    "- **Feedback, Tags, Metadata** (反馈、标签、元数据)：这部分显示了系统如何利用用户或自动化工具生成的反馈、标签和元数据来增强轨迹的管理和过滤。反馈可以用于改进未来的运行，标签和元数据可用于分类和筛选特定的轨迹或运行，以便在LangSmith的用户界面中更容易地管理和审查"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Trace（追踪）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一次完整应用执行的全链路记录，从用户输入到最终输出的整个调用树。它可视化LLM应用的执行路径，帮助开发者快速定位问题。\n",
    "\n",
    "   * 作用：提供端到端的可见性，捕获所有输入、输出和中间步骤，是调试和性能分析的基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210111225733.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangSmith可以追踪从用户输入到最终输出的完整流程，只要执行了invoke或者stream方法，就会自动记录一条Trace。包括：\n",
    "\n",
    "- Agent决策过程\n",
    "\n",
    "- 工具调用详情\n",
    "\n",
    "- LLM调用参数和响应\n",
    "\n",
    "- 检索结果质量\n",
    "\n",
    "- 执行耗时分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run（运行单元）、Feedback（反馈）、Metadata（元数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run：Trace中的单个执行节点，每个LLM调用、工具调用或函数执行都会生成一个Run，形成父子关系的树状结构。\n",
    "\n",
    "  - 作用：记录具体操作细节（如token消耗、延迟、参数）， granular 级别的监控和成本分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feedback：对单个Run的质量评估，包含标签（如\"answer_correctness\"）和分数（0-1或分类），可人工标注或自动计算。\n",
    "\n",
    "  - 作用：构建评估数据集，驱动持续优化。支持在线（实时用户反馈）和离线（批量评估）两种模式。\n",
    "\n",
    "  - **注意**：LangSmith不会自动生成Feedback，必须由开发者主动在代码中调用API显式创建反馈记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Metadata：附加在Run上的键值对信息（如{\"version\": \"v1.2\", \"env\": \"production\"}），用于标记运行环境、模型版本等。\n",
    "\n",
    "  - 作用：支持跨维度筛选、分组分析（如对比不同版本的性能差异）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210112202512.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 LangSmith配置步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Step 1. 创建一个 LangSmith 帐户**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T03:46:14.155911Z",
     "start_time": "2025-12-10T03:46:14.149631Z"
    }
   },
   "source": [
    "&emsp;&emsp;要开始使用 `LangSmith`，我们需要创建一个帐户。可以在这里注册一个免费帐户进入`LangSmith`登录页面： https://smith.langchain.com/， 支持使用 Google、GitHub、Discord 和电子邮件登录。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/image-20241022165215709.png\" width=40%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;注册并等登录后，可以直接查看到仪表板："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210114756767.png\" width=85%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在构建程序跟踪前，首先需要创建一个 `API` 密钥，该密钥将允许我们的项目开始向 `Langsmith` 发送跟踪数据，务必保存好api_key!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210115234152.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210115403568.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`LangSmith` 支持两种类型的 API 密钥：服务密钥和个人访问令牌。两种类型的令牌都可用于验证对 `LangSmith API` 的请求，但它们有不同的用例。这里选择“密钥类型令牌的个人访问” ，因为我们将使用此密钥作为用户进行个人访问。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210115758508.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;单击“创建 API 密钥” ，复制并确认已保存。这和`OpenAI`的`API`密钥一样，一旦创建完成，则不允许再次复制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210120021074.png\" width=60%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210120256273.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;现在，就可以将其集成到我们的项目中了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Step 3. 创建环境变量**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;将`LANGCHAIN_API_KEY`替换为我们刚刚创建的 `API` 密钥，或者直接放到.env文件中保存（**推荐**）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T04:55:03.519179Z",
     "start_time": "2025-12-10T04:55:03.516192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "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\n",
      "My_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# 设置LangSmith的API密钥\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "\n",
    "# 设置LangSmith的项目名称\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"My_project\"\n",
    "\n",
    "\n",
    "# 验证环境变量是否设置成功\n",
    "print(os.getenv(\"LANGCHAIN_TRACING_V2\"))\n",
    "print(os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "print(os.getenv(\"LANGSMITH_PROJECT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T04:55:29.437349Z",
     "start_time": "2025-12-10T04:55:05.451411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据搜索结果，2024年诺贝尔物理学奖得主是：\n",
      "\n",
      "## 2024年诺贝尔物理学奖得主\n",
      "\n",
      "**获奖者：**\n",
      "1. **约翰·霍普菲尔德（John J. Hopfield）** - 美国物理学家\n",
      "2. **杰弗里·辛顿（Geoffrey E. Hinton）** - 英国出生的加拿大计算机科学家\n",
      "\n",
      "## 获奖原因\n",
      "\n",
      "他们因**在人工神经网络实现机器学习方面的基础性发现和发明**而获奖。具体来说：\n",
      "\n",
      "- **约翰·霍普菲尔德**：开发了霍普菲尔德网络，这是一种基于物理学原理的神经网络模型\n",
      "- **杰弗里·辛顿**：被称为\"深度学习之父\"，在神经网络和机器学习领域做出了开创性贡献\n",
      "\n",
      "## 重要意义\n",
      "\n",
      "他们的工作：\n",
      "1. 为现代人工智能和机器学习技术奠定了基础\n",
      "2. 展示了如何从物理学中汲取灵感来解决计算问题\n",
      "3. 推动了人工神经网络的发展，这些技术现在被广泛应用于图像识别、自然语言处理等领域\n",
      "\n",
      "## 颁奖时间\n",
      "\n",
      "2024年诺贝尔物理学奖于**2024年10月8日**公布，颁奖典礼在斯德哥尔摩举行。\n",
      "\n",
      "这是一个相当有趣的奖项，因为它将物理学奖授予了在人工智能和机器学习领域做出基础性贡献的科学家，体现了跨学科研究的重要性。\n"
     ]
    }
   ],
   "source": [
    "# 1.导入相关库\n",
    "from langchain.agents import create_agent\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 2.导入模型和工具\n",
    "web_search = TavilySearch(max_results=2)\n",
    "\n",
    "# 3.创建模型\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\")\n",
    "\n",
    "# 4.创建Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[web_search],\n",
    "    system_prompt=\"你是一名多才多艺的智能助手，可以调用工具帮助用户解决问题。\"\n",
    ")\n",
    "\n",
    "# 5.运行Agent获得结果\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"请帮我查询2024年诺贝尔物理学奖得主是谁？\"}]}\n",
    ")\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210125640902.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 免费Developer Plan容量限制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于免费的**Developer Plan**，具体的容量限制如下：\n",
    "\n",
    "- **Trace 额度**：每月 **5,000 条 (5k)** 免费 Base Traces\n",
    "\n",
    "  - 注：如果绑定了信用卡，超过5000条后不会停止服务，而是自动按 $0.50/1k 条收费；未绑定信用卡则会停止接收新数据\n",
    "\n",
    "- **数据保留期 (Retention)**：默认为 **14天**\n",
    "\n",
    "  - 14天前的运行日志会被自动清除，除非手动将其添加到Dataset（数据集）中\n",
    "\n",
    "- **并发/速率限制**：\n",
    "\n",
    "  - 每小时最多接收 **500MB** 的数据包或 **50,000** 个事件，防止滥用\n",
    "\n",
    "- **席位限制**：仅限 **1** 个用户（不能邀请团队成员）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体费用查看，还是先进入到**settings**设置中，然后点击**Billing and usage**来进行查看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/ZhiJie/20251210102407004.png\" width=80%></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain]",
   "language": "python",
   "name": "conda-env-langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
