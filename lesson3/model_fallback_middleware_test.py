#%%
# ==================== ModelFallbackMiddleware å®Œæ•´å®ç° ====================

from langchain.agents import create_agent
from langchain.agents.middleware import ModelFallbackMiddleware
from langchain_core.messages import HumanMessage
from langchain_deepseek import ChatDeepSeek
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import logging
from model_factory import get_model
from langchain_core.runnables import ensure_config

# ==================== 1. é…ç½®æ—¥å¿— ====================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
load_dotenv(override=True)

# ==================== 2. å®šä¹‰å·¥å…· ====================
@tool
def calculate_sum(a: int, b: int) -> int:
    """è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ"""
    logger.info(f"calculate_sum è¢«è°ƒç”¨: {a} + {b}")
    return a + b

@tool
def get_system_info() -> str:
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    logger.info("get_system_info è¢«è°ƒç”¨")
    return "ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼ŒCPUä½¿ç”¨ç‡: 45%, å†…å­˜ä½¿ç”¨ç‡: 60%"

tools = [calculate_sum, get_system_info]

# ==================== 3. å®šä¹‰ä¸Šä¸‹æ–‡ ====================
class UserContext(BaseModel):
    user_id: str = Field(..., description="ç”¨æˆ·å”¯ä¸€æ ‡è¯†")

# ==================== 4. é…ç½®ä¸­é—´ä»¶ ====================
# é…ç½®æ¨¡å‹æ•…éšœè½¬ç§»ï¼šä¸»æ¨¡å‹ -> å¤‡ç”¨æ¨¡å‹1 -> å¤‡ç”¨æ¨¡å‹2
# æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ç›¸åŒçš„æ¨¡å‹ä½œä¸ºæ¼”ç¤ºï¼Œå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
fallback_middleware = ModelFallbackMiddleware(
    get_model("deepseek-r1:1.5b", "ollama"),  # ç¬¬ä¸€ä¸ªå¤‡ç”¨æ¨¡å‹
    get_model("qwen3:0.6b", "ollama"),    # ç¬¬äºŒä¸ªå¤‡ç”¨æ¨¡å‹
)

# ==================== 5. åˆ›å»º Agent ====================
agent = create_agent(
    model=get_model("qwen2.5:7b", "ollama"),  # ä¸»æ¨¡å‹
    tools=tools,
    middleware=[
        fallback_middleware,  # æ·»åŠ æ•…éšœè½¬ç§»ä¸­é—´ä»¶
    ],
    context_schema=UserContext,
    debug=False,
)

# ==================== 6. æ‰§è¡Œæµ‹è¯• ====================
def run_fallback_test():
    """
    æµ‹è¯• ModelFallbackMiddleware çš„æ•…éšœè½¬ç§»åŠŸèƒ½

    åœºæ™¯ï¼šæ­£å¸¸æƒ…å†µä¸‹ä½¿ç”¨ä¸»æ¨¡å‹ï¼Œæ¨¡æ‹Ÿæ•…éšœæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹
    """
    logger.info("å¼€å§‹ ModelFallbackMiddleware æµ‹è¯•")
    logger.info("é…ç½®: ä¸»æ¨¡å‹(qwen2.5) + 2ä¸ªå¤‡ç”¨æ¨¡å‹")

    # æµ‹è¯•åœºæ™¯1: æ­£å¸¸è°ƒç”¨ï¼ˆä¸»æ¨¡å‹æˆåŠŸï¼‰
    logger.info("\n" + "="*60)
    logger.info("åœºæ™¯1: æ­£å¸¸è°ƒç”¨ - ä¸»æ¨¡å‹åº”è¯¥æˆåŠŸå¤„ç†")
    logger.info("="*60)

    query1 = "è¯·è®¡ç®— 15 + 27 çš„ç»“æœ"
    logger.info(f"æŸ¥è¯¢: {query1}")

    try:
        result1 = agent.invoke(
            {"messages": [HumanMessage(content=query1)]},
            context=UserContext(user_id="user_fallback_test"),
            config=ensure_config({"configurable": {"thread_id": "session_fallback_001"}})
        )

        final_message = result1["messages"][-1]
        logger.info(f"âœ… åœºæ™¯1æˆåŠŸ: {final_message.content[:100]}...")

    except Exception as e:
        logger.error(f"âŒ åœºæ™¯1å¤±è´¥: {e}")

    # æµ‹è¯•åœºæ™¯2: å¤æ‚æŸ¥è¯¢
    logger.info("\n" + "="*60)
    logger.info("åœºæ™¯2: å¤æ‚æŸ¥è¯¢ - æµ‹è¯•æ¨¡å‹å¤„ç†èƒ½åŠ›")
    logger.info("="*60)

    query2 = "è¯·å…ˆè·å–ç³»ç»Ÿä¿¡æ¯ï¼Œç„¶åè®¡ç®— 100 + 200 çš„ç»“æœï¼Œæœ€åæ€»ç»“ä¸€ä¸‹"
    logger.info(f"æŸ¥è¯¢: {query2}")

    try:
        result2 = agent.invoke(
            {"messages": [HumanMessage(content=query2)]},
            context=UserContext(user_id="user_fallback_test"),
            config=ensure_config({"configurable": {"thread_id": "session_fallback_002"}})
        )

        final_message = result2["messages"][-1]
        logger.info(f"âœ… åœºæ™¯2æˆåŠŸ: {final_message.content[:100]}...")

    except Exception as e:
        logger.error(f"âŒ åœºæ™¯2å¤±è´¥: {e}")

    # è¾“å‡ºè¯´æ˜
    logger.info("\n" + "="*60)
    logger.info("æµ‹è¯•å®Œæˆ")
    logger.info("="*60)

    print("\n" + "="*60)
    print("ModelFallbackMiddleware å·¥ä½œåŸç†è¯´æ˜")
    print("="*60)
    print("1. ä¸»æ¨¡å‹: deepseek-chat (temperature=0.1)")
    print("2. å¤‡ç”¨æ¨¡å‹1: deepseek-reasoner (temperature=0.3)")
    print("3. å¤‡ç”¨æ¨¡å‹2: deepseek-chat (temperature=0.5)")
    print("4. å½“ä¸»æ¨¡å‹è°ƒç”¨å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å°è¯•å¤‡ç”¨æ¨¡å‹1")
    print("5. å¦‚æœå¤‡ç”¨æ¨¡å‹1ä¹Ÿå¤±è´¥ï¼Œç»§ç»­å°è¯•å¤‡ç”¨æ¨¡å‹2")
    print("6. è¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ¨¡å‹å“åº”")
    print("7. å®é™…åº”ç”¨ä¸­åº”é…ç½®ä¸åŒçš„æ¨¡å‹æä¾›å•†ï¼ˆå¦‚ OpenAI, Anthropic ç­‰ï¼‰")
    print("="*60 + "\n")

    print("\nğŸ’¡ æç¤ºï¼š")
    print("åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå»ºè®®é…ç½®ä¸åŒæä¾›å•†çš„æ¨¡å‹ï¼Œä¾‹å¦‚ï¼š")
    print("  ä¸»æ¨¡å‹: openai:gpt-4o")
    print("  å¤‡ç”¨1: anthropic:claude-sonnet-4-5-20250929")
    print("  å¤‡ç”¨2: deepseek:deepseek-chat")
    print("è¿™æ ·å¯ä»¥åœ¨æŸä¸ªæä¾›å•†æœåŠ¡ä¸­æ–­æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…¶ä»–æä¾›å•†ã€‚\n")

# ==================== 7. è¿è¡Œæµ‹è¯• ====================
run_fallback_test()