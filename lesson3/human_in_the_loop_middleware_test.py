import os
from dotenv import load_dotenv
from langchain_deepseek import ChatDeepSeek
from langchain.agents import create_agent
from langchain.agents.middleware import HumanInTheLoopMiddleware
from langchain.agents.middleware.human_in_the_loop import (
    HITLResponse,
    ApproveDecision,
    EditDecision,
    RejectDecision
)
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from langgraph.types import Command
from model_factory import get_model
from langgraph.checkpoint.memory import MemorySaver

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# ---------------------------------------------------------------------------
# 2. å®šä¹‰å·¥å…· (Tools)
# ---------------------------------------------------------------------------
class SendEmailSchema(BaseModel):
    recipient: str = Field(description="é‚®ä»¶æ¥æ”¶è€…çš„é‚®ç®±åœ°å€")
    subject: str = Field(description="é‚®ä»¶ä¸»é¢˜")
    body: str = Field(description="é‚®ä»¶æ­£æ–‡å†…å®¹")

@tool(args_schema=SendEmailSchema)
def send_email(recipient: str, subject: str, body: str):
    """æ¨¡æ‹Ÿå‘é€é‚®ä»¶çš„å·¥å…·"""
    print(f"\n======== [SYSTEM ACTION: æ­£åœ¨æ‰§è¡Œå‘é€é‚®ä»¶] ========")
    print(f"æ”¶ä»¶äºº: {recipient}")
    print(f"ä¸»é¢˜  : {subject}")
    print(f"å†…å®¹  : {body}")
    print(f"================================================\n")
    return f"é‚®ä»¶å·²æˆåŠŸå‘é€ç»™ {recipient}"

tools = [send_email]

model = get_model("qwen2.5:7b", "ollama")

system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡Œæ”¿åŠ©æ‰‹ã€‚
å½“ç”¨æˆ·è¯·æ±‚å‘é€é‚®ä»¶æ—¶ï¼Œä½ å¿…é¡»ç›´æ¥è°ƒç”¨ `send_email` å·¥å…·ã€‚
ä¸è¦é—®ä»»ä½•åç»­é—®é¢˜ï¼Œä¸è¦è¦æ±‚ç¡®è®¤ï¼Œç›´æ¥ç”Ÿæˆå·¥å…·è°ƒç”¨ã€‚
"""

hitl_middleware = HumanInTheLoopMiddleware(
    interrupt_on={"send_email": True},
    description_prefix="éœ€è¦äººå·¥æ‰¹å‡†æ‰èƒ½å‘é€é‚®ä»¶"
)

graph = create_agent(
    model=model,
    tools=tools,
    system_prompt=system_prompt,
    middleware=[hitl_middleware]
)

def run_interactive_session():
    local_graph = create_agent(
        model = model,
        tools = tools,
        system_prompt = system_prompt,
        middleware = [hitl_middleware],
        checkpointer = MemorySaver()  # æœ¬åœ°è¿è¡Œéœ€è¦
    )

    thread_id = "demo_thread_middleware_1"
    config = {"configurable": {"thread_id": thread_id}}

    user_input = "å¸®æˆ‘ç»™ hr@example.com å‘ä¸€å°é‚®ä»¶ï¼Œä¸»é¢˜æ˜¯'ä¼‘å‡ç”³è¯·'ï¼Œå†…å®¹æ˜¯æˆ‘ä¸‹å‘¨ä¸€æƒ³è¯·å‡ä¸€å¤©ã€‚"
    print(f"\n[ç”¨æˆ·]: {user_input}")
    # === ç¬¬ä¸€æ­¥ï¼šåˆå§‹æ‰§è¡Œ ===
    print("\n[ç³»ç»Ÿ]: å¼€å§‹å¤„ç†è¯·æ±‚...")
    # input ä¼ å…¥ç”¨æˆ·æ¶ˆæ¯
    # stream_mode="values" å¯ä»¥è®©æˆ‘ä»¬çœ‹åˆ°æ¶ˆæ¯æµ
    for event in local_graph.stream(
            {"messages": [{"role": "user", "content": user_input}]},
            config = config,
            stream_mode = "values"
    ):
        # ç®€å•æ‰“å°æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
        if "messages" in event:
            last_msg = event["messages"][-1]
            if last_msg.type == "ai" and last_msg.tool_calls:
                print(f"[AI æ€è€ƒ]: å†³å®šè°ƒç”¨å·¥å…· -> {last_msg.tool_calls[0]['name']}")

    # === ç¬¬äºŒæ­¥ï¼šè§‚å¯Ÿ (Observation) ===
    # ä¸­é—´ä»¶åº”è¯¥è§¦å‘äº†ä¸­æ–­
    snapshot = local_graph.get_state(config)

    print(f"\n--- ğŸ›‘ æ‰§è¡Œå·²æš‚åœ (HITL Middleware) ---")
    print(f"ä¸‹ä¸€æ­¥éª¤ (Next): {snapshot.next}")
    print(f"ä»»åŠ¡æ•°é‡: {len(snapshot.tasks) if snapshot.tasks else 0}")

    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡ï¼ˆè¿™è¡¨ç¤ºä¸­æ–­å‘ç”Ÿï¼‰
    if snapshot.tasks:
        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯
        last_message = snapshot.values["messages"][-1]

        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            tool_call = last_message.tool_calls[0]
            print(f"\n[å¾…å®¡æ‰¹æ“ä½œ]:")
            print(f"  - å·¥å…·: {tool_call['name']}")
            print(f"  - å‚æ•°: {tool_call['args']}")

            # === ç¬¬ä¸‰æ­¥ï¼šäººå·¥ä»‹å…¥ (Human Input) ===
            approval = input("\n[ç®¡ç†å‘˜]: æ˜¯å¦æ‰¹å‡†æ‰§è¡Œæ­¤æ“ä½œ? (y/n/e[ç¼–è¾‘]): ")

            if approval.lower() == 'y':
                # === ç¬¬å››æ­¥ï¼šæ¢å¤æ‰§è¡Œ (Resume) - æ‰¹å‡† ===
                print("\n[ç³»ç»Ÿ]: æ“ä½œå·²æ‰¹å‡†ï¼Œç»§ç»­æ‰§è¡Œ...")

                # åˆ›å»º HITLResponse å¯¹è±¡ï¼ŒåŒ…å« ApproveDecision
                hitl_response = HITLResponse(
                    decisions = [ApproveDecision(type = "approve")]
                )

                # ä½¿ç”¨ Command(resume=hitl_response) æ¥æ‰¹å‡†å¹¶ç»§ç»­æ‰§è¡Œ
                for event in local_graph.stream(
                        Command(resume = hitl_response),  # ä¼ å…¥ HITLResponse å¯¹è±¡
                        config = config,
                        stream_mode = "values"
                ):
                    if "messages" in event:
                        last_msg = event["messages"][-1]
                        if last_msg.type == "tool":
                            print(f"[å·¥å…·è¾“å‡º]: {last_msg.content}")
                        elif last_msg.type == "ai" and last_msg.content:
                            print(f"[AI å›å¤]: {last_msg.content}")

            elif approval.lower() == 'e':
                # === ç¼–è¾‘å·¥å…·è°ƒç”¨å‚æ•° ===
                print("\n[ç³»ç»Ÿ]: ç¼–è¾‘æ¨¡å¼...")
                print(f"å½“å‰å‚æ•°: {tool_call['args']}")

                # è®©ç”¨æˆ·ç¼–è¾‘å‚æ•°
                new_recipient = input(
                    f"æ–°æ”¶ä»¶äºº (å½“å‰: {tool_call['args'].get('recipient', '')}ï¼Œç•™ç©ºä¿æŒä¸å˜): ").strip()
                new_subject = input(
                    f"æ–°ä¸»é¢˜ (å½“å‰: {tool_call['args'].get('subject', '')}ï¼Œç•™ç©ºä¿æŒä¸å˜): ").strip()
                new_body = input(
                    f"æ–°å†…å®¹ (å½“å‰: {tool_call['args'].get('body', '')}ï¼Œç•™ç©ºä¿æŒä¸å˜): ").strip()

                # æ„å»ºæ–°çš„å‚æ•°
                updated_args = tool_call['args'].copy()
                if new_recipient:
                    updated_args['recipient'] = new_recipient
                if new_subject:
                    updated_args['subject'] = new_subject
                if new_body:
                    updated_args['body'] = new_body

                print(f"\n[ç³»ç»Ÿ]: ä½¿ç”¨æ›´æ–°åçš„å‚æ•°ç»§ç»­æ‰§è¡Œ...")
                print(f"æ›´æ–°åçš„å‚æ•°: {updated_args}")

                # åˆ›å»º HITLResponse å¯¹è±¡ï¼ŒåŒ…å« EditDecision
                # EditDecision éœ€è¦ edited_actionï¼ŒåŒ…å« name å’Œ args
                hitl_response = HITLResponse(
                    decisions = [EditDecision(
                        type = "edit",
                        edited_action = {
                            "name": tool_call['name'],
                            "args": updated_args
                        }
                    )]
                )

                # ä½¿ç”¨ Command(resume=hitl_response) æ¥æ‰¹å‡†å¹¶ä½¿ç”¨æ–°å‚æ•°
                for event in local_graph.stream(
                        Command(resume = hitl_response),  # ä¼ å…¥åŒ…å«ç¼–è¾‘å†³ç­–çš„ HITLResponse
                        config = config,
                        stream_mode = "values"
                ):
                    if "messages" in event:
                        last_msg = event["messages"][-1]
                        if last_msg.type == "tool":
                            print(f"[å·¥å…·è¾“å‡º]: {last_msg.content}")
                        elif last_msg.type == "ai" and last_msg.content:
                            print(f"[AI å›å¤]: {last_msg.content}")

            else:
                # === æ‹’ç»æ“ä½œ ===
                print("\n[ç³»ç»Ÿ]: æ“ä½œè¢«æ‹’ç»ã€‚")

                # åˆ›å»º HITLResponse å¯¹è±¡ï¼ŒåŒ…å« RejectDecision
                rejection_reason = input("æ‹’ç»åŸå›  (å¯é€‰): ").strip() or "æ“ä½œè¢«ç®¡ç†å‘˜æ‹’ç»"

                hitl_response = HITLResponse(
                    decisions = [RejectDecision(
                        type = "reject",
                        message = rejection_reason
                    )]
                )

                # ä½¿ç”¨ Command(resume=hitl_response) æ¥æ‹’ç»
                for event in local_graph.stream(
                        Command(resume = hitl_response),  # ä¼ å…¥åŒ…å«æ‹’ç»å†³ç­–çš„ HITLResponse
                        config = config,
                        stream_mode = "values"
                ):
                    if "messages" in event:
                        last_msg = event["messages"][-1]
                        if last_msg.type == "ai" and last_msg.content:
                            print(f"[AI å›å¤]: {last_msg.content}")
                        elif last_msg.type == "tool":
                            print(f"[å·¥å…·æ¶ˆæ¯]: {last_msg.content}")

                print("[ç³»ç»Ÿ]: æµç¨‹å·²ç»ˆæ­¢ã€‚")
        else:
            print("æ²¡æœ‰æ£€æµ‹åˆ°å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨ã€‚")
    else:
        print("æµç¨‹å·²å®Œæˆï¼Œæ²¡æœ‰è§¦å‘ä¸­æ–­ã€‚")
        # æ‰“å°æœ€ç»ˆç»“æœ
        if snapshot.values.get("messages"):
            last_msg = snapshot.values["messages"][-1]
            if last_msg.type == "ai" and last_msg.content:
                print(f"\n[æœ€ç»ˆå›å¤]: {last_msg.content}")

run_interactive_session()