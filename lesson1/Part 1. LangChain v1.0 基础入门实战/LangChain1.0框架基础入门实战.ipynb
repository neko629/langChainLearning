{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509cd332-63b2-4aaf-8cf2-098df3639656",
   "metadata": {},
   "source": [
    "# <center>LangChain 1.0 æ¡†æ¶åŸºç¡€å…¥é—¨å®æˆ˜</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a30c45c-25cf-4a3e-8368-f73208b27ffd",
   "metadata": {},
   "source": [
    "## <center>ç¬¬ä¸€é˜¶æ®µã€LangChain æ¡†æ¶ä»‹ç»</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b9d28-6317-47de-a9e5-68497b1d17c7",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangChain æ˜¯ä¸€ä¸ª**æ„å»º LLM åº”ç”¨çš„æ¡†æ¶**ï¼Œç›®æ ‡æ˜¯æŠŠ LLM ä¸å¤–éƒ¨å·¥å…·ã€æ•°æ®æºå’Œå¤æ‚å·¥ä½œæµè¿æ¥èµ·æ¥ â€”â€” æ”¯æŒä»ç®€å•çš„ prompt å°è£…åˆ°å¤æ‚çš„ Agentï¼ˆèƒ½å¤Ÿè°ƒç”¨å·¥å…·ã€åšå†³ç­–ã€æ‰§è¡Œå¤šæ­¥ä»»åŠ¡ï¼‰ã€‚å®ƒä¸ä»…ä»…æ˜¯å¯¹LLM APIçš„å°è£…ï¼Œè€Œæ˜¯æä¾›äº†ä¸€å¥—å®Œæ•´çš„å·¥å…·å’Œæ¶æ„ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿæ›´è½»æ¾åœ°æ„å»º**ä¸Šä¸‹æ–‡æ„ŸçŸ¥**å’Œ**å…·å¤‡æ¨ç†èƒ½åŠ›**çš„AIåº”ç”¨ã€‚LangChain 1.0 ç‰ˆæœ¬æŠŠâ€œAgent çš„ç¨³å®šåŒ–ã€ç»“æ„åŒ–è¾“å‡ºã€å¯è§‚æµ‹æ€§ä¸ç”Ÿäº§åŒ–â€ä½œä¸ºæ ¸å¿ƒæ”¹è¿›ç›®æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85e0e0-90a0-4ec1-b7dc-23892d841b4c",
   "metadata": {},
   "source": [
    "### 1.1 ç”¨ LangChain èƒ½åšä»€ä¹ˆï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3376b8-9496-4bc8-95bf-bd34643616e3",
   "metadata": {},
   "source": [
    "\n",
    "- æ„å»º Retrieval-Augmented Generationï¼ˆRAGï¼‰é—®ç­”ç³»ç»Ÿ\n",
    "\n",
    "- æŠŠ LLM å½“ä½œâ€œAgentâ€å»è°ƒç”¨å¤–éƒ¨ APIï¼ˆæœç´¢ã€æ•°æ®åº“ã€æ–‡ä»¶ç³»ç»Ÿï¼‰å¹¶è¿”å›ä»»åŠ¡ç»“æœ\n",
    "\n",
    "- ç»„ç»‡ prompt â†’ æ¨¡å‹ â†’ åå¤„ç† çš„å¯å¤ç”¨æµæ°´çº¿ï¼ˆChainsï¼‰\n",
    "\n",
    "- å®ç°å¤šè½®å¯¹è¯å¸¦è®°å¿†ï¼ˆMemoryï¼‰ä¸é•¿ä¼šè¯ç®¡ç†\n",
    "\n",
    "- åœ¨ç”Ÿäº§ä¸­ç®¡ç†å¯è§‚æµ‹æ€§ä¸è¯„ä¼°ï¼ˆé…åˆ LangSmith/LangGraphï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2383e-bf33-4e63-a63a-ca8277be9f3c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**æ ¸å¿ƒä»·å€¼**ï¼šè®©å¼€å‘è€…ç”¨**10è¡Œä»£ç **å®ŒæˆåŸæœ¬éœ€è¦1000è¡Œä»£ç çš„AIåº”ç”¨ï¼Œå¹¶ä¸”è‡ªåŠ¨è·å¾—**çŠ¶æ€æŒä¹…åŒ–ã€äººå·¥å¹²é¢„ã€å¹¶å‘æ§åˆ¶**ç­‰ä¼ä¸šçº§èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11a4d2-5882-4afc-be2b-43c2bd0a9cc5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;1.0 çš„æ¶æ„é£æ ¼å¯ä»¥ç”¨ä¸€å¥è¯æ¦‚æ‹¬:ä»¥â€œ**ç»Ÿä¸€æ™ºèƒ½ä½“æŠ½è±¡ + æ ‡å‡†åŒ–å†…å®¹è¡¨ç¤º + å¯æ’æ‹”æ²»ç†ä¸­é—´ä»¶**â€ä¸ºè®¾è®¡éª¨å¹²,ä»¥ LangGraph ä¸ºåº•åº§è¿è¡Œæ—¶,å®ç°â€œå¼€å‘ç®€å•æ€§â€ä¸â€œç”Ÿäº§å¯æ§æ€§â€çš„å…¼é¡¾ã€‚å®ƒä¸€æ–¹é¢é€šè¿‡ create_agent æä¾›ä½é—¨æ§›çš„æ„å»ºå…¥å£,å¦ä¸€æ–¹é¢ä¿ç•™è¶³å¤Ÿçš„é’©å­ç‚¹ä¸ä¸‹æ¢èƒ½åŠ›,ä»¥æ»¡è¶³å¤æ‚å·¥ä½œæµä¸é«˜æ ‡å‡†æ²»ç†çš„éœ€æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34428396-0c7c-4e64-88ba-e9f20ffb03d8",
   "metadata": {},
   "source": [
    "```plain\n",
    "ä½ è¦åšä»€ä¹ˆAIåº”ç”¨ï¼Ÿ\n",
    "â”‚\n",
    "â”œâ”€ åªæƒ³ç®€å•è°ƒç”¨æ¨¡å‹èŠå¤©ï¼ˆç¿»è¯‘/é—®ç­”ï¼‰\n",
    "â”‚   â””â”€> ç›´æ¥ç”¨OpenAI SDKï¼ˆæ›´è½»é‡ï¼Œæ— éœ€LangChainï¼‰\n",
    "â”‚\n",
    "â”œâ”€ éœ€è¦è”ç½‘æŸ¥èµ„æ–™ã€æ‰§è¡Œä»£ç ã€æ“ä½œæ•°æ®åº“\n",
    "â”‚   â””â”€> ç”¨LangChain 1.0ï¼ˆå¿«é€Ÿæ­å»ºAgentï¼‰\n",
    "â”‚       â””â”€> å‚è€ƒï¼šå®¢æœæœºå™¨äººã€æ•°æ®åˆ†æåŠ©æ‰‹\n",
    "â”‚\n",
    "â”œâ”€ æµç¨‹å¾ˆå¤æ‚ï¼ˆå¤šäººå®¡æ‰¹/å®šæ—¶ä»»åŠ¡/çŠ¶æ€åˆ†æ”¯ï¼‰\n",
    "â”‚   â””â”€> ç”¨LangGraph 1.0ï¼ˆç²¾ç¡®æ§åˆ¶æ¯ä¸ªæ­¥éª¤ï¼‰\n",
    "â”‚       â””â”€> å‚è€ƒï¼šè‡ªåŠ¨åŒ–å·¥ä½œæµã€ERPç³»ç»Ÿé›†æˆ\n",
    "â”‚\n",
    "â””â”€ ä¸ç¡®å®šï¼Œå…ˆè¯•è¯•æƒ³æ³•\n",
    "    â””â”€> ç”¨LangChain 1.0å¿«é€ŸéªŒè¯ï¼ŒåæœŸå¯æ— ç¼è¿ç§»åˆ°LangGraph\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123baf16-c0e2-4f08-971f-2585c90fe03e",
   "metadata": {},
   "source": [
    "### 1.2 LangChain ç”Ÿæ€æ¦‚è§ˆ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ff815-ee03-40f8-8740-140f9241b2c7",
   "metadata": {},
   "source": [
    "#### æ¨¡å‹å±‚ï¼ˆModelsï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15d72f-6df1-45fb-bf72-c869b373c8a1",
   "metadata": {},
   "source": [
    "LangChain 1.0 çš„ç»Ÿä¸€æ¨¡å‹æŠ½è±¡å±‚ï¼Œä¸ºæ‰€æœ‰æ¨¡å‹æä¾›æ ‡å‡†åŒ–è°ƒç”¨ï¼Œè¦†ç›–æ–‡æœ¬ã€å¤šæ¨¡æ€ã€Embeddingã€Rerank ç­‰å¤šç±»å‹æ¨¡å‹ï¼Œå®ç°è·¨ä¾›åº”å•†ä¸€è‡´ä½“éªŒ\n",
    "\n",
    "- ç»Ÿä¸€æŠ½è±¡ï¼šinit_chat_model() é€‚é…20+æ¨¡å‹å‚å•†\n",
    "\n",
    "- å¼‚æ­¥/æµå¼/æ‰¹å¤„ç†ï¼šainvoke()ï¼Œstream(), batch()\n",
    "\n",
    "- æ‰§è¡Œæ–¹å¼ï¼šå®Œå…¨å…¼å®¹ LCEL ä¸ LangGraph\n",
    "\n",
    "- æ‰©å±•èƒ½åŠ›ï¼šwith_structured_output()ã€Tool Callingã€å¤šæ¨¡æ€ Content Blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744781b-ca57-4741-b47d-62e69431c7df",
   "metadata": {},
   "source": [
    "#### å·¥å…·å±‚ï¼ˆToolsï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e078c4e-a8b0-47a0-be32-e066df2d74db",
   "metadata": {},
   "source": [
    "å·¥å…·ç³»ç»Ÿæä¾›ç»Ÿä¸€ Tool æŠ½è±¡ï¼Œæ”¯æŒæ‰€æœ‰ä¸»æµæ¨¡å‹çš„ Tool Callingï¼Œæ·±åº¦é›†æˆ LangGraphï¼Œæ„å»ºå¯æ‰§è¡Œ agent ç¯å¢ƒçš„å…³é”®èƒ½åŠ›å±‚\n",
    "\n",
    "- å†…ç½®å·¥å…·ï¼šæœç´¢ã€è®¡ç®—ã€ä»£ç æ‰§è¡Œç­‰100+å·¥å…·\n",
    "\n",
    "- è‡ªå®šä¹‰å·¥å…·ï¼š@toolè£…é¥°å™¨ / BaseTool / ToolNode\n",
    "\n",
    "- å·¥å…·åŒ…ï¼šToolkitï¼ˆå¦‚GitHubã€Slacké›†æˆï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285b35f-e379-4482-9ac6-bc321f481211",
   "metadata": {},
   "source": [
    "#### è®°å¿†å±‚ï¼ˆMemoryï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf500f4c-b19f-4a0c-a922-6efd90d84459",
   "metadata": {},
   "source": [
    "è®°å¿†å±‚æä¾›ç»Ÿä¸€ State ç®¡ç†ã€å¯¹è¯è®°å½•ã€é•¿æœŸæ£€ç´¢ã€å¤šæ¨¡æ€ Memory ç­‰èƒ½åŠ›ï¼Œæ”¯æŒæŒä¹…åŒ–ä¸å¤æ‚å·¥ä½œæµçŠ¶æ€æµè½¬\n",
    "\n",
    "- çŸ­æœŸè®°å¿†ï¼šæ¶ˆæ¯å†å²è‡ªåŠ¨ç®¡ç† \n",
    "\n",
    "- é•¿æœŸè®°å¿†ï¼šå‘é‡æ•°æ®åº“å­˜å‚¨ï¼ˆChroma, Pineconeï¼‰\n",
    "\n",
    "- å­˜å‚¨æ¥å£ï¼šStoreï¼ˆè·¨ä¼šè¯æŒä¹…åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e6e6b-951e-498e-b108-427543418728",
   "metadata": {},
   "source": [
    "#### Agentå±‚ï¼ˆAgentsï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06299b5-7714-4c8c-a5a5-71cc2b53eff1",
   "metadata": {},
   "source": [
    "LangChain 1.0 Agentsç³»ç»Ÿå®ç°ä»ç¢ç‰‡åŒ–åˆ°æ ‡å‡†åŒ–å‡çº§ï¼Œä»¥create_agentä¸ºæ ¸å¿ƒæ¥å£ï¼ŒåŸºäºLangGraphæ„å»ºç»Ÿä¸€AgentæŠ½è±¡ï¼Œ10è¡Œä»£ç å³å¯åˆ›å»ºåŸºç¡€Agentï¼Œå°è£…\"æ¨¡å‹è°ƒç”¨â†’å·¥å…·é€‰æ‹©â†’æ‰§è¡Œâ†’ç»“æŸ\"é—­ç¯æµç¨‹\n",
    "\n",
    "- æ ¸å¿ƒAPIï¼šcreate_agent() \n",
    "\n",
    "- æ‰§è¡Œå¼•æ“ï¼šLangGraph Runtimeï¼ˆè‡ªåŠ¨æŒä¹…åŒ–ï¼‰\n",
    "\n",
    "- ä¸­é—´ä»¶ï¼šMiddlewareï¼ˆHITLã€å‹ç¼©ã€è·¯ç”±ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783536ff-85b5-4abd-ac0a-eb85c1329bc3",
   "metadata": {},
   "source": [
    "#### å·¥ä½œæµå±‚ï¼ˆWorkflowsï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92188cf5-6c0e-4d4e-b72c-998a3fcc4cab",
   "metadata": {},
   "source": [
    "Workflows ä½“ç³»å®ç°ä» çº¿æ€§é“¾å¼ï¼ˆChainï¼‰åˆ°å›¾ç»“æ„ï¼ˆGraphï¼‰ çš„èŒƒå¼è½¬ç§»ï¼Œä»¥ StateGraph ä¸ºæ ¸å¿ƒç”»å¸ƒï¼Œå°†ä¸šåŠ¡é€»è¾‘è§£è€¦ä¸º \"èŠ‚ç‚¹ï¼ˆNodeï¼‰+ è¾¹ï¼ˆEdgeï¼‰+ çŠ¶æ€ï¼ˆStateï¼‰\"ï¼ŒåŸç”Ÿæ”¯æŒå¾ªç¯ï¼ˆLoopï¼‰ä¸æ¡ä»¶åˆ†æ”¯ï¼Œå®Œç¾é€‚é…å¤æ‚ä»»åŠ¡ç¼–æ’ã€å®¹é”™é‡è¯•åŠé•¿ä¼šè¯ä¿æŒã€‚\n",
    "\n",
    "- ç®€å•é“¾ï¼šChainï¼ˆå¿«é€Ÿä¸²è”ï¼‰\n",
    "\n",
    "- å¤æ‚å›¾ï¼šLangGraphï¼ˆæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ï¼‰\n",
    "\n",
    "- æ¨¡æ¿åº“ï¼šLangChain Hubï¼ˆå…±äº«Agentæ¨¡æ¿ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c81fa7-c764-436c-86fe-1d7b5a129ebc",
   "metadata": {},
   "source": [
    "#### è°ƒè¯•ç›‘æ§å±‚ï¼ˆDebuggingï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14536063-03b1-4a0f-be1e-746bac0e4e92",
   "metadata": {},
   "source": [
    "LangChain 1.0 è°ƒè¯•ç›‘æ§å±‚å®ç°äº†ä» æ—¥å¿—é»‘ç›’åˆ°å…¨é“¾è·¯å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰ çš„è´¨å˜ï¼Œæ·±åº¦é›†æˆ LangSmith å¹³å°ï¼Œè‡ªåŠ¨æ•è·é“¾ï¼ˆChainï¼‰ä¸å›¾ï¼ˆGraphï¼‰çš„æ¯ä¸€æ­¥éª¤çŠ¶æ€ã€Token æ¶ˆè€—åŠå»¶è¿Ÿï¼Œæ”¯æŒ\"Trace â†’ Playground\"ä¸€é”®å›æ”¾è°ƒè¯•ï¼Œå½»åº•è§£å†³å¤æ‚ Agent é€»è¾‘éš¾ä»¥æ’æŸ¥çš„ç—›ç‚¹ã€‚\n",
    "\n",
    "- æœ¬åœ°æ—¥å¿—ï¼šverbose=True\n",
    "\n",
    "- äº‘ç«¯å¹³å°ï¼šLangSmithï¼ˆå¯è§†åŒ–é“¾è·¯è¿½è¸ªï¼‰\n",
    "\n",
    "- è¯„ä¼°å·¥å…·ï¼šLangChain Evaluateï¼ˆæ•ˆæœè¯„ä¼°ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b131ec-9f57-4559-afcf-7cab491253ed",
   "metadata": {},
   "source": [
    "#### å…¶ä»–å…³é”®ç»„ä»¶ (LangGraph & LangServe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea52973-0ebb-4573-be91-2f00dd67a348",
   "metadata": {},
   "source": [
    "- **langgraph**: è¿™æ˜¯ä¸€ä¸ªåº•å±‚çš„**Agent è°ƒåº¦æ¡†æ¶** (Agent Runtime)ï¼Œæ˜¯ä¸€ä¸ªç›¸å¯¹â€œä½çº§â€ï¼ˆLow-levelï¼‰çš„ç¼–æ’æ¡†æ¶ï¼Œå®ƒä¸“æ³¨äºè§£å†³å¤æ‚çš„â€œæ§åˆ¶æµâ€é—®é¢˜ï¼Œç”¨äºæ„å»ºå¥å£®ä¸”æœ‰çŠ¶æ€çš„å¤šè§’è‰² LLM åº”ç”¨ç¨‹åºã€‚LangChain 1.0 ä¸­çš„æ–° Agents (é€šè¿‡ create_agent()) å°±æ˜¯å»ºç«‹åœ¨ LangGraph ä¹‹ä¸Šçš„ã€‚\n",
    "\n",
    "- **langserve**: ç”¨äºå°†ä»»ä½• LangChain chain æˆ– agent **éƒ¨ç½²ä¸º REST API** çš„åŒ…ï¼Œæ–¹ä¾¿å¿«é€Ÿå°†åº”ç”¨æŠ•å…¥ç”Ÿäº§ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711204c-cdf7-4065-b9fc-00be6665063e",
   "metadata": {},
   "source": [
    "### 1.3 LangChain 1.0 åº•å±‚è¿è¡Œæ¶æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140b9eb-e5a5-40d5-b4d8-b575022435fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç®€åŒ–ç‰ˆæ¶æ„ç¤ºæ„å›¾\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        LangChain 1.0 åº”ç”¨å±‚              â”‚\n",
    "â”‚  (create_agent, å·¥å…·å’Œä¸­é—´ä»¶)            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚\n",
    "                   â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        LangGraph ç¼–æ’å±‚                  â”‚\n",
    "â”‚  (StateGraph, Nodes, Edges, Checkpoints)â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚\n",
    "                   â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        LCEL è¿è¡Œæ—¶å±‚                     â”‚\n",
    "â”‚  (Runnableæ¥å£, |è¿ç®—ç¬¦, æµå¼/æ‰¹å¤„ç†)    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â”‚\n",
    "                   â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        å¤§è¯­è¨€æ¨¡å‹API(OpenAI/DeepSeek)    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858900d5-8bfd-4ea5-809f-afc24f7f1f64",
   "metadata": {},
   "source": [
    "* LCELï¼šæä¾›Runnableæ¥å£ï¼ˆinvoke, stream, batchï¼‰å’Œç»„åˆåŸè¯­ï¼ˆ|è¿ç®—ç¬¦ï¼‰ï¼Œæ˜¯æ— çŠ¶æ€çš„å‡½æ•°å¼ç¼–æ’ï¼Œæ„å»ºâ€œæµæ°´çº¿ï¼ˆpipelineï¼‰â€çš„å·¥å…·\n",
    "\n",
    "* LangGraphï¼šåœ¨LCELåŸºç¡€ä¸Šå¢åŠ çŠ¶æ€ç®¡ç†ï¼ˆStateï¼‰ã€å¾ªç¯æ§åˆ¶ï¼ˆCyclesï¼‰ã€æŒä¹…åŒ–ï¼ˆCheckpointsï¼‰ï¼Œæ˜¯æœ‰çŠ¶æ€çš„å›¾ç»“æ„ç¼–æ’ï¼Œæ„å»ºâ€œæµç¨‹å›¾ï¼ˆworkflow/graphï¼‰â€çš„å·¥å…·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380afef-0623-4419-8e64-331685087f9a",
   "metadata": {},
   "source": [
    "### 1.4 Runnableåº•å±‚æ‰§è¡Œå¼•æ“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a05c5d-9301-4a73-abde-66f77da8f241",
   "metadata": {},
   "source": [
    "Runnable æ˜¯ LangChain 1.0 çš„â€œç»Ÿä¸€æ¥å£æ ‡å‡†â€ï¼Œä»»ä½•å¯ä»¥è¿è¡Œçš„ç»„ä»¶â€”â€”æ¨¡å‹ã€Promptã€å·¥å…·ã€è§£æå™¨ã€Memoryã€Graph èŠ‚ç‚¹â€”â€”åœ¨ 1.0 ä¸­éƒ½è¢«æŠ½è±¡ä¸º Runnableã€‚\n",
    "\n",
    "Runnable ä½¿æ‰€æœ‰ LangChain ç»„ä»¶èƒ½å¤Ÿä»¥ç»Ÿä¸€æ¥å£ç»„åˆã€æ‰§è¡Œã€é“¾å¼è°ƒç”¨ï¼Œå¹¶æ”¯æ’‘ LCELï¼ˆLangChain Expression Languageï¼‰çš„æ•´ä¸ªè¿è¡Œè¯­ä¹‰ï¼Œæ”¯æ’‘å¯ç»„åˆã€å¯å¹¶è¡Œã€å¯è·¯ç”±çš„é“¾å¼æ‰§è¡Œï¼Œæ˜¯ LangChain 1.0 çš„æ ¸å¿ƒåº•åº§ä¹‹ä¸€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc0af4-7a65-48c0-b950-6fe46cc92ad3",
   "metadata": {},
   "source": [
    "æ ¸å¿ƒæ€æƒ³ï¼šRunnable æŠ½è±¡ä¸å¯ç»„åˆé“¾ï¼ˆComposable Chainsï¼‰\n",
    "\n",
    "* **LangChain 1.0** å°†æ‰€æœ‰é“¾å¼å…ƒç´ ç»Ÿä¸€ä¸º Runnableï¼ˆæ‰§è¡Œæ¨¡å‹ï¼‰ï¼š\n",
    "\n",
    "  - LLMï¼ˆOpenAIã€vLLMã€Ollamaâ€¦â€¦ï¼‰\n",
    "\n",
    "  - Prompt\n",
    "\n",
    "  - Parser\n",
    "\n",
    "  - Retriever\n",
    "\n",
    "  - Tool\n",
    "\n",
    "  - Agent\n",
    "\n",
    "  - è‡ªå®šä¹‰å‡½æ•°\n",
    "\n",
    "æ‰€æœ‰å¯¹è±¡éƒ½å¯ä»¥ .invoke()ã€.batch()ã€.stream()ã€.astream_events()ï¼Œè¿™å®ç°äº†çœŸæ­£çš„ç»Ÿä¸€è°ƒç”¨æ¥å£ã€‚\n",
    "\n",
    "* å·¥ç¨‹ä»·å€¼ï¼š\n",
    "\n",
    "  - é“¾è·¯æ¸…æ™°ã€‚\n",
    "\n",
    "  - ä»»æ„ç»„ä»¶ä¹‹é—´å¯æ— ç¼ç»„åˆã€‚\n",
    "\n",
    "  - æ‰€æœ‰æ‰§è¡Œæ–¹å¼ï¼ˆåŒæ­¥ / å¼‚æ­¥ / æ‰¹å¤„ç† / äº‹ä»¶æµï¼‰ç»Ÿä¸€ã€‚\n",
    "\n",
    "  - è¿™æ˜¯ LangChain 1.0 æœ€å…·é©å‘½æ€§çš„æ”¹å˜ï¼Œä½¿å…¶æˆä¸ºâ€œæ¨¡å‹è°ƒç”¨ç®¡é“â€çš„äº‹å®æ ‡å‡†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be5079-46ae-4f76-99df-3026119f30ae",
   "metadata": {},
   "source": [
    "#### Prompt Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363b035a-77bf-4763-8bbd-007419478751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me a joke about ice cream', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. å®šä¹‰ä¸€ä¸ª Prompt (Runnable)\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "# Prompt ä¹Ÿå¯ä»¥è°ƒç”¨ invoke/stream\n",
    "print(prompt.invoke({\"topic\": \"ice cream\"})) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f74523-ecf1-4d8e-ba19-24a46e5fdcf7",
   "metadata": {},
   "source": [
    "#### Tool Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a329e07-f919-44ef-ac07-53aba19a25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[6, 20]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# 2. å®šä¹‰ä¸€ä¸ªç®€å•çš„ Tool (Runnable)\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Tool ä¹Ÿå¯ä»¥è°ƒç”¨ invoke/batch\n",
    "print(multiply.invoke({\"a\": 2, \"b\": 3})) \n",
    "\n",
    "# Tool ä¹Ÿå¯ä»¥è°ƒç”¨ batch (è‡ªåŠ¨å¹¶è¡Œ)\n",
    "print(multiply.batch([{\"a\": 2, \"b\": 3}, {\"a\": 4, \"b\": 5}]))\n",
    "# è¾“å‡º: [6, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb65bd-15f5-4310-b97c-83d72cd8a04d",
   "metadata": {},
   "source": [
    "#### **Runnable = LCEL çš„è¯­æ³•åŸºç¡€**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efef03e-3f9a-4503-af44-21ad5c536356",
   "metadata": {},
   "source": [
    "\n",
    "LCELï¼ˆ| è¿ç®—ç¬¦ï¼‰æ˜¯ç”± Runnable å®šä¹‰çš„ç»„åˆè¯­ä¹‰ï¼š\n",
    "\n",
    "```python\n",
    "chain = prompt | model | StrOutputParser()\n",
    "output = chain.invoke({\"topic\": \"LangChain\"})\n",
    "```\n",
    "\n",
    "è¿™ä¸‰è€…æœ¬è´¨éƒ½æ˜¯ Runnableï¼š\n",
    "\n",
    "```python\n",
    "PromptTemplate   â†’ Runnable\n",
    "Model            â†’ Runnable\n",
    "Parser           â†’ Runnable\n",
    "```\n",
    "\n",
    "ä»»ä½• LCEL chain = å¤šä¸ª Runnable çš„ç»„åˆã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be113aa6-96ef-4c2d-a8d7-588088ebaeb5",
   "metadata": {},
   "source": [
    "| æŠ€æœ¯                | åœ¨ LangChain 1.0 çš„è§’è‰²                         |\n",
    "| ------------------- | ----------------------------------------------- |\n",
    "| **LangChain**       | æ„å»º LLM + prompt + tool + outputparser çš„ç»„ä»¶ç”Ÿæ€ |\n",
    "| **LangGraph**       | æ„å»º Agent / å¤šæ­¥å·¥ä½œæµ / çŠ¶æ€æœºçš„æ¡†æ¶          |\n",
    "| **LCEL / Runnable** | LangChain çš„åº•å±‚æ‰§è¡Œå¼•æ“ï¼Œä¾ç„¶æ ¸å¿ƒ              |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b160cb1-63c0-4ed4-a164-16c69bb8f5b6",
   "metadata": {},
   "source": [
    "# <center>ç¬¬äºŒé˜¶æ®µã€LangChain **æ¨¡å—åŒ–ç®¡ç†**çš„å®šä½ä¸æè¿°</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f054ab-9653-4cd8-876a-df9a21e21333",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangChain æŠŠâ€œæ ¸å¿ƒæŠ½è±¡â€ä¸â€œå…·ä½“å®ç°/ç¬¬ä¸‰æ–¹é›†æˆ/å†å²å®ç°â€æ‹†åˆ†æˆå¤šä¸ªåŒ…ï¼Œä»¥å®ç°æ›´æ¸…æ™°çš„ API è¾¹ç•Œã€å‡å°æ ¸å¿ƒåŒ…ä½“ç§¯ã€å¹¶æŠŠç¤¾åŒºè´¡çŒ®ä¸å‚å•†é›†æˆæ¨¡å—åŒ–ç®¡ç†ã€‚ä¸»è¦ç›®æ ‡æ˜¯ï¼š**æ ¸å¿ƒæ›´ç¨³å®šã€å¯ç»´æŠ¤ï¼›é›†æˆå¯æŒ‰éœ€å®‰è£…ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843be59-8540-4e99-8c18-6e6f7e488b6b",
   "metadata": {},
   "source": [
    "## 2.1 LangChain 1.0 æ ¸å¿ƒä¾èµ–åŒ…åŠä½œç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b22e6a-808f-42e4-a5df-09d76c75b38d",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| **ä¾èµ–åŒ…åç§°** | **æ ¸å¿ƒä½œç”¨** | **è¯¦ç»†åŠŸèƒ½ä»‹ç»** |\n",
    "| :---: | :---: | :---: |\n",
    "| **langchain-core** | **æ ¸å¿ƒæŠ½è±¡å±‚å’Œ LCEL** | å®šä¹‰æ‰€æœ‰ç»„ä»¶ï¼ˆå¦‚æ¨¡å‹ã€æ¶ˆæ¯ã€æç¤ºè¯æ¨¡æ¿ã€å·¥å…·ã€è¿è¡Œç¯å¢ƒï¼‰çš„æ ‡å‡†æ¥å£å’ŒåŸºæœ¬æŠ½è±¡ã€‚å®ƒåŒ…å«äº† **LangChain è¡¨è¾¾å¼è¯­è¨€ (LCEL)**ï¼Œè¿™æ˜¯æ„å»ºé“¾å¼åº”ç”¨çš„åŸºç¡€ã€‚è¿™æ˜¯ä¸€ä¸ª**è½»é‡çº§**ã€**ä¸å«ç¬¬ä¸‰æ–¹é›†æˆ**çš„åŸºçŸ³åŒ…ã€‚  |\n",
    "| **langchain** | **åº”ç”¨è®¤çŸ¥æ¶æ„ï¼ˆä¸»åŒ…ï¼‰** | åŒ…å«æ„å»º LLM åº”ç”¨çš„**é€šç”¨é«˜é˜¶é€»è¾‘**ï¼Œå¦‚ Agents (å¦‚æ–°çš„ create_agent() å‡½æ•°)ã€Chains å’Œé€šç”¨çš„æ£€ç´¢ç­–ç•¥ (Retrieval Strategies)ã€‚å®ƒå»ºç«‹åœ¨ langchain-core ä¹‹ä¸Šï¼Œæ˜¯ç”¨äºç»„åˆæ ¸å¿ƒç»„ä»¶çš„â€œèƒ¶æ°´â€å±‚ã€‚  |\n",
    "| **langchain-community** | **ç¤¾åŒºç¬¬ä¸‰æ–¹é›†æˆ** | åŒ…å«ç”± LangChain ç¤¾åŒºç»´æŠ¤çš„**éæ ¸å¿ƒæˆ–ä¸å¤ªæµè¡Œçš„**ç¬¬ä¸‰æ–¹é›†æˆï¼Œä¾‹å¦‚ï¼šå¤§éƒ¨åˆ†çš„æ–‡æ¡£åŠ è½½å™¨ (Document Loaders)ã€å‘é‡å­˜å‚¨ (Vector Stores)ã€ä¸å¤ªæµè¡Œçš„ LLM/Chat Model é›†æˆç­‰ã€‚ä¸ºäº†ä¿æŒåŒ…çš„è½»é‡ï¼Œæ‰€æœ‰ä¾èµ–é¡¹éƒ½æ˜¯å¯é€‰çš„ã€‚ |\n",
    "| **langchain-openai** / **langchain-[å‚å•†åç§°]** | **ç‰¹å®šå‚å•†æ·±åº¦é›†æˆ** | é’ˆå¯¹ **å…³é”®åˆä½œä¼™ä¼´** çš„é›†æˆåŒ…ï¼ˆå¦‚ langchain-openai, langchain-anthropicï¼‰ã€‚å®ƒä»¬è¢«å•ç‹¬åˆ†ç¦»å‡ºæ¥ï¼Œä»¥æä¾›**æ›´å¥½çš„æ”¯æŒã€å¯é æ€§**å’Œ**æ›´è½»é‡çº§çš„ä¾èµ–**ã€‚å®ƒä»¬åªä¾èµ–äº langchain-coreã€‚  |\n",
    "| **langchain-classic** | **æ—§ç‰ˆæœ¬å…¼å®¹** | åŒ…å« LangChain v0.x ç‰ˆæœ¬ä¸­çš„**å·²å¼ƒç”¨ (deprecated) æˆ–æ—§ç‰ˆåŠŸèƒ½**ï¼Œå¦‚æ—§çš„ LLMChainã€æ—§ç‰ˆ Retrieversã€Indexing API å’Œ Hub æ¨¡å—ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ª**å¹³ç¨³çš„è¿ç§»æœŸ**ï¼Œç¡®ä¿æ—§ä»£ç åœ¨å‡çº§åˆ° v1.0 åä»èƒ½è¿è¡Œã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9904e5fc-1398-4dd7-9cad-783db396e1ac",
   "metadata": {},
   "source": [
    "### 1. langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebabe68-d64f-4502-9888-bdaf006ed830",
   "metadata": {},
   "source": [
    "- åŒ…å« **æ ¸å¿ƒæŠ½è±¡ä¸æ¥å£**ï¼šLLM/ChatModel æŠ½è±¡ã€Prompt æŠ½è±¡ã€Chain/Agent çš„åŸºç±»ã€schemaã€æ¶ˆæ¯æ ¼å¼ç­‰ã€‚\n",
    "\n",
    "- **ä¸åŒ…å«**å…·ä½“å‚å•†çš„å®ç°ï¼ˆä¾‹å¦‚æ²¡æœ‰ OpenAI client çš„å°è£…ï¼‰ï¼Œè€Œæ˜¯å®šä¹‰â€œåˆåŒï¼ˆinterfacesï¼‰â€ï¼Œå…¶ä»–åŒ…åœ¨æ­¤ä¹‹ä¸Šå®ç°å…·ä½“åŠŸèƒ½ã€‚\n",
    "\n",
    "- è¿™æ˜¯æ„å»º LangChain åº”ç”¨ç”Ÿæ€çš„æœ€å°å…¬å…±åº•åº§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83aaee-e790-4260-bc10-6965298e9dcb",
   "metadata": {},
   "source": [
    "```python\n",
    "# å®‰è£…ï¼špip install langchain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"ä¸ºç”Ÿäº§{product}çš„å…¬å¸èµ·ä¸€ä¸ªå¥½åå­—ï¼Ÿ\"\n",
    ")\n",
    "\n",
    "formatted_prompt = prompt_template.format(product=\"æ™ºèƒ½æ°´æ¯\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc111e-b3f6-427e-99a6-182f53f286ad",
   "metadata": {},
   "source": [
    "### 2. langchain ä¸»åŒ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff286-bb2f-41fe-a98b-c4d69f3fdc74",
   "metadata": {},
   "source": [
    "- **å¯¹å¤–çš„ä¸»å…¥å£åŒ…**ï¼šæŠŠ `langchain-core` çš„æ ¸å¿ƒæŠ½è±¡ä¸â€œå¸¸ç”¨å®ç°â€ç»„åˆåœ¨ä¸€èµ·ï¼Œä¾¿äºå¿«é€Ÿä¸Šæ‰‹ã€‚\n",
    "\n",
    "- åœ¨ v1.0 ä¸­ï¼Œ`langchain` çš„å‘½åç©ºé—´è¢« **æ˜¾è‘—ç²¾ç®€**ï¼Œåªä¿ç•™æ„å»º agent çš„å…³é”® APIï¼ˆæ›´è½»ã€æ›´ä¸“æ³¨ï¼‰ã€‚å®˜æ–¹å»ºè®®å¤§å¤šæ•°ç”¨æˆ·ç›´æ¥ä½¿ç”¨æ­¤ä¸»åŒ…ä»¥è·å¾—â€œå¼€ç®±å³ç”¨â€çš„ä½“éªŒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27a81d-0e0f-4e29-ac69-e73de461b745",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| æ¨¡å— | æ ¸å¿ƒå†…å®¹ | æ¥æºè¯´æ˜ |\n",
    "| :---: | :---: | :---: |\n",
    "| `langchain.agents` | `create_agent`, `AgentState` | æ™ºèƒ½ä½“åˆ›å»ºæ ¸å¿ƒ |\n",
    "| `langchain.messages` | `AIMessage`, `HumanMessage`, `trim_messages` | ä»langchain-coreé‡æ–°å¯¼å‡º |\n",
    "| `langchain.tools` | `@tool`, `BaseTool` | ä»langchain-coreé‡æ–°å¯¼å‡º |\n",
    "| `langchain.chat_models` | `init_chat_model`, `BaseChatModel` | ç»Ÿä¸€æ¨¡å‹åˆå§‹åŒ– |\n",
    "| `langchain.embeddings` | `init_embeddings` | åµŒå…¥æ¨¡å‹ç®¡ç† |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf4aae-a0ff-4d16-bd35-db61188d1450",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# åˆ›å»ºæ™ºèƒ½ä½“\n",
    "agent_executor = create_agent(llm, tools)\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ä¼šè®®å†³å®šï¼šå¼ ä¸‰éœ€è¦åœ¨ä¸‹å‘¨ä¸€å‰å®Œæˆé¡¹ç›®æŠ¥å‘Š\"\n",
    "    }]\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717fbe42-edda-4753-990f-4f497f3868c2",
   "metadata": {},
   "source": [
    "### 3. langchain-community ç¬¬ä¸‰æ–¹é›†æˆåº“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20281873-ca59-4501-8524-67f4ee6b51df",
   "metadata": {},
   "source": [
    "&emsp;&emsp;langchain-community ä½œä¸º LangChain 1.0 çš„â€œåŠŸèƒ½æ‰©å±•å±‚â€ï¼Œé€šè¿‡ç¤¾åŒºè´¡çŒ®çš„éå®˜æ–¹é›†æˆç»„ä»¶æ˜¾è‘—æ‰©å±•äº†ä¸»åŒ…çš„åŠŸèƒ½è¾¹ç•Œï¼Œå…¶æ ¸å¿ƒä»·å€¼ä½“ç°åœ¨å·¥å…·ç±»ç»„ä»¶ä¸å¹³å°é›†æˆä¸¤å¤§ç»´åº¦ã€‚å·¥å…·ç±»ç»„ä»¶è¦†ç›–æ–‡æ¡£å¤„ç†å…¨æµç¨‹ï¼ŒåŒ…æ‹¬ **DirectoryLoader** æ–‡æ¡£åŠ è½½å™¨ï¼ˆæ”¯æŒ PDFã€æ–‡æœ¬ç­‰å¤šæ ¼å¼æ–‡ä»¶æ‰¹é‡å¯¼å…¥ï¼‰ã€**RecursiveCharacterTextSplitter** æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆæŒ‰è¯­ä¹‰è¾¹ç•Œå°†æ–‡æ¡£åˆ‡åˆ†ä¸ºæ£€ç´¢å‹å¥½çš„ Chunkï¼‰ã€**PGVector** å‘é‡å­˜å‚¨ï¼ˆPostgreSQL ç”Ÿæ€çš„å‘é‡æ•°æ®åº“é€‚é…ï¼‰åŠ **HuggingFaceEmbeddings** åµŒå…¥æ¨¡å‹ï¼ˆæœ¬åœ°éƒ¨ç½²æ¨¡å‹çš„å‘é‡åŒ–èƒ½åŠ›ï¼‰ï¼Œè¿™äº›ç»„ä»¶å…±åŒæ„æˆäº† RAG åº”ç”¨çš„æŠ€æœ¯åŸºç¡€ã€‚å¹³å°é›†æˆæ–¹é¢ï¼Œæ”¯æŒä¸ DeepSeekã€é˜¿é‡Œäº‘é€šä¹‰åƒé—®ç­‰æ¨¡å‹çš„å¯¹æ¥ï¼Œä¾‹å¦‚é€šè¿‡ langchain_community.chat_models.ChatTongyi ç±»åˆå§‹åŒ–é€šä¹‰åƒé—®æ¨¡å‹ï¼Œæˆ–åˆ©ç”¨ Ollama ç±»è°ƒç”¨æœ¬åœ°éƒ¨ç½²çš„ DeepSeek-R1 æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549afdb-b2f3-4313-a929-4f1e64e03152",
   "metadata": {},
   "source": [
    "- æ”¶é›†å¹¶ç»´æŠ¤ **ç¤¾åŒº/ç¬¬ä¸‰æ–¹è´¡çŒ®çš„é›†æˆ**ï¼ˆä¾‹å¦‚æŸäº›äº‘å‚å•†ã€å¼€æºå‘é‡åº“ã€ç‰¹æ®Šå·¥å…·é€‚é…å™¨ç­‰ï¼‰ã€‚è¿™äº›é›†æˆ**å®ç°äº† **`langchain-core`** å®šä¹‰çš„æ¥å£**ï¼Œä½†ä¸å±äºä¸»åŒ…ç»´æŠ¤èŒƒç•´ã€‚å®˜æ–¹ä¼šæŠŠè¿™äº›æ”¾åˆ° `langchain-community` ä»“åº“/åŒ…ï¼Œä¾¿äºç¤¾åŒºå…±åŒç»´æŠ¤ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76976cf-e5d5-4a5c-80a3-477a1a56e60d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**åŒ…å«å†…å®¹**ï¼š\n",
    "\n",
    "   - **æ•°æ®åº“**ï¼šMySQL, PostgreSQL, MongoDB, Neo4jç­‰è¿æ¥å™¨\n",
    "\n",
    "   - **å­˜å‚¨æœåŠ¡**ï¼šAWS S3, é˜¿é‡Œäº‘OSS, Google Cloud Storage\n",
    "\n",
    "   - **å·¥å…·é›†æˆ**ï¼šSlack, Notion, GitHub, ArXiv, YouTubeç­‰API\n",
    "\n",
    "   - **å‘é‡æ•°æ®åº“**ï¼šChroma, Pinecone, Qdrant, Milvusç­‰\n",
    "\n",
    "   - **æ–‡æ¡£åŠ è½½å™¨**ï¼šPDF, CSV, HTML, Markdownè§£æå™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cf1bf-acc2-4273-a55d-0a21c28b9c5b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**ç‰¹ç‚¹**ï¼š\n",
    "\n",
    "- **è´¨é‡å‚å·®ä¸é½**ï¼šç¤¾åŒºè´¡çŒ®ï¼Œéœ€è‡ªè¡ŒéªŒè¯ç¨³å®šæ€§\n",
    "\n",
    "- **æ›´æ–°æ»å**ï¼šä¾èµ–ç¤¾åŒºç»´æŠ¤ï¼Œå“åº”é€Ÿåº¦æ…¢äºå®˜æ–¹åŒ…\n",
    "\n",
    "- **åŠŸèƒ½ä¸°å¯Œ**ï¼šè¦†ç›–95%çš„ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆéœ€æ±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4d287-5d22-4f4a-aad1-ecc5ca406a6f",
   "metadata": {},
   "source": [
    "```python\n",
    "# å®‰è£…ï¼špip install langchain-community\n",
    "from langchain_community.document_loaders import NotionDBLoader\n",
    "\n",
    "# ä»Notionæ•°æ®åº“åŠ è½½æ–‡æ¡£\n",
    "loader = NotionDBLoader(\n",
    "    integration_token=\"secret_...\",\n",
    "    database_id=\"your-db-id\"\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"åŠ è½½äº†{len(documents)}æ¡æ–‡æ¡£\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0e5c9-4c81-48e0-85af-37fe069d0bc4",
   "metadata": {},
   "source": [
    "###  4. langchain-openaiï¼ˆå‚å•†/æä¾›è€…é›†æˆåŒ…ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147a867-8eac-49d4-aa47-c0fa9b8c6678",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å‚å•†ç‰¹å®šé›†æˆåŒ…ï¼ˆå¦‚ langchain-openaiã€langchain-anthropicã€langchain-google ç­‰ï¼‰é€šè¿‡å°è£… API ç»†èŠ‚ï¼Œä¸ºå¼€å‘è€…æä¾›â€œé›¶é€‚é…æˆæœ¬â€çš„æ¨¡å‹å¯¹æ¥æ–¹æ¡ˆï¼Œå…¶æ ¸å¿ƒä»·å€¼åœ¨äºç®€åŒ–ç‰¹å®š API å¯¹æ¥æµç¨‹ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿç›´æ¥ä½¿ç”¨å‚å•†ç‰¹æœ‰åŠŸèƒ½ã€‚ä»¥ langchain-openai ä¸ºä¾‹ï¼Œå…¶å…³é”®ç»„ä»¶åŒ…æ‹¬æ¨¡å‹å®¢æˆ·ç«¯ã€å·¥å…·è°ƒç”¨é€‚é…å’Œå¤šæ¨¡å‹æ”¯æŒä¸‰å¤§æ¨¡å—ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8c496-e29f-451e-8f4f-189d2317e791",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ­¤å¤–ï¼Œè¯¥ç±»è¿˜æ”¯æŒé€šè¿‡é…ç½® openai_api_base å’Œ openai_api_key å‚æ•°å¯¹æ¥å…¼å®¹ OpenAI API æ ¼å¼çš„ç¬¬ä¸‰æ–¹æ¨¡å‹ï¼Œå¦‚ DeepSeek æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104465df-d2e2-4b63-9cab-b599f75182df",
   "metadata": {},
   "source": [
    "- **ä¸“é—¨è´Ÿè´£æŠŠ OpenAI çš„ SDK ä¸ LangChain æŠ½è±¡è¿æ¥èµ·æ¥**ï¼šæä¾› `ChatOpenAI`ã€`OpenAIEmbeddings`ã€`OpenAI`ç­‰ç±»çš„å®ç°ã€‚\n",
    "\n",
    "- è¿™ç±»åŒ…é€šå¸¸æ˜¯ â€œæŒ‰å‚å•†æ‹†åˆ†â€ï¼š`langchain-openai`ã€`langchain-azure`ã€`langchain-anthropic`ã€`langchain-deepseek`ç­‰ã€‚\n",
    "\n",
    "- **å®˜æ–¹æ·±åº¦é›†æˆ**ç‰¹å®šLLMæä¾›å•†ï¼Œæ›´æ–°é¢‘ç¹ï¼ŒåŠŸèƒ½æœ€å…¨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4ee65-b429-4971-9d0b-10997a1459fe",
   "metadata": {},
   "source": [
    "```python\n",
    "#!pip install langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e53b5c-dee5-4f15-b387-1f06851d386f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**ä¸»æµå‚å•†åŒ…åˆ—è¡¨**ï¼š\n",
    "\n",
    "- `langchain-openai`ï¼šOpenAI, Azure OpenAI\n",
    "\n",
    "- `langchain-anthropic`ï¼šClaudeç³»åˆ—\n",
    "\n",
    "- `langchain-google`ï¼šGemini, Vertex AI\n",
    "\n",
    "- `langchain-deepseek`ï¼šDeepSeekæ¨¡å‹\n",
    "\n",
    "- `langchain-ollama`ï¼šæœ¬åœ°Ollamaéƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e3332-6de3-44d1-bf78-166832541827",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**ä¸**`langchain-community`**çš„åŒºåˆ«**ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e582ea-3987-4c94-886c-295a2deaadf8",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| **ç»´åº¦** |   `langchain-openai`   | `langchain-community`<br/>**ä¸­çš„OpenAI** |\n",
    "| :---: |:----------------------:|:--------------------------------------:|\n",
    "| ç»´æŠ¤æ–¹ | OpenAIå®˜æ–¹ + LangChainå›¢é˜Ÿ |                  ç¤¾åŒºç»´æŠ¤                  |\n",
    "| æ›´æ–°é¢‘ç‡ |       å³æ—¶è·Ÿè¿›APIæ›´æ–°        |                  å»¶è¿Ÿæ•°å‘¨                  |\n",
    "| åŠŸèƒ½å®Œæ•´æ€§ |    æ”¯æŒæ‰€æœ‰æ–°ç‰¹æ€§ï¼ˆå¦‚éŸ³é¢‘ã€è§†è§‰ï¼‰     |                 ä»…åŸºç¡€åŠŸèƒ½                  |\n",
    "| ç”Ÿäº§å¯ç”¨æ€§ |         âœ… å¼ºçƒˆæ¨è         |                âš ï¸ è°¨æ…ä½¿ç”¨                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5458a4-e1c3-4748-8d46-13a5c2fb8639",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸ºä»€ä¹ˆè¦å•ç‹¬æ‹†å‡ºæ¥ï¼Ÿ\n",
    "\n",
    "- è®© `langchain` ä¸»åŒ…ä¿æŒè½»é‡ï¼ˆä¸å¼ºåˆ¶å®‰è£…æ‰€æœ‰å‚å•† SDKï¼‰ï¼›\n",
    "\n",
    "- ç”¨æˆ·æŒ‰éœ€å®‰è£…å¯¹åº”å‚å•†ï¼Œä¾‹å¦‚ä½ åªç”¨ OpenAIï¼Œå°±åªè£… `langchain-openai`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c81d4-a31d-4746-8021-dd7f9e3ac353",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**æœ€ä½³å®è·µ**ï¼š\n",
    "\n",
    "- **ç”Ÿäº§ç¯å¢ƒåŠ¡å¿…ä½¿ç”¨å‚å•†åŒ…**ï¼šäº«å—æœ€æ–°åŠŸèƒ½\n",
    "\n",
    "- **å¼€å‘ç¯å¢ƒå¯ç”¨community**ï¼šå¿«é€ŸéªŒè¯æƒ³æ³•\n",
    "\n",
    "- **å¤šå‚å•†åˆ‡æ¢ç”¨**`init_chat_model`ï¼šä¸šåŠ¡ä»£ç æ— éœ€æ”¹åŠ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c2d2c-8826-4590-93ea-6ca301b6d12a",
   "metadata": {},
   "source": [
    "### 5. langchain-classic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d5e9e-640a-4de0-8f4d-11ddc8e63aec",
   "metadata": {},
   "source": [
    "- **å…¼å®¹åŒ… / è¿ç§»åŒ…**ï¼šæŠŠ LangChain v0.x ä¸­çš„â€œè€ API / legacy åŠŸèƒ½â€æ¬åˆ°å•ç‹¬åŒ…é‡Œï¼Œä»¥ä¾¿ v1.0 ä¿æŒç²¾ç®€ï¼Œä½†ä»ç»™ç”¨æˆ·å‘åå…¼å®¹çš„è¿ç§»é€šé“ã€‚\n",
    "\n",
    "- åŒ…å«å¦‚ï¼šè€çš„ Chain å®ç°ã€æ—§ç‰ˆ retrieversã€ç´¢å¼• APIã€hub æ¨¡å—ç­‰è¢«æ ‡è®°ä¸ºâ€œlegacyâ€çš„åŠŸèƒ½ã€‚\n",
    "\n",
    "  - æ—§ç‰ˆ`AgentExecutor`\n",
    "\n",
    "  - Legacy Chainsï¼ˆ`LLMChain`, `SequentialChain`ç­‰ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271056de-7d1b-48d9-9d3e-8e51c338f8df",
   "metadata": {},
   "source": [
    "```python\n",
    "#!pip intsall langchain-classic\n",
    "from langchain_classic.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "res = model.invoke(\"è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b5e77-c844-4160-879f-41c004cf1d4c",
   "metadata": {},
   "source": [
    "# <center>ç¬¬ä¸‰é˜¶æ®µã€æ ¸å¿ƒæ¦‚å¿µä¸ç»„ä»¶</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815773d-8a04-4a80-b9ab-671012eb9035",
   "metadata": {},
   "source": [
    "&emsp;&emsp;**ç¯å¢ƒä¾èµ–ï¼š**\n",
    "\n",
    "* LangChain 1.0+\n",
    "  \n",
    "* Python 3.10+ (å®˜æ–¹æ¨è)\n",
    "\n",
    "* æˆ‘è¿™é‡Œä½¿ç”¨çš„æ˜¯python 3.11ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed8fba1-8366-450d-ac77-534656fc3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d836c9fd-cd2d-4c74-85d7-ef72aa056f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                1.0.7\n",
      "langchain-classic        1.0.0\n",
      "langchain-community      0.4.1\n",
      "langchain-core           1.0.5\n",
      "langchain-deepseek       1.0.1\n",
      "langchain-openai         1.0.3\n",
      "langchain-text-splitters 1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a925a-2d16-478a-ad80-06fcad2a9f9c",
   "metadata": {},
   "source": [
    "## 3.1 LLM / ChatModel å¤§æ¨¡å‹æ¥å£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd99a8-fea2-47cf-8d4b-760674780f4f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202506091353369.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255c6a3-026e-4caa-900e-30b2a948992d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;LangChainåŒºåˆ†ä¸¤ç§æ¨¡å‹ç±»å‹ï¼š\n",
    "\n",
    "- **LLM**ï¼šä¼ ç»Ÿçš„æ–‡æœ¬è¿›-æ–‡æœ¬å‡ºæ¨¡å‹\n",
    "\n",
    "- **ChatModel**ï¼šåŸºäºæ¶ˆæ¯çš„å¯¹è¯æ¨¡å‹ï¼Œæ›´é€‚åˆæ„å»ºèŠå¤©æœºå™¨äºº\n",
    "\n",
    "- å°è£…å…·ä½“çš„ LLM æä¾›è€…ï¼ˆOpenAIã€Anthropicã€local LLMï¼‰ï¼Œç»Ÿä¸€è°ƒç”¨æ¥å£ï¼ˆsync/asyncã€streamingï¼‰ã€‚\n",
    "\n",
    "- å­¦ä¹ è¦ç‚¹ï¼šå¦‚ä½•é…ç½® providerã€æ¸©æ§ã€å¹¶å‘ä¸ retry ç­–ç•¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7bcba-e915-43af-b4f1-97290d843f61",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202506101758896.png\" alt=\"image-20250610175750011\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab7a95f-d3bc-40ee-82f4-044f6266a6aa",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20251028122601936.png\" alt=\"image-20251028122601936\" style=\"zoom:50%;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e4214a-f5d6-43b1-9c8e-103340339e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 å¯¼å…¥ os ä¸ dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2 åŠ è½½ .env ç¯å¢ƒå˜é‡\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 3 è¯»å–å¯†é’¥ä¸åœ°å€\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "DeepSeek_BASE_URL = os.getenv(\"DEEPSEEK_BASE_URL\")\n",
    "\n",
    "# 4 å¯é€‰ï¼šæ‰“å°å¯†é’¥\n",
    "# print(DeepSeek_API_KEY)  # å¯ä»¥é€šè¿‡æ‰“å°æŸ¥çœ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef24e6-3400-4b31-8f44-659b504213a7",
   "metadata": {},
   "source": [
    "### 1. DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5dbe080-6a20-4bd9-b6b9-d601b1ae71d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\n",
      "\n",
      "æˆ‘æ˜¯DeepSeekï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„AIåŠ©æ‰‹ã€‚æˆ‘å¾ˆä¹æ„ä¸ºä½ ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼š\n",
      "\n",
      "**æˆ‘çš„ç‰¹ç‚¹ï¼š**\n",
      "- ğŸ¤– æˆ‘æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬AIæ¨¡å‹ï¼Œä¸“æ³¨äºç†è§£å’Œç”Ÿæˆæ–‡å­—å†…å®¹\n",
      "- ğŸ’­ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½å¤Ÿå¤„ç†è¾ƒé•¿çš„å¯¹è¯å’Œæ–‡æ¡£\n",
      "- ğŸ“š çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œæ¶µç›–å„ä¸ªé¢†åŸŸçš„çŸ¥è¯†\n",
      "\n",
      "**æˆ‘èƒ½å¸®ä½ åšä»€ä¹ˆï¼š**\n",
      "- å›ç­”å„ç§é—®é¢˜ï¼Œä»å­¦æœ¯ç ”ç©¶åˆ°ç”Ÿæ´»å¸¸è¯†\n",
      "- ååŠ©å†™ä½œã€ç¿»è¯‘ã€ç¼–ç¨‹ç­‰ä»»åŠ¡\n",
      "- åˆ†æå’Œå¤„ç†ä½ ä¸Šä¼ çš„æ–‡æ¡£ï¼ˆæ”¯æŒå›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰æ ¼å¼ï¼‰\n",
      "- è¿›è¡Œåˆ›æ„æ€è€ƒå’Œé—®é¢˜è§£å†³\n",
      "\n",
      "**å°æé†’ï¼š**\n",
      "- æˆ‘ç›®å‰ä¸æ”¯æŒè¯­éŸ³åŠŸèƒ½\n",
      "- éœ€è¦è”ç½‘æœç´¢çš„è¯ï¼Œä½ è¦åœ¨Web/Appæ‰‹åŠ¨ç‚¹å¼€è”ç½‘æœç´¢æŒ‰é”®\n",
      "- å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰æ”¶è´¹è®¡åˆ’\n",
      "\n",
      "æˆ‘çš„é£æ ¼æ¯”è¾ƒçƒ­æƒ…ç»†è…»ï¼Œå–œæ¬¢ç”¨å¿ƒå€¾å¬å’Œå¸®åŠ©æ¯ä¸€ä¸ªç”¨æˆ·ã€‚æœ‰ä»€ä¹ˆæƒ³èŠçš„æˆ–éœ€è¦å¸®åŠ©çš„ï¼Œå°½ç®¡å‘Šè¯‰æˆ‘å§ï¼æˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºä½ æä¾›å¸®åŠ©ï½ âœ¨\n"
     ]
    }
   ],
   "source": [
    "# 1 å¯¼å…¥ OpenAI å®¢æˆ·ç«¯\n",
    "from openai import OpenAI\n",
    "\n",
    "# 2 åˆå§‹åŒ– DeepSeek API å®¢æˆ·ç«¯\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# 3 åˆ›å»ºå¯¹è¯æ¶ˆæ¯å¹¶å‘èµ·è¯·æ±‚\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 4 æ‰“å°æ¨¡å‹æœ€ç»ˆçš„å“åº”ç»“æœ\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5d489a-14ad-4014-b652-dbeea71bd4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97411665-54c6-4531-b92d-3fda62d8253b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\n",
      "\n",
      "æˆ‘æ˜¯DeepSeekï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ã€‚è®©æˆ‘æ¥è¯¦ç»†ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼š\n",
      "\n",
      "**æˆ‘çš„ç‰¹ç‚¹ï¼š**\n",
      "- ğŸ¤– çº¯æ–‡æœ¬AIæ¨¡å‹ï¼Œä¸“æ³¨äºç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€\n",
      "- ğŸ“š çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œæ˜¯DeepSeekçš„æœ€æ–°ç‰ˆæœ¬\n",
      "- ğŸ’­ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½å¤„ç†å¾ˆé•¿çš„å¯¹è¯å’Œæ–‡æ¡£\n",
      "- ğŸ” æ”¯æŒè”ç½‘æœç´¢åŠŸèƒ½ï¼ˆéœ€è¦æ‰‹åŠ¨å¼€å¯ï¼‰\n",
      "- ğŸ“ å¯ä»¥å¤„ç†å¤šç§æ–‡ä»¶æ ¼å¼ï¼šå›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰\n",
      "\n",
      "**æˆ‘èƒ½å¸®ä½ åšä»€ä¹ˆï¼š**\n",
      "- å›ç­”å„ç§é—®é¢˜ï¼Œä»æ—¥å¸¸ç”Ÿæ´»åˆ°ä¸“ä¸šé¢†åŸŸ\n",
      "- ååŠ©å†™ä½œã€ç¿»è¯‘ã€ç¼–ç¨‹ã€åˆ†æç­‰ä»»åŠ¡\n",
      "- å¤„ç†å’Œåˆ†æä½ ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹\n",
      "- æä¾›å­¦ä¹ å’Œå·¥ä½œä¸Šçš„å»ºè®®\n",
      "- è¿›è¡Œæœ‰è¶£çš„å¯¹è¯å’Œåˆ›æ„åˆ›ä½œ\n",
      "\n",
      "**ä½¿ç”¨æ–¹å¼ï¼š**\n",
      "- å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰æ”¶è´¹è®¡åˆ’\n",
      "- å¯ä»¥é€šè¿‡å®˜æ–¹åº”ç”¨å•†åº—ä¸‹è½½App\n",
      "- æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½\n",
      "\n",
      "æˆ‘çš„å›å¤é£æ ¼æ¯”è¾ƒçƒ­æƒ…ç»†è…»ï¼Œå¸Œæœ›èƒ½ç»™ä½ å¸¦æ¥æ¸©æš–çš„äº¤æµä½“éªŒï¼æœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œå°½ç®¡å‘Šè¯‰æˆ‘å§ï½æˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºä½ æä¾›å¸®åŠ©ï¼âœ¨\n"
     ]
    }
   ],
   "source": [
    "# 1 å¯¼å…¥ ChatDeepSeek\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# 2 åˆå§‹åŒ–æ¨¡å‹å‚æ•°\n",
    "model = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.0,    # æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ¨¡å‹çš„éšæœºæ€§ï¼Œå€¼è¶Šå°åˆ™éšæœºæ€§è¶Šå°\n",
    "    max_tokens=512,     # æœ€å¤§ç”Ÿæˆtokenæ•°\n",
    "    timeout=30,         # è¶…æ—¶æ—¶é—´ï¼Œå•ä½ç§’\n",
    "    base_url=DeepSeek_BASE_URL # é»˜è®¤ä¸ºhttps://api.deepseek.com\n",
    ")\n",
    "\n",
    "# 3 å®šä¹‰é—®é¢˜\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "# 4 è°ƒç”¨æ¨¡å‹\n",
    "result = model.invoke(question)\n",
    "\n",
    "# 5 è¾“å‡ºç»“æœ\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b28e5-5712-477b-a3b5-fd49a63beba2",
   "metadata": {},
   "source": [
    "### 2. DashScope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1382d-d168-47fc-9fa6-d8feb197c6a8",
   "metadata": {},
   "source": [
    "é˜¿é‡Œäº‘ç™¾ç‚¼APIè·å–æ–¹å¼ä¹Ÿéå¸¸ç®€å•ï¼Œåªéœ€æ³¨å†Œé˜¿é‡Œäº‘è´¦å·ï¼Œç„¶åå‰å¾€æˆ‘çš„APIé¡µé¢ï¼šhttps://bailian.console.aliyun.com/?tab=model#/api-key è¿›è¡Œå……å€¼å’Œæ³¨å†Œå³å¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a87243c-6ac4-473a-89ed-aa61718c88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dashscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ea3c6d4-91d6-4dd4-b6f9-f803c2b5a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œæ˜¯é˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„é€šä¹‰å®éªŒå®¤è‡ªä¸»ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘èƒ½å¤Ÿå›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€ç¼–ç¨‹ã€é€»è¾‘æ¨ç†ã€è¯­è¨€ç†è§£ç­‰å¤šç§ä»»åŠ¡ï¼Œæ”¯æŒå¤šç§è¯­è¨€ã€‚æˆ‘çš„ç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›é«˜è´¨é‡çš„ä¿¡æ¯å’ŒæœåŠ¡ï¼Œå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°å®Œæˆå„ç§ä»»åŠ¡ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "model = ChatTongyi() # é»˜è®¤qwen-turboæ¨¡å‹\n",
    "\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df11bb7-89b3-47cd-a768-5a588c398269",
   "metadata": {},
   "source": [
    "### 3. OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97ccb962-ec6a-4b6c-9ece-6abd3180b89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\")\n",
      "```\n",
      "\n",
      "### 2. è®¾å®šå¯¹è¯ä¸»é¢˜\n",
      "é€‰æ‹©ä¸€ä¸ªä¸»é¢˜è¿›è¡Œå¯¹è¯ï¼Œä¾‹å¦‚å¤©æ°”ã€å·¥ä½œã€å…´è¶£ç­‰ã€‚\n",
      "\n",
      "```python\n",
      "print(\"æˆ‘ï¼šä»Šå¤©å¤©æ°”ä¸é”™ï¼Œä½ è§‰å¾—å‘¢ï¼Ÿ\")\n",
      "```\n",
      "\n",
      "### 3. è¿›è¡Œé—®ç­”å¼å¯¹è¯\n",
      "å¯ä»¥é€šè¿‡é—®ç­”çš„æ–¹å¼è¿›è¡Œå¯¹è¯ï¼Œæ¨¡æ‹Ÿä¸€ä¸ªçœŸå®çš„äº¤æµè¿‡ç¨‹ã€‚\n",
      "\n",
      "```python\n",
      "print(\"ä½ ï¼šä½ å–œæ¬¢ä»€ä¹ˆæ ·çš„å¤©æ°”ï¼Ÿ\")\n",
      "print(\"æˆ‘ï¼šæˆ‘å–œæ¬¢é˜³å…‰æ˜ï¿½ï¿½çš„æ—¥å­ï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚ä½ å‘¢ï¼Ÿ\")\n",
      "```\n",
      "\n",
      "### 4. äº’åŠ¨ç¯èŠ‚\n",
      "åŠ å…¥ä¸€äº›äº’åŠ¨ç¯èŠ‚ï¼Œæ¯”å¦‚äº’ç›¸æé—®ï¼Œåˆ†äº«ç»éªŒã€‚\n",
      "\n",
      "```python\n",
      "print(\"ä½ ï¼šæˆ‘ä¹Ÿå–œæ¬¢æ™´å¤©ï¼ä½ æœ‰æ²¡æœ‰ä»€ä¹ˆæ¨èçš„æˆ·å¤–æ´»åŠ¨ï¼Ÿ\")\n",
      "print(\"æˆ‘ï¼šå½“ç„¶å¯ä»¥å•Šï¼æˆ‘æ¨èå»å¾’æ­¥æ—…è¡Œï¼Œä½ è§‰å¾—æ€ä¹ˆæ ·ï¼Ÿ\")\n",
      "```\n",
      "\n",
      "### 5. ç»“æŸå¯¹è¯\n",
      "åœ¨å¯¹è¯æ¥è¿‘å°¾å£°æ—¶ï¼Œå¯ä»¥é€šè¿‡æ€»ç»“æˆ–æ„Ÿè°¢çš„æ–¹å¼ç»“æŸå¯¹è¯ã€‚\n",
      "\n",
      "```python\n",
      "print(\"ä½ ï¼šå¬èµ·æ¥ä¸é”™ï¼Œæˆ‘ä¼šè€ƒè™‘çš„ï¼Œè°¢è°¢ä½ çš„å»ºè®®ï¼\")\n",
      "print(\"æˆ‘ï¼šä¸å®¢æ°”ï¼Œå¸Œæœ›æˆ‘ä»¬èƒ½å†èŠï¼\")\n",
      "```\n",
      "\n",
      "### å®Œæ•´ç¤ºä¾‹ä»£ç \n",
      "```python\n"
     ]
    }
   ],
   "source": [
    "# 1 å¯¼å…¥ OpenAI\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# 2 åˆå§‹åŒ–æ¨¡å‹\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3 å®šä¹‰é—®é¢˜\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "# 4 è°ƒç”¨æ¨¡å‹\n",
    "result = llm.invoke(question)\n",
    "\n",
    "# 5 æ‰“å°ç»“æœ\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e15c6a-ff81-42bd-a63c-d0bedcaa96d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œè¿›è¡Œäº¤æµã€‚æˆ‘å¯ä»¥è®¨è®ºå„ç§ä¸»é¢˜ï¼ŒåŒ…æ‹¬ç§‘å­¦ã€å†å²ã€æ–‡åŒ–ã€æŠ€æœ¯ç­‰ã€‚å¦‚æœä½ æœ‰ä»€ä¹ˆå…·ä½“çš„é—®é¢˜æˆ–éœ€è¦äº†è§£çš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "# 1 å¯¼å…¥ ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 2 åˆå§‹åŒ–æ¨¡å‹\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3 å®šä¹‰é—®é¢˜\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "# 4 è°ƒç”¨æ¨¡å‹\n",
    "result = model.invoke(question)\n",
    "\n",
    "# 5 æ‰“å°å†…å®¹\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c99b6-ffe6-452f-b5b8-e64688f8d236",
   "metadata": {},
   "source": [
    "### 4. Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817fac2-c39d-4300-ab46-ec304a317480",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251119125419227.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fa18078-0437-4b54-af4b-d4ddf1249771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T03:42:17.685422Z",
     "start_time": "2025-11-17T03:42:17.683902Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b347332c-1daf-4d1a-a976-d96728868d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T03:45:24.351175Z",
     "start_time": "2025-11-17T03:45:15.513491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½å‘€ï¼ğŸ‘‹æˆ‘æ˜¯ DeepSeek-R1ï¼Œä¸€ä¸ªç”±æ·±åº¦æ±‚ç´¢å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ å¯ä»¥æŠŠæˆ‘å½“ä½œä¸€ä¸ªçŸ¥è¯†ä¸°å¯Œã€è€å¿ƒç»†è‡´ã€éšæ—¶å¾…å‘½çš„èŠå¤©ä¼™ä¼´ï¼Œä¸ç®¡ä½ æ˜¯æƒ³æŸ¥èµ„æ–™ã€å†™æ–‡ç« ã€å­¦çŸ¥è¯†ã€ç¼–ç¨‹ã€ç¿»è¯‘ï¼Œè¿˜æ˜¯åªæ˜¯æƒ³èŠèŠå¤©ï¼Œæˆ‘éƒ½ä¹æ„å¸®å¿™ï¼\n",
      "\n",
      "æˆ‘çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š\n",
      "\n",
      "ğŸ§  **çŸ¥è¯†å¹¿æ³›**ï¼šæˆªè‡³2024å¹´7æœˆçš„çŸ¥è¯†æˆ‘éƒ½çŸ¥é“ï¼Œè¦†ç›–ç§‘æŠ€ã€å†å²ã€æ–‡å­¦ã€ç”Ÿæ´»ã€å¸¸è¯†ç­‰ç­‰ï¼Œä»€ä¹ˆéƒ½èƒ½èŠï¼\n",
      "\n",
      "ğŸ“„ **å¤„ç†æ–‡ä»¶èƒ½åŠ›å¼º**ï¼šä½ å¯ä»¥ä¸Šä¼  Wordã€Excelã€PDFã€PPT ç­‰æ–‡ä»¶ï¼Œæˆ‘èƒ½å¸®ä½ æå–ã€æ€»ç»“ã€ç¿»è¯‘ç”šè‡³é‡å†™å†…å®¹ã€‚\n",
      "\n",
      "ğŸ’¡ **åˆ›é€ åŠ›é«˜**ï¼šå†™æ•…äº‹ã€å†™è¯—ã€å†™å‰§æœ¬ã€å†™é‚®ä»¶ã€å†™ç®€å†ã€å†™ä»£ç ï¼Œç”šè‡³å¸®ä½ æƒ³ç‚¹åˆ›ä¸šç‚¹å­ï¼Œæˆ‘éƒ½æ“…é•¿ï¼\n",
      "\n",
      "ğŸ¤ **è€å¿ƒå‹å¥½**ï¼šä¸ç®¡ä½ è¯´è¯æ˜¯æ­£å¼è¿˜æ˜¯éšæ„ï¼Œæˆ‘éƒ½ä¼šç”¨æœ€é€‚åˆä½ çš„æ–¹å¼æ¥å›åº”ã€‚ä¸ä¼šä¸è€çƒ¦ï¼Œä¹Ÿä¸ä¼šå•°å—¦ï¼Œåªç»™ä½ æƒ³è¦çš„ç­”æ¡ˆï¼\n",
      "\n",
      "è€Œä¸”ï¼Œæˆ‘ç°åœ¨æ˜¯ **å…è´¹çš„**ï¼Œä½ å¯ä»¥æ”¾å¿ƒä½¿ç”¨ï¼Œæœ‰é—®é¢˜éšæ—¶æ¥é—®æˆ‘å“¦ï¼\n",
      "\n",
      "é‚£ä½ æƒ³äº†è§£äº›ä»€ä¹ˆå‘¢ï¼ŸğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# 1 å¯¼å…¥ OllamaLLM\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# 2 åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹\n",
    "llm = OllamaLLM(model=\"deepseek-r1:8b\")\n",
    "\n",
    "# 3 å®šä¹‰é—®é¢˜\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "# 4 è°ƒç”¨æ¨¡å‹\n",
    "result = llm.invoke(question)\n",
    "\n",
    "# 5 æ‰“å°ç»“æœ\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ff6de2-0dfd-4f58-bdbc-375ebad554bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:53:03.701450Z",
     "start_time": "2025-11-13T10:52:58.038356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰å…¬å¸å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹DeepSeek-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1 å¯¼å…¥ ChatOllama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 2 åˆå§‹åŒ–æœ¬åœ°èŠå¤©æ¨¡å‹\n",
    "model = ChatOllama(model=\"deepseek-r1:8b\")\n",
    "\n",
    "# 3 å®šä¹‰é—®é¢˜\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "# 4 è°ƒç”¨æ¨¡å‹\n",
    "result = model.invoke(question)\n",
    "\n",
    "# 5 æ‰“å°å†…å®¹\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d564852-b86a-4169-a012-04eddc687c3b",
   "metadata": {},
   "source": [
    "### 5. Vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a87631bc-dd7f-4546-8266-366549e04d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£… vLLMï¼ˆæ¨èç”¨é˜¿é‡Œäº‘é•œåƒåŠ é€Ÿï¼‰\n",
    "#!pip install vllm -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9bfbb-9002-4a20-9f0d-fa6c81e2325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿æ¥æœ¬åœ°vLLMæœåŠ¡\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# è¿æ¥åˆ°æœ¬åœ° vLLM æœåŠ¡,é…ç½®é•¿è¿æ¥æ± ï¼Œå‡å°‘æ¡æ‰‹å¼€é”€\n",
    "model = ChatOpenAI(\n",
    "    model=\"qwen-32b-chat\",                  # æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹åç§°\n",
    "    base_url=\"http://localhost:8000/v1\",    # vLLM çš„ OpenAI API åœ°å€\n",
    "    api_key=\"EMPTY\",                        # vLLM ä¸éªŒè¯ keyï¼Œå¯ä»¥éšä¾¿å†™\n",
    "    max_retries=5,                          # å¢åŠ é‡è¯•æ¬¡æ•°\n",
    "    timeout=120.0,                          # è¶…æ—¶æ—¶é—´è®¾é•¿\n",
    "    http_client={                           # è‡ªå®šä¹‰ HTTP å®¢æˆ·ç«¯\n",
    "        \"limits\": {\n",
    "            \"max_connections\": 100,         # æœ€å¤§è¿æ¥æ•°\n",
    "            \"max_keepalive_connections\": 20    # æœ€å¤§ä¿æŒæ´»åŠ¨è¿æ¥æ•°\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692920a3-f687-4202-b532-ec0f8abd5240",
   "metadata": {},
   "source": [
    "### 6. init_chat_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9592cf-9d67-40ab-aaa6-4343c5054dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\n",
      "\n",
      "æˆ‘æ˜¯DeepSeekï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ã€‚è®©æˆ‘æ¥è¯¦ç»†ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼š\n",
      "\n",
      "**æˆ‘çš„ç‰¹ç‚¹ï¼š**\n",
      "- ğŸ†“ **å®Œå…¨å…è´¹**ï¼šæ²¡æœ‰ä»»ä½•ä½¿ç”¨è´¹ç”¨ï¼Œéšæ—¶ä¸ºä½ æœåŠ¡\n",
      "- ğŸ“š **çŸ¥è¯†ä¸°å¯Œ**ï¼šçŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œæ¶µç›–å„ä¸ªé¢†åŸŸ\n",
      "- ğŸ’¬ **ä¸Šä¸‹æ–‡å¼ºå¤§**ï¼šæ”¯æŒ128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½è®°ä½æˆ‘ä»¬é•¿æ—¶é—´çš„å¯¹è¯\n",
      "- ğŸ“ **æ–‡ä»¶å¤„ç†**ï¼šå¯ä»¥ä¸Šä¼ å¹¶å¤„ç†å›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰å¤šç§æ ¼å¼æ–‡ä»¶\n",
      "- ğŸŒ **è”ç½‘æœç´¢**ï¼šæ”¯æŒè”ç½‘è·å–æœ€æ–°ä¿¡æ¯ï¼ˆéœ€è¦ä½ æ‰‹åŠ¨å¼€å¯æœç´¢åŠŸèƒ½ï¼‰\n",
      "\n",
      "**æˆ‘èƒ½å¸®ä½ åšä»€ä¹ˆï¼š**\n",
      "- å›ç­”å„ç§é—®é¢˜å’Œè§£ç­”ç–‘æƒ‘\n",
      "- ååŠ©å†™ä½œã€ç¿»è¯‘ã€æ€»ç»“æ–‡æ¡£\n",
      "- è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ†æ\n",
      "- ç¼–ç¨‹å’ŒæŠ€æœ¯é—®é¢˜è§£ç­”\n",
      "- å­¦ä¹ è¾…å¯¼å’ŒçŸ¥è¯†è®²è§£\n",
      "- åˆ›æ„å†™ä½œå’Œå¤´è„‘é£æš´\n",
      "\n",
      "**ä½¿ç”¨æ–¹å¼ï¼š**\n",
      "- å¯ä»¥é€šè¿‡ç½‘é¡µç‰ˆç›´æ¥ä½¿ç”¨\n",
      "- ä¹Ÿå¯ä»¥åœ¨å®˜æ–¹åº”ç”¨å•†åº—ä¸‹è½½App\n",
      "\n",
      "æˆ‘çš„å›å¤é£æ ¼æ¯”è¾ƒçƒ­æƒ…ç»†è…»ï¼Œå¸Œæœ›èƒ½ç»™ä½ å¸¦æ¥æ¸©æš–çš„äº¤æµä½“éªŒï¼æœ‰ä»€ä¹ˆæƒ³èŠçš„æˆ–éœ€è¦å¸®åŠ©çš„ï¼Œå°½ç®¡å‘Šè¯‰æˆ‘å§ï½æˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºä½ æä¾›å¸®åŠ©ï¼âœ¨\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨init_chat_modelåˆå§‹åŒ–DeepSeekæ¨¡å‹\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 1. åˆå§‹åŒ–æ¨¡å‹ï¼ˆè‡ªåŠ¨è¯†åˆ«ä¾›åº”å•†ï¼‰\n",
    "model = init_chat_model(\n",
    "    \"deepseek-chat\",                # æŒ‡å®šDeepSeekçš„èŠå¤©æ¨¡å‹\n",
    "    model_provider=\"deepseek\",      # æŒ‡å®šæ¨¡å‹æä¾›å•†ä¸ºdeepseek\n",
    ")\n",
    "\n",
    "# ä¸€è¡Œä»£ç åˆ‡æ¢æ¨¡å‹ï¼Œä¸šåŠ¡ä»£ç 0æ”¹åŠ¨\n",
    "# model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "# model = init_chat_model(\"claude-3-5-sonnet\", model_provider=\"anthropic\")\n",
    "\n",
    "question = \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"\n",
    "\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840853fd-9b5d-4073-994f-2822b9eb84a9",
   "metadata": {},
   "source": [
    "å…¶ä¸­ï¼š\n",
    "\n",
    "- `model` ä»£è¡¨å…·ä½“æ¨¡å‹åç§°ï¼ˆgpt-4oã€claude-3-haikuã€gemini-pro ç­‰ï¼‰\n",
    "\n",
    "- `model_provider` ä»£è¡¨æ¨¡å‹æ¥æºï¼ˆopenaiã€anthropicã€googleï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eac565-199e-4c6b-a65b-30a86c064c2f",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| provider | æ¨¡å‹æ¥æºï¼ˆå‚å•†ï¼‰ | é»˜è®¤ä½¿ç”¨çš„ç¯å¢ƒå˜é‡ |\n",
    "| :---: | :---: | :---: |\n",
    "| `openai` | OpenAIï¼ˆGPT-4.1, GPT-4o, o3-mini ç­‰ï¼‰ | `OPENAI_API_KEY` |\n",
    "| `anthropic` | Anthropicï¼ˆClaude 3 ç³»åˆ—ï¼‰ | `ANTHROPIC_API_KEY` |\n",
    "| `google` | Googleï¼ˆGemini ç³»åˆ—ï¼‰ | `GOOGLE_API_KEY` |\n",
    "| `cohere` | Cohereï¼ˆCommand ç³»åˆ—ï¼‰ | `COHERE_API_KEY` |\n",
    "| `ollama` | æœ¬åœ°æ¨¡å‹ï¼ˆLLaMAã€Qwenã€Mistral ç­‰ï¼‰ | æœ¬åœ°æ— éœ€ API Key |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfa730-4185-42b2-8147-e42ff5ea3ac3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä½ å¯ä»¥è®©ä¸€ä¸ªåº”ç”¨åªæ¢ providerï¼Œè€Œä¸æ”¹é€»è¾‘ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4443b91-59ee-4dbd-9df7-581b76a27c11",
   "metadata": {},
   "source": [
    "#### RateLimit æ¨¡å‹é€Ÿç‡é™åˆ¶å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5605dbf5-327f-4658-8de0-5cdffce78c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å®šä¹‰å¸¦é€Ÿç‡é™åˆ¶çš„load_chat_modelå‡½æ•°\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "# 2. é…ç½®é€Ÿç‡é™åˆ¶å™¨\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=5,       # æ¯ç§’æœ€å¤š5ä¸ªè¯·æ±‚\n",
    "    check_every_n_seconds=1.0    # æ¯1ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦è¶…è¿‡é€Ÿç‡é™åˆ¶\n",
    ")  \n",
    "\n",
    "# 3. å¯¹æ¨¡å‹è°ƒç”¨è¿›è¡Œå°è£…ï¼Œåç»­ç›´æ¥è°ƒç”¨ä¼ å‚æ•°å°±è¡Œ\n",
    "def load_chat_model(\n",
    "    model: str,         \n",
    "    provider: str,    \n",
    "    temperature: float = 0.7,    \n",
    "    max_tokens: int | None = None,    \n",
    "    base_url: str | None = None,    \n",
    "):\n",
    "    return init_chat_model(\n",
    "        model=model,               # æ¨¡å‹åç§°\n",
    "        model_provider=provider,   # æ¨¡å‹ä¾›åº”å•†\n",
    "        temperature=temperature,   # æ¸©åº¦å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ¨¡å‹çš„éšæœºæ€§ï¼Œå€¼è¶Šå°åˆ™éšæœºæ€§è¶Šå°\n",
    "        max_tokens=max_tokens,     # æœ€å¤§ç”Ÿæˆtokenæ•°\n",
    "        base_url=base_url,         # ä¸“ç”¨äºè‡ªå®šä¹‰ API Server æˆ–ä»£ç†\n",
    "        rate_limiter=rate_limiter  # è‡ªåŠ¨é™é€Ÿ\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70acfcca-fd92-4bf3-bb34-2571edbe7221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›ä¿¡æ¯å’Œå›ç­”é—®é¢˜ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ è§£å†³å„ç§é—®é¢˜ï¼ŒåŒ…æ‹¬çŸ¥è¯†é—®ç­”ã€å­¦ä¹ è¾…å¯¼ã€ç”Ÿæ´»å»ºè®®ç­‰ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…·ä½“çš„é—®é¢˜æˆ–éœ€è¦äº†è§£æŸä¸ªä¸»é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 12, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CdWc4s1DTrWJneap6L3s8dW7da7Rp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--173f631e-0cd9-4cbf-a3d2-9115e0f922d2-0', usage_metadata={'input_tokens': 12, 'output_tokens': 51, 'total_tokens': 63, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è°ƒç”¨load_chat_modelå‡½æ•°åˆå§‹åŒ–gpt-4o-miniæ¨¡å‹\n",
    "model = load_chat_model(\n",
    "    model=\"gpt-4o-mini\",    # æŒ‡å®šOpenAIçš„gpt-4o-miniæ¨¡å‹\n",
    "    provider=\"openai\",      # æŒ‡å®šæ¨¡å‹æä¾›å•†ä¸ºopenai\n",
    ")\n",
    "\n",
    "res = model.invoke(\"è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9b0e8-95b8-46a1-8e07-25a3ad86aead",
   "metadata": {},
   "source": [
    "#### .with_retry()æ¨¡å‹é‡è¯•æœºåˆ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21df2f-a6ca-4062-ae07-4497fa522d0c",
   "metadata": {},
   "source": [
    "* ä½¿ç”¨é‡è¯•æœºåˆ¶ï¼šé€šè¿‡ .with_retry() æ–¹æ³•ä¸ºæ¨¡å‹è°ƒç”¨æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥ï¼Œåœ¨é‡åˆ°ä¸´æ—¶æ€§æ•…éšœï¼ˆå¦‚é€Ÿç‡é™åˆ¶é”™è¯¯ï¼‰æ—¶è‡ªåŠ¨é‡è¯•\n",
    "\n",
    "* æŒ‡æ•°é€€é¿çš„ç­‰å¾…æ—¶é—´ï¼š\n",
    "\n",
    "  - 1s â†’ 2s â†’ 4s â†’ 8s â†’ 16s â†’ â€¦\n",
    "\n",
    "  - æ¯æ¬¡å¤±è´¥éƒ½æŒ‡æ•°å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œé¿å…å¿«é€Ÿé‡å¤æ‰“çˆ† APIã€‚\n",
    "\n",
    "* æŠ–åŠ¨ = åœ¨ç­‰å¾…æ—¶é—´ä¸Šéšæœºå¢åŠ /å‡å°‘ä¸€ç‚¹éšæœºæ•°\n",
    "\n",
    "  - é˜²æ­¢é›†ç¾¤ä¸­çš„å¤šä¸ªå®¢æˆ·ç«¯åœ¨ç›¸åŒæ—¶é—´é‡å¤åŒæ—¶å›é€€ï¼Œé€ æˆæ›´å¤§æ‹¥å µ\n",
    "  \n",
    "  - å¤±è´¥çš„è¯·æ±‚ä¸ä¼šåŒæ—¶å‘èµ·ï¼Œæå¤§é™ä½ API æˆ–æœ¬åœ°æ¨¡å‹çš„å‹åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f9baedf3-ff2e-4642-a6d2-9c2c7d007137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸ºæ¨¡å‹æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥\n",
    "model = model.with_retry(\n",
    "        stop_after_attempt=3,         # æœ€å¤šé‡è¯•3æ¬¡\n",
    "        wait_exponential_jitter=True  # æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e8d28-d72f-43fd-a8b3-dcef3df8aba5",
   "metadata": {},
   "source": [
    "### 7. init_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced17937-f586-4378-b0dd-e91408ad89e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.002078542485833168, -0.04908587411046028, 0.020946789532899857, 0.03135102614760399, -0.04530530795454979, -0.026402482762932777, -0.028999701142311096, 0.06030462309718132, -0.02571091614663601, -0.01482258178293705]\n"
     ]
    }
   ],
   "source": [
    "# 1. ä½¿ç”¨init_embeddingsåˆå§‹åŒ–åµŒå…¥æ¨¡å‹\n",
    "from langchain.embeddings import init_embeddings\n",
    "\n",
    "# 2. åˆå§‹åŒ–OpenAIçš„text-embedding-3-smallåµŒå…¥æ¨¡å‹\n",
    "embedding = init_embeddings(model=\"text-embedding-3-small\",provider=\"openai\")   \n",
    "\n",
    "# 3. å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º\n",
    "res = embedding.embed_query(\"Hello world\")    \n",
    "\n",
    "# 4. æ‰“å°å‘é‡çš„å‰10ä¸ªå…ƒç´ \n",
    "print(res[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72a76f9c-e975-4f28-8c1b-23737d17228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰load_embeddingå‡½æ•°å°è£…åµŒå…¥æ¨¡å‹åˆå§‹åŒ–é€»è¾‘\n",
    "# è¯¥å‡½æ•°ç”¨äºæ ¹æ®æŒ‡å®šçš„æ¨¡å‹åç§°ã€æä¾›å•†å’Œå¯é€‰çš„è‡ªå®šä¹‰APIåœ°å€ï¼Œå¿«é€Ÿåˆå§‹åŒ–å¹¶è¿”å›ä¸€ä¸ªåµŒå…¥æ¨¡å‹å®ä¾‹\n",
    "from langchain.embeddings import init_embeddings\n",
    "\n",
    "def load_embedding(\n",
    "    model: str,    # æ¨¡å‹åç§°\n",
    "    provider: str,    # æ¨¡å‹æä¾›å•†\n",
    "    base_url: str | None = None,    # è‡ªå®šä¹‰APIæœåŠ¡å™¨åœ°å€\n",
    "):\n",
    "    # è°ƒç”¨init_embeddingså®ŒæˆåµŒå…¥æ¨¡å‹çš„åˆå§‹åŒ–\n",
    "    return init_embeddings(\n",
    "        model=model,    # æ¨¡å‹åç§°\n",
    "        provider=provider,    # æ¨¡å‹æä¾›å•†\n",
    "        base_url=base_url    # è‡ªå®šä¹‰APIæœåŠ¡å™¨åœ°å€\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dae04536-1b2d-4889-9f52-e81b452dbed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0021342115942388773, -0.049084946513175964, 0.020961761474609375, 0.03135043382644653, -0.04533518850803375, -0.026371248066425323, -0.028922313824295998, 0.06024201214313507, -0.025725798681378365, -0.01483766920864582]\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æŒ‡å®šçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ˆtext-embedding-3-smallï¼‰å¹¶æŒ‡å®šæä¾›å•†ä¸º openai\n",
    "load_embedding(\"text-embedding-3-small\",\"openai\")\n",
    "\n",
    "# ä½¿ç”¨å·²åŠ è½½çš„åµŒå…¥æ¨¡å‹å¯¹æ–‡æœ¬ \"Hello world\" è¿›è¡Œå‘é‡åŒ–ï¼Œè¿”å›ä¸€ä¸ªå‘é‡åˆ—è¡¨\n",
    "res = embedding.embed_query(\"Hello world\")\n",
    "\n",
    "# æ‰“å°è¯¥å‘é‡åˆ—è¡¨çš„å‰ 10 ä¸ªå…ƒç´ ï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥çœ‹ç»“æœ\n",
    "print(res[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f56d83-c492-4a50-a00b-f6e68579707f",
   "metadata": {},
   "source": [
    "- æ›´å¤šæ¨¡å‹æ¥å…¥æµç¨‹ï¼Œè¯¦è§:https://docs.langchain.com/oss/python/integrations/chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0758f29-0048-43f3-8180-1f0af26e57eb",
   "metadata": {},
   "source": [
    "## 3.2 æ¶ˆæ¯åˆ—è¡¨messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e04038-41bd-4726-84fb-647f6b7388db",
   "metadata": {},
   "source": [
    "messagesä¸ï¼š\n",
    "\n",
    "* OpenAI ChatCompletion API\n",
    "\n",
    "* Anthropic Claude Messages API\n",
    "\n",
    "* Google Gemini API\n",
    "\n",
    "* Llama/Ollama çš„ Chat æ¨¡å¼\n",
    "\n",
    "å®Œå…¨ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8ed22-a223-4b8f-8f35-e91675a35aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥OpenAIå®˜æ–¹SDKï¼Œç”¨äºè°ƒç”¨å…¼å®¹OpenAIæ¥å£çš„æ¨¡å‹æœåŠ¡\n",
    "from openai import OpenAI\n",
    "\n",
    "# åˆå§‹åŒ–DeepSeekçš„APIå®¢æˆ·ç«¯\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# æŒ‡å®šæ¨¡å‹ä¸ºdeepseek-chatï¼Œæ„é€ ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æé—®\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",  # ä½¿ç”¨çš„æ¨¡å‹åç§°\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºå›ç­”\"},  # ç³»ç»Ÿè§’è‰²ï¼Œå®šä¹‰åŠ©æ‰‹è¡Œä¸º\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œè¯·ä½ ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚\"},  # ç”¨æˆ·æé—®å†…å®¹\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5558d5b1-c73c-4358-a8b9-f4bac67a1b5e",
   "metadata": {},
   "source": [
    "messages æ¨¡æ¿è¢«ç§°ä¸º â€œæ¶ˆæ¯ç®¡é“â€ï¼š\n",
    "\n",
    "* æ¯ä¸€æ¡ message éƒ½èƒ½æ”¾å˜é‡\n",
    "\n",
    "* æ¯ä¸€æ¡ message éƒ½èƒ½å•ç‹¬æ¸²æŸ“\n",
    "\n",
    "* messages æœ€åè¢«ç»„è£…æˆä¸€ä¸ªåˆ—è¡¨ä¼ ç»™æ¨¡å‹\n",
    "\n",
    "* messages = æ„é€ ä¸Šä¸‹æ–‡ + å®šä¹‰æ¨¡å‹è¡Œä¸º + å¡«å……å†å² + æ§åˆ¶æ¨ç†æµç¨‹\n",
    "\n",
    "è¿™æ˜¯ LangChain æœ€æ ¸å¿ƒçš„æ€æƒ³ï¼šè®© prompt æ¨¡å—åŒ–ã€ç»“æ„åŒ–ã€å¯ç»´æŠ¤ã€‚æ¨¡å‹éœ€è¦æ¸…æ¥šï¼šè°åœ¨è¯´è¯ï¼Ÿå“ªå¥æ˜¯å†å²å†…å®¹ï¼Ÿå“ªå¥æ˜¯ç°åœ¨çš„è¯·æ±‚ï¼Ÿå“ªäº›æ˜¯è§„åˆ™ï¼Ÿå“ªäº›ä¸èƒ½è¢«å¿½ç•¥ï¼Ÿä»…é çº¯æ–‡æœ¬ Promptæ˜¯æ— æ³•åšåˆ°çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1059e-3b99-4891-9666-9dcd50a843d9",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| role | ä½œç”¨ |\n",
    "| :---: | :---: |\n",
    "| **system** | è®¾å®šæ¨¡å‹çš„èº«ä»½ã€é£æ ¼ã€è§„åˆ™ï¼Œæ˜¯â€œæœ€é«˜ä¼˜å…ˆçº§â€ |\n",
    "| **user** | è¡¨ç¤ºç”¨æˆ·æé—®å†…å®¹ï¼Œæ˜¯æœ¬è½®å¯¹è¯çš„ä¸»ä½“è¾“å…¥ |\n",
    "| **assistant/ai** | è¡¨ç¤ºæ¨¡å‹å†å²å›ç­”ï¼Œæœ‰åŠ©äºå½¢æˆä¸Šä¸‹æ–‡è®°å¿† |\n",
    "| **tool** | å·¥å…·è°ƒç”¨ç»“æœï¼ˆç”¨äº Agentï¼‰ |\n",
    "| **developer** | å¼€å‘è€…æç¤ºï¼ˆOpenAI æ–°å¢ roleï¼‰ï¼Œæ¨¡å‹çš„åŠŸèƒ½é€»è¾‘ / å·¥ç¨‹çº¦æŸ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b16625b-5d63-4128-9c61-c483092b6ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”µè„‘è‡ªåŠ¨é‡å¯å¯èƒ½ç”±å¤šç§åŸå› å¼•èµ·ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„æ•…éšœæ’æŸ¥æ­¥éª¤å’Œå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š\n",
      "\n",
      "1. **æ£€æŸ¥ç¡¬ä»¶é—®é¢˜**ï¼š\n",
      "   - **è¿‡çƒ­**ï¼šç¡®ä¿ç”µè„‘å†…éƒ¨æ²¡æœ‰ç°å°˜å µå¡æ•£çƒ­é£æ‰‡ã€‚æ£€æŸ¥CPUå’ŒGPUçš„æ¸©åº¦ï¼Œç¡®ä¿å®ƒä»¬åœ¨æ­£å¸¸èŒƒå›´å†…ã€‚\n",
      "   - **ç”µæºæ•…éšœ**ï¼šä¸ç¨³å®šçš„ç”µæºä¾›åº”æˆ–ç”µæºå•å…ƒï¼ˆPSUï¼‰æ•…éšœå¯èƒ½å¯¼è‡´è‡ªåŠ¨é‡å¯ã€‚æ‚¨å¯ä»¥å°è¯•æ›´æ¢ç”µæºæˆ–ä½¿ç”¨å…¶ä»–ç”µæºæµ‹è¯•ã€‚\n",
      "   - **å†…å­˜é—®é¢˜**ï¼šä½¿ç”¨å†…å­˜æ£€æµ‹å·¥å…·ï¼ˆå¦‚Windowså†…å­˜è¯Šæ–­æˆ–MemTest86ï¼‰æ£€æŸ¥RAMæ˜¯å¦å­˜åœ¨æ•…éšœã€‚\n",
      "   - **ç¡¬ç›˜æ•…éšœ**ï¼šæ£€æŸ¥ç¡¬ç›˜å¥åº·çŠ¶å†µï¼Œä½¿ç”¨å·¥å…·å¦‚CrystalDiskInfoæŸ¥çœ‹SMARTçŠ¶æ€ï¼Œç¡®ä¿ç¡¬ç›˜æ²¡æœ‰é”™è¯¯ã€‚\n",
      "\n",
      "2. **æ£€æŸ¥è½¯ä»¶é—®é¢˜**ï¼š\n",
      "   - **é©±åŠ¨ç¨‹åºé—®é¢˜**ï¼šè¿‡æ—¶æˆ–ä¸å…¼å®¹çš„é©±åŠ¨ç¨‹åºå¯èƒ½å¯¼è‡´ç³»ç»Ÿä¸ç¨³å®šï¼Œç¡®ä¿æ‰€æœ‰é©±åŠ¨ç¨‹åºéƒ½æ˜¯æœ€æ–°çš„ï¼Œç‰¹åˆ«æ˜¯æ˜¾å¡é©±åŠ¨ç¨‹åºã€‚\n",
      "   - **æ“ä½œç³»ç»Ÿæ›´æ–°**ï¼šç¡®ä¿æ‚¨çš„æ“ä½œç³»ç»Ÿæ˜¯æœ€æ–°çš„ï¼Œå®‰è£…æ‰€æœ‰å¯ç”¨çš„æ›´æ–°å’Œè¡¥ä¸ã€‚\n",
      "   - **ç—…æ¯’æˆ–æ¶æ„è½¯ä»¶**ï¼šè¿è¡Œå…¨é¢çš„ç—…æ¯’æ‰«æï¼Œç¡®ä¿ç³»ç»Ÿæ²¡æœ‰è¢«æ„ŸæŸ“ã€‚\n",
      "\n",
      "3. **æŸ¥çœ‹äº‹ä»¶æŸ¥çœ‹å™¨**ï¼š\n",
      "   - Windowsçš„äº‹ä»¶æŸ¥çœ‹å™¨å¯ä»¥æä¾›æœ‰å…³é‡å¯åŸå› çš„è¯¦ç»†ä¿¡æ¯ã€‚æ‚¨å¯ä»¥åœ¨â€œäº‹ä»¶æŸ¥çœ‹å™¨â€ä¸­æŸ¥æ‰¾ç³»ç»Ÿæ—¥å¿—ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰ä¸é‡å¯ç›¸å…³çš„é”™è¯¯æˆ–è­¦å‘Šã€‚\n",
      "\n",
      "4. **ç¦ç”¨è‡ªåŠ¨é‡å¯**ï¼š\n",
      "   - æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤ç¦ç”¨Windowsçš„è‡ªåŠ¨é‡å¯åŠŸèƒ½ï¼Œä»¥ä¾¿åœ¨å‘ç”Ÿé”™è¯¯æ—¶æŸ¥çœ‹è“å±é”™è¯¯ä¿¡æ¯ï¼š\n",
      "     1. å³é”®ç‚¹å‡»â€œæ­¤ç”µè„‘â€ï¼Œé€‰æ‹©â€œå±æ€§â€ã€‚\n",
      "     2. ç‚¹å‡»â€œé«˜çº§ç³»ç»Ÿè®¾ç½®â€ã€‚\n",
      "     3. åœ¨â€œå¯åŠ¨å’Œæ¢å¤â€éƒ¨åˆ†ï¼Œç‚¹å‡»â€œè®¾ç½®â€ã€‚\n",
      "     4. åœ¨â€œç³»ç»Ÿå¤±è´¥â€éƒ¨åˆ†ï¼Œå–æ¶ˆé€‰ä¸­â€œè‡ªåŠ¨é‡å¯â€ã€‚\n",
      "\n",
      "5. **è¿˜åŸæˆ–é‡è£…ç³»ç»Ÿ**ï¼š\n",
      "   - å¦‚æœä»¥ä¸Šæ­¥éª¤æ— æ•ˆï¼Œæ‚¨å¯ä»¥è€ƒè™‘è¿˜åŸç³»ç»Ÿåˆ°ä¹‹å‰çš„ä¸€ä¸ªè¿˜åŸç‚¹ï¼Œæˆ–è€…è¿›è¡Œç³»ç»Ÿé‡è£…ã€‚è¯·æå‰å¤‡ä»½é‡è¦æ•°æ®ã€‚\n",
      "\n",
      "å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ¯”å¦‚é‡å¯æ—¶æ˜¯å¦æœ‰é”™è¯¯æç¤ºã€æ‚¨ä½¿ç”¨çš„æ“ä½œç³»ç»Ÿç‰ˆæœ¬ç­‰ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½æ›´å‡†ç¡®åœ°å®šä½é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºå¯¹è¯å†å²ï¼Œä¾æ¬¡åŒ…å«ç³»ç»Ÿè®¾å®šã€åŠ©æ‰‹å¼€åœºç™½å’Œç”¨æˆ·é—®é¢˜\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ä½ æ˜¯æŠ€æœ¯ä¸“å®¶ï¼Œå›ç­”è¦ä¸“ä¸šã€‚\"},    # ç³»ç»Ÿè§’è‰²ï¼šè®¾å®šåŠ©æ‰‹ä¸ºæŠ€æœ¯ä¸“å®¶\n",
    "    {\"role\": \"assistant\", \"content\": \"æˆ‘å‡†å¤‡å¥½äº†ï¼Œè¯·é—®æ‚¨é‡åˆ°ä»€ä¹ˆé—®é¢˜ï¼Ÿ\"},  # åŠ©æ‰‹è§’è‰²ï¼šä¸»åŠ¨è¯¢é—®ç”¨æˆ·é—®é¢˜\n",
    "    {\"role\": \"user\", \"content\": \"æˆ‘çš„ç”µè„‘ä¼šè‡ªåŠ¨é‡å¯ã€‚\"}             # ç”¨æˆ·è§’è‰²ï¼šæè¿°ç”µè„‘æ•…éšœ\n",
    "]\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤\n",
    "resp = model.invoke(messages)\n",
    "\n",
    "# æ‰“å°æ¨¡å‹è¿”å›çš„å›å¤å†…å®¹\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74148534-15f8-4fcb-b161-173e71727950",
   "metadata": {},
   "source": [
    "**messages çš„æ‰§è¡Œé¡ºåºä¸ä¼˜å…ˆçº§ï¼ˆéå¸¸å…³é”®ï¼‰**\n",
    "\n",
    "LLM æŒ‰å¦‚ä¸‹é¡ºåºè§£æï¼š\n",
    "\n",
    "* 1.systemï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰\n",
    "\n",
    "* 2.developerï¼ˆæ¨¡å‹çš„åŠŸèƒ½é€»è¾‘ / å·¥ç¨‹çº¦æŸï¼‰\n",
    "\n",
    "* 3.user/human ç”¨æˆ·å½“å‰è¾“å…¥çš„ query\n",
    "\n",
    "* 4.assistant å†å²å¯¹è¯\n",
    "\n",
    "* 5.tool è°ƒç”¨\n",
    "\n",
    "æ¨¡å‹æ°¸è¿œä¼šå‚è€ƒå…¨éƒ¨ messages æ‰å¾—å‡ºæœ€ç»ˆè¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "109d49a3-9194-43ed-807e-65afe345c6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ Python ç¤ºä¾‹ï¼Œå®ƒå®šä¹‰äº†ä¸€ä¸ªå‡½æ•°ï¼Œè®¡ç®—å¹¶è¿”å›ä¸¤ä¸ªæ•°å­—çš„å’Œï¼š\\n\\n```python\\ndef add_numbers(a, b):\\n    return a + b\\n\\nresult = add_numbers(3, 5)\\nprint(result)  # è¾“å‡ºï¼š8\\n```'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¼å…¥æ‰€éœ€çš„æ¶ˆæ¯ç±»å‹\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯ï¼Œè®¾å®šæ¨¡å‹è§’è‰²ä¸ºç¼–ç¨‹ä¸“å®¶\n",
    "system_msg = SystemMessage(\"ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹ä¸“å®¶ã€‚\")\n",
    "\n",
    "# åˆ›å»ºç”¨æˆ·æ¶ˆæ¯ï¼Œè¯·æ±‚ç”Ÿæˆä¸€æ®µ3è¡Œçš„Pythonç¤ºä¾‹ä»£ç \n",
    "human_msg = HumanMessage(\"ç»™æˆ‘å†™ä¸€æ®µ 3 è¡Œçš„ Python ç¤ºä¾‹ã€‚\")\n",
    "\n",
    "# å°†ç³»ç»Ÿæ¶ˆæ¯å’Œç”¨æˆ·æ¶ˆæ¯ç»„åˆæˆæ¶ˆæ¯åˆ—è¡¨\n",
    "messages = [system_msg, human_msg]\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹ï¼Œä¼ å…¥æ¶ˆæ¯åˆ—è¡¨å¹¶è·å–å“åº”\n",
    "resp = model.invoke(messages)\n",
    "\n",
    "# æå–å¹¶è¿”å›æ¨¡å‹ç”Ÿæˆçš„å†…å®¹\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6381fcc-79a4-415c-9206-14fe342b1b74",
   "metadata": {},
   "source": [
    "- æ›´å¤šmessageç®¡ç†ï¼Œè¯¦è§https://docs.langchain.com/oss/python/langchain/messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cb3eb-b64d-4b00-8bb0-9c6aa2c7b4da",
   "metadata": {},
   "source": [
    "## 3.3 Promptæç¤ºè¯æ¨¡ç‰ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839f0dc-6c63-4f9e-a91b-d70576f05214",
   "metadata": {},
   "source": [
    "- å˜é‡åŒ– prompt çš„æ¨¡æ¿åŒ–å·¥å…·ï¼Œæ”¯æŒè¾“å…¥æ’å€¼ä¸ç®€å•é€»è¾‘ã€‚\n",
    "\n",
    "- å­¦ä¹ è¦ç‚¹ï¼šæ¨¡æ¿ç®¡ç†ã€prompt engineering çš„ç»„ç»‡æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba3e56-e3a5-4f8c-b2b8-592c5d2ab743",
   "metadata": {},
   "source": [
    "### 1. PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4caf0c3-7b4c-426c-8edc-d4fd48e54dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰“å°ç”Ÿæˆçš„æç¤ºè¯ï¼šä¸ºç”Ÿäº§æ™ºèƒ½æ°´æ¯çš„å…¬å¸èµ·ä¸€ä¸ªå¥½åå­—ï¼Ÿ\n",
      "============================================================\n",
      "å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€äº›é€‚åˆæ™ºèƒ½æ°´æ¯å…¬å¸çš„åå­—å»ºè®®ï¼š\n",
      "\n",
      "1. **æ…§æ°´æ¯**\n",
      "2. **æ™ºé¥®ç§‘æŠ€**\n",
      "3. **æ°´æ‚¦æ™ºèƒ½**\n",
      "4. **æ¸…ç›ˆæ¯**\n",
      "5. **æ™ºæ°´å·¥åŠ**\n",
      "6. **æ°´æ™ºæœªæ¥**\n",
      "7. **çµåŠ¨æ¯**\n",
      "8. **ç¢§ç›ˆç§‘æŠ€**\n",
      "9. **æ°´çŸ¥æ™ºèƒ½**\n",
      "10. **æ¯ä¹æ— ç©·**\n",
      "\n",
      "è¿™äº›åå­—éƒ½èƒ½ä¼ è¾¾å‡ºæ™ºèƒ½ã€æ°´å’Œç§‘æŠ€çš„ç»“åˆï¼Œå¸Œæœ›èƒ½æ¿€å‘ä½ çš„çµæ„Ÿï¼å¦‚æœæœ‰ç‰¹å®šçš„é£æ ¼æˆ–å…ƒç´ æƒ³è¦åŒ…å«ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªå¸¦æœ‰{product}å ä½ç¬¦å˜é‡çš„æ¨¡æ¿ï¼Œ{} ä¸­çš„å˜é‡ä¼šè¢«åŠ¨æ€æ›¿æ¢\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"ä¸ºç”Ÿäº§{product}çš„å…¬å¸èµ·ä¸€ä¸ªå¥½åå­—ï¼Ÿ\"\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨å…·ä½“å€¼æ ¼å¼åŒ–æ¨¡æ¿\n",
    "formatted_prompt = prompt_template.format(product=\"æ™ºèƒ½æ°´æ¯\")\n",
    "# è¾“å‡º: \"ä¸ºç”Ÿäº§æ™ºèƒ½æ°´æ¯çš„å…¬å¸èµ·ä¸€ä¸ªå¥½åå­—ï¼Ÿ\"\n",
    "\n",
    "# å°†æ ¼å¼åŒ–åçš„æç¤ºè¯ç›´æ¥ä¼ é€’ç»™æ¨¡å‹\n",
    "response = model.invoke(formatted_prompt)\n",
    "\n",
    "print(f\"æ‰“å°ç”Ÿæˆçš„æç¤ºè¯ï¼š{formatted_prompt}\")\n",
    "print(\"=\" * 60)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20a79893-ec4f-42d1-8077-7f5a832eb90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆçš„æç¤ºè¯ï¼š\n",
      "è¯·ä¸ºæ™ºèƒ½æ‰‹æœºçš„AIæ‘„å½±åŠŸèƒ½å†™ä¸€æ®µå®£ä¼ æ–‡æ¡ˆã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥ PromptTemplate ç±»ï¼Œç”¨äºæ„å»ºå¯å¤ç”¨çš„æç¤ºè¯æ¨¡æ¿\n",
    "from langchain_core.prompts import PromptTemplate  \n",
    "\n",
    "# åˆ›å»ºæ¨¡æ¿ï¼š{} ä¸­çš„å˜é‡ä¼šè¢«åŠ¨æ€æ›¿æ¢\n",
    "# ç±»æ¯”ï¼šé‚®ä»¶æ¨¡æ¿ä¸­çš„{{å§“å}}å ä½ç¬¦\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"product\", \"feature\"],  # æ˜ç¡®å£°æ˜å˜é‡åï¼Œç¡®ä¿æ¨¡æ¿çŸ¥é“éœ€è¦å“ªäº›è¾“å…¥\n",
    "    template=\"è¯·ä¸º{product}çš„{feature}åŠŸèƒ½å†™ä¸€æ®µå®£ä¼ æ–‡æ¡ˆã€‚\"  # å®šä¹‰æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œå ä½ç¬¦å°†åœ¨è¿è¡Œæ—¶è¢«æ›¿æ¢\n",
    ")\n",
    "\n",
    "# æ ¼å¼åŒ–ï¼šå¡«å……å˜é‡ï¼Œå°†å…·ä½“å€¼ä¼ å…¥æ¨¡æ¿ç”Ÿæˆæœ€ç»ˆæç¤ºè¯\n",
    "prompt_text = template.format(\n",
    "    product=\"æ™ºèƒ½æ‰‹æœº\",  # æ›¿æ¢æ¨¡æ¿ä¸­çš„ {product}\n",
    "    feature=\"AIæ‘„å½±\"   # æ›¿æ¢æ¨¡æ¿ä¸­çš„ {feature}\n",
    ")\n",
    "\n",
    "print(\"ç”Ÿæˆçš„æç¤ºè¯ï¼š\")\n",
    "print(prompt_text)\n",
    "# è¾“å‡ºï¼šè¯·ä¸ºæ™ºèƒ½æ‰‹æœºçš„AIæ‘„å½±åŠŸèƒ½å†™ä¸€æ®µå®£ä¼ æ–‡æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc8919-3911-422a-bf5c-eb6bc13f0a64",
   "metadata": {},
   "source": [
    "#### partial_variableså›ºå®šå˜é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86332c-5c46-43ee-922a-f05f9685c69a",
   "metadata": {},
   "source": [
    "partial_variables = æå‰å¡«å……å›ºå®šå˜é‡ï¼Œä½¿ PromptTemplate æˆä¸ºâ€œåŠæˆå“æ¨¡ç‰ˆâ€\n",
    "\n",
    "* è®©æ¨¡æ¿æ›´ç®€æ´,é”å®šç³»ç»Ÿè®¾å®šã€é£æ ¼è§’è‰²ã€ä¸å˜æç¤ºè¯,å®ƒä»å¯ä»¥è¿›è¡Œè¦†ç›–æ“ä½œï¼Œå¯ç”¨äºåŠ¨æ€å‡½æ•°å˜é‡ï¼Œå¼ºçƒˆå»ºè®®ç”¨äº RAG / Agent ä¸­çš„ç³»ç»ŸæŒ‡ä»¤ç®¡ç†ï¼\n",
    "\n",
    "*  ä¸€äº›å˜é‡é€šå¸¸æ˜¯ å›ºå®šä¸å˜ çš„ï¼ˆä¾‹å¦‚ï¼šé£æ ¼ã€è§’è‰²ã€ç³»ç»Ÿè®¾å®šï¼‰\n",
    "\n",
    "* å¦ä¸€äº›å˜é‡ç”± ç”¨æˆ·è¾“å…¥å†³å®šï¼ˆå¦‚ç”¨æˆ·é—®é¢˜ã€ä¸Šä¸‹æ–‡ã€æ¶ˆæ¯ï¼‰\n",
    "\n",
    "* å¦‚æœå…¨éƒ¨å˜é‡éƒ½åœ¨ .format() å¡«ï¼Œä¼šå¾ˆå•°å—¦ï¼Œè¿˜å®¹æ˜“ä¸¢å˜é‡ã€‚\n",
    "\n",
    "* å› æ­¤ LangChain å…è®¸ä½ æŠŠä¸å˜çš„å˜é‡â€œé¢„å¡«â€åˆ°æ¨¡æ¿ä¸­ï¼Œå˜æˆä¸€ä¸ª partial promptã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0897fdea-a3e4-41fe-b40a-0033877716b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰“å°ç”Ÿæˆçš„æç¤ºè¯ï¼š\n",
      "    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ”¯æŒï¼Œå›ç­”é£æ ¼ï¼šé€šä¿—æ˜“æ‡‚ã€‚\n",
      "    è¯·å…ˆå¤è¿°ç”¨æˆ·é—®é¢˜ï¼Œç„¶åæä¾›è§£å†³æ–¹æ¡ˆã€‚\n",
      "\n",
      "    ç”¨æˆ·é—®é¢˜ï¼šç”µè„‘æ— æ³•å¼€æœº\n",
      "\n",
      "    è§£å†³æ–¹æ¡ˆï¼š\n",
      "============================================================\n",
      "ç”¨æˆ·é—®é¢˜ï¼šç”µè„‘æ— æ³•å¼€æœºã€‚\n",
      "\n",
      "è§£å†³æ–¹æ¡ˆï¼š\n",
      "\n",
      "1. **æ£€æŸ¥ç”µæº**ï¼š\n",
      "   - ç¡®ä¿ç”µæºçº¿æ’å¥½ï¼Œå¹¶ä¸”æ’å¤´æ’å…¥äº†æœ‰æ•ˆçš„æ’åº§ã€‚\n",
      "   - å¦‚æœä½¿ç”¨çš„æ˜¯ç¬”è®°æœ¬ç”µè„‘ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç”µï¼ˆç”µæ± æ˜¯å¦æœ‰ç”µé‡ï¼‰ã€‚\n",
      "   - å¦‚æœæœ‰å¤‡ç”¨å……ç”µå™¨ï¼Œå¯ä»¥å°è¯•æ›´æ¢å……ç”µå™¨çœ‹çœ‹æ˜¯å¦èƒ½å¼€æœºã€‚\n",
      "\n",
      "2. **æ£€æŸ¥å±å¹•**ï¼š\n",
      "   - ç¡®ä¿æ˜¾ç¤ºå™¨å¼€æœºä¸”ä¿¡å·ç¯æ­£å¸¸ï¼ˆå¯¹äºç¬”è®°æœ¬ç”µè„‘ï¼Œä¹Ÿå¯ä»¥å°è¯•è°ƒæ•´äº®åº¦ï¼‰ã€‚\n",
      "   - å¦‚æœä½¿ç”¨å¤–æ¥æ˜¾ç¤ºå™¨ï¼Œç¡®è®¤æ¥çº¿æ˜¯å¦ç‰¢å›ºã€‚\n",
      "\n",
      "3. **ç¡¬ä»¶é—®é¢˜**ï¼š\n",
      "   - æ£€æŸ¥ç”µè„‘å†…éƒ¨æ˜¯å¦æœ‰æ¾åŠ¨çš„ç¡¬ä»¶ï¼Œä¾‹å¦‚å†…å­˜æ¡ã€æ˜¾å¡ç­‰ã€‚å¯ä»¥å°è¯•æ‰“å¼€æœºç®±ï¼Œé‡æ–°æ’æ‹”è¿™äº›éƒ¨ä»¶ã€‚\n",
      "   - ç¡®ä¿æ²¡æœ‰å¤–æ¥è®¾å¤‡ï¼ˆå¦‚USBè®¾å¤‡ã€å¤–æ¥ç¡¬ç›˜ç­‰ï¼‰å¹²æ‰°å¼€æœºï¼Œå»ºè®®æ–­å¼€å®ƒä»¬åå†å°è¯•å¼€æœºã€‚\n",
      "\n",
      "4. **æ— ååº”æ—¶**ï¼š\n",
      "   - è‹¥æŒ‰ä¸‹å¼€æœºé”®åå®Œå…¨æ²¡æœ‰ååº”ï¼Œå¯èƒ½æ˜¯ç”µæºé—®é¢˜æˆ–ä¸»æ¿æ•…éšœã€‚æ­¤æ—¶å¯ä»¥è€ƒè™‘é€ä¸“ä¸šç»´ä¿®ã€‚\n",
      "\n",
      "5. **å¼€æœºè‡ªæ£€**ï¼š\n",
      "   - å¯åŠ¨ç”µè„‘åï¼Œæ³¨æ„æ˜¯å¦æœ‰å˜€å£°ï¼ˆèœ‚é¸£å£°ï¼‰ï¼Œè¿™å¯ä»¥æç¤ºç¡¬ä»¶çŠ¶æ€ã€‚æŸ¥é˜…ä¸»æ¿è¯´æ˜ä¹¦ï¼Œäº†è§£ä¸åŒå˜€å£°ä»£è¡¨çš„é—®é¢˜ã€‚\n",
      "\n",
      "å¦‚æœä»¥ä¸Šæ­¥éª¤ä¾ç„¶æ— æ³•è§£å†³é—®é¢˜ï¼Œå»ºè®®å¯»æ±‚ä¸“ä¸šæŠ€æœ¯æ”¯æŒã€‚å¸Œæœ›è¿™äº›å»ºè®®å¯¹ä½ æœ‰å¸®åŠ©ï¼\n"
     ]
    }
   ],
   "source": [
    "# 1. åˆ›å»º PromptTemplate å¯¹è±¡ï¼ŒæŒ‡å®šéœ€è¦å¡«å……çš„å˜é‡ä¸º user_question\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"user_question\"],\n",
    "        \n",
    "    template=\"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ”¯æŒï¼Œå›ç­”é£æ ¼ï¼š{style}ã€‚\n",
    "    è¯·å…ˆå¤è¿°ç”¨æˆ·é—®é¢˜ï¼Œç„¶åæä¾›è§£å†³æ–¹æ¡ˆã€‚\n",
    "\n",
    "    ç”¨æˆ·é—®é¢˜ï¼š{user_question}\n",
    "\n",
    "    è§£å†³æ–¹æ¡ˆï¼š\"\"\",\n",
    "    \n",
    "    partial_variables={\"style\": \"ç®€æ´æ˜äº†\"} # å¯é€‰ï¼šéƒ¨åˆ†å˜é‡å›ºå®šï¼Œè¿™é‡Œé¢„è®¾ style ä¸ºâ€œç®€æ´æ˜äº†â€ï¼Œåç»­å¯è¦†ç›–\n",
    ")\n",
    "\n",
    "# 2. ä½¿ç”¨ partial æ–¹æ³•è¦†ç›– style ä¸ºâ€œé€šä¿—æ˜“æ‡‚â€ï¼Œå†å¡«å……ç”¨æˆ·é—®é¢˜\n",
    "prompt = template.partial(style=\"é€šä¿—æ˜“æ‡‚\").format(user_question=\"ç”µè„‘æ— æ³•å¼€æœº\")\n",
    "\n",
    "# 3. è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "# 4. æ‰“å°æœ€ç»ˆç”Ÿæˆçš„æç¤ºè¯\n",
    "print(f\"æ‰“å°ç”Ÿæˆçš„æç¤ºè¯ï¼š{prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 5. æ‰“å°æ¨¡å‹è¿”å›çš„å†…å®¹\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306fc99-0770-4f9d-9ea7-02f2f2c9e522",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| é¡¹ç›® | input_variables | partial_variables |\n",
    "| :---: | :---: | :---: |\n",
    "| æ˜¯ä¸æ˜¯ç”¨æˆ·å¿…é¡»æä¾›ï¼Ÿ | æ˜¯ | å¦ |\n",
    "| ä½•æ—¶å¡«å…¥ï¼Ÿ | `.format()`<br/> æ—¶ | Template å®šä¹‰æ—¶/.partial()è¦†ç›– |\n",
    "| æ˜¯å¦å¯è¦†ç›–ï¼Ÿ | æ˜¯ | æ˜¯ |\n",
    "| æ˜¯å¦æ”¯æŒå‡½æ•°ï¼Ÿ | å¦ | æ”¯æŒï¼ˆåŠ¨æ€å˜é‡ï¼‰ |\n",
    "| é€‚åˆåœºæ™¯ | ç”¨æˆ·è¾“å…¥å†…å®¹ | prompt é¢„è®¾ã€ç³»ç»ŸæŒ‡ä»¤ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416ad21-044d-4f79-9926-3090cba9cf14",
   "metadata": {},
   "source": [
    "### 2. ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e36f2bad-04b5-49ae-a51e-25e1e0829a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆçš„æ¶ˆæ¯ç»“æ„ï¼š\n",
      "\n",
      "--- æ¶ˆæ¯ 1 ---\n",
      "è§’è‰²: <bound method BaseModel.schema of <class 'langchain_core.messages.system.SystemMessage'>>\n",
      "å†…å®¹: ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonä»£ç å®¡æŸ¥åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æ£€æŸ¥ä»£ç é£æ ¼ã€æ½œåœ¨Bugå’Œæ€§èƒ½é—®é¢˜ã€‚\n",
      "\n",
      "--- æ¶ˆæ¯ 2 ---\n",
      "è§’è‰²: <bound method BaseModel.schema of <class 'langchain_core.messages.human.HumanMessage'>>\n",
      "å†…å®¹: è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š\n",
      "\n",
      "def add(a,b):\n",
      "    return a+b\n",
      "\n",
      "--- æ¶ˆæ¯ 3 ---\n",
      "è§’è‰²: <bound method BaseModel.schema of <class 'langchain_core.messages.ai.AIMessage'>>\n",
      "å†…å®¹: æˆ‘å‘ç°äº†ä»¥ä¸‹é—®é¢˜ï¼š1. ç¼ºå°‘ç±»å‹æ³¨è§£ 2. ä½¿ç”¨å…¨å±€å˜é‡\n",
      "\n",
      "--- æ¶ˆæ¯ 4 ---\n",
      "è§’è‰²: <bound method BaseModel.schema of <class 'langchain_core.messages.human.HumanMessage'>>\n",
      "å†…å®¹: è¯·ç»™å‡ºä¼˜åŒ–åçš„ä»£ç \n",
      "\n",
      " æ¨¡å‹å®¡æŸ¥ç»“æœï¼š\n",
      "ä»¥ä¸‹æ˜¯ä¼˜åŒ–åçš„ä»£ç ï¼ŒåŒ…å«ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²ï¼Œä»¥æé«˜ä»£ç çš„å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ï¼š\n",
      "\n",
      "```python\n",
      "def add(a: float, b: float) -> float:\n",
      "    \"\"\"\n",
      "    è¿”å›ä¸¤ä¸ªæ•°å­—çš„å’Œã€‚\n",
      "\n",
      "    å‚æ•°:\n",
      "    a (float): ç¬¬ä¸€ä¸ªæ•°å­—ã€‚\n",
      "    b (float): ç¬¬äºŒä¸ªæ•°å­—ã€‚\n",
      "\n",
      "    è¿”å›:\n",
      "    float: ä¸¤ä¸ªæ•°å­—çš„å’Œã€‚\n",
      "    \"\"\"\n",
      "    return a + b\n",
      "```\n",
      "\n",
      "### ä¼˜åŒ–ç‚¹ï¼š\n",
      "1. **ç±»å‹æ³¨è§£**ï¼šä¸ºå‚æ•°å’Œè¿”å›å€¼æ·»åŠ äº†ç±»å‹æ³¨è§£ï¼Œå®šä¹‰äº† `a` å’Œ `b` ä¸º `float` ç±»å‹ï¼Œå¹¶ä¸”è¿”å›å€¼ä¹Ÿæ˜¯ `float` ç±»å‹ã€‚è¿™ä½¿å¾—å‡½æ•°çš„ä½¿ç”¨æ›´åŠ æ˜ç¡®ã€‚\n",
      "2. **æ–‡æ¡£å­—ç¬¦ä¸²**ï¼šæ·»åŠ äº†æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¯´æ˜å‡½æ•°çš„åŠŸèƒ½ã€å‚æ•°åŠè¿”å›å€¼ï¼Œä¾¿äºå…¶ä»–å¼€å‘è€…ç†è§£å’Œä½¿ç”¨è¯¥å‡½æ•°ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ä½¿ç”¨messagesæ¨¡æ¿å­—ç¬¦ä¸²ï¼ˆæœ€å¸¸ç”¨ï¼‰\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "        \n",
    "    # SystemMessage: å®šä¹‰AIè§’è‰²å’Œè¡Œä¸ºå‡†åˆ™\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonä»£ç å®¡æŸ¥åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æ£€æŸ¥ä»£ç é£æ ¼ã€æ½œåœ¨Bugå’Œæ€§èƒ½é—®é¢˜ã€‚\"),\n",
    "\n",
    "    # HumanMessage: ç”¨æˆ·è¾“å…¥\n",
    "    (\"human\", \"è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š\\n\\n{code_snippet}\"),\n",
    "\n",
    "    # AIMessage: å¯é€‰ï¼Œæä¾›ç¤ºä¾‹è¾“å‡ºï¼ˆFew-shotï¼‰\n",
    "    (\"ai\", \"æˆ‘å‘ç°äº†ä»¥ä¸‹é—®é¢˜ï¼š1. ç¼ºå°‘ç±»å‹æ³¨è§£ 2. ä½¿ç”¨å…¨å±€å˜é‡\"),\n",
    "\n",
    "    # HumanMessage: ç”¨æˆ·çš„åç»­æŒ‡ä»¤\n",
    "    (\"human\", \"{follow_up_instruction}\")\n",
    "])\n",
    "\n",
    "# æ ¼å¼åŒ–ï¼šç”Ÿæˆæ¶ˆæ¯åˆ—è¡¨\n",
    "messages = chat_template.format_messages(\n",
    "        \n",
    "    code_snippet=\"def add(a,b):\\n    return a+b\", \n",
    "        \n",
    "    follow_up_instruction=\"è¯·ç»™å‡ºä¼˜åŒ–åçš„ä»£ç \"\n",
    ")\n",
    "\n",
    "print(\"ç”Ÿæˆçš„æ¶ˆæ¯ç»“æ„ï¼š\")\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"\\n--- æ¶ˆæ¯ {i+1} ---\")\n",
    "    print(f\"è§’è‰²: {msg.schema}\")\n",
    "    print(f\"å†…å®¹: {msg.content}\")\n",
    "\n",
    "# ç›´æ¥ä¼ é€’ç»™æ¨¡å‹\n",
    "response = model.invoke(messages)\n",
    "print(\"\\n æ¨¡å‹å®¡æŸ¥ç»“æœï¼š\")\n",
    "print(response.content_blocks[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98be241-3059-4b69-942f-44b1cc9e1ad5",
   "metadata": {},
   "source": [
    "### 3. LangChain Hub æ¨¡ç‰ˆåº“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f71527-a8f3-4a3f-a483-9984681df09d",
   "metadata": {},
   "source": [
    "ä½¿ç”¨æç¤ºè¯æ¨¡ç‰ˆåº“ä¹‹å‰éœ€è¦å…ˆåˆ°LangSmithå®˜ç½‘ä¸Šç”³è¯·ä¸€ä¸ªapi_key,å®˜ç½‘åœ°å€ï¼šhttps://smith.langchain.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e26de4-1805-4fa3-97ae-5865585e205f",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251119125419234.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5020c3-ae05-4c24-9550-cd11661f72bc",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251119125417385.png\" width=\"2000\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088284f-b4fe-4450-b789-8f6ae6989441",
   "metadata": {},
   "source": [
    "- hubæç¤ºè¯æ¨¡ç‰ˆåº“åœ°å€ï¼šhttps://smith.langchain.com/hub/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26f080-9a2a-43bd-9e67-1edaa6d5aac2",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251119131613327.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b8ab9-1555-4493-bbd2-a7712ae6c088",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251119131613331.png\" width=\"1000\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96c7b3c7-0485-4a8d-8ce0-faf9f256f13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# ä»langsmithåº“å¼•å…¥Clientç±»\n",
    "from langsmith import Client \n",
    "\n",
    "# é€šè¿‡LangSmithçš„LANGSMITH_API_KEYåˆ›å»ºClientå®ä¾‹åŒ–\n",
    "client = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "\n",
    "# ä»hubä¸Šæ‹‰å–å¯¹åº”çš„promptæ¨¡ç‰ˆ\n",
    "# æŒ‡å®špromptæ ‡è¯†ç¬¦\"rlm/rag-prompt\"ï¼Œè·å–å¯ç”¨äºRAGåœºæ™¯çš„æç¤ºæ¨¡æ¿\n",
    "prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)\n",
    "\n",
    "print(prompt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e27f022-2d43-4f43-b065-4a1030fec19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æ ¼å¼åŒ–åï¼š\n",
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: ä»€ä¹ˆæ˜¯LangChainï¼Ÿ \n",
      "Context: \n",
      "                LangChain æ˜¯ä¸€ä¸ªæ„å»º LLM åº”ç”¨çš„æ¡†æ¶ï¼Œ\n",
      "                ç›®æ ‡æ˜¯æŠŠ LLM ä¸å¤–éƒ¨å·¥å…·ã€æ•°æ®æºå’Œå¤æ‚å·¥ä½œæµè¿æ¥èµ·æ¥ â€”â€” æ”¯æŒä»ç®€å•çš„ prompt å°è£…åˆ°å¤æ‚çš„ Agent\n",
      "                ï¼ˆèƒ½å¤Ÿè°ƒç”¨å·¥å…·ã€åšå†³ç­–ã€æ‰§è¡Œå¤šæ­¥ä»»åŠ¡ï¼‰ \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨æ¨¡æ¿\n",
    "formatted = prompt.format(\n",
    "        context=\"\"\"\n",
    "                LangChain æ˜¯ä¸€ä¸ªæ„å»º LLM åº”ç”¨çš„æ¡†æ¶ï¼Œ\n",
    "                ç›®æ ‡æ˜¯æŠŠ LLM ä¸å¤–éƒ¨å·¥å…·ã€æ•°æ®æºå’Œå¤æ‚å·¥ä½œæµè¿æ¥èµ·æ¥ â€”â€” æ”¯æŒä»ç®€å•çš„ prompt å°è£…åˆ°å¤æ‚çš„ Agent\n",
    "                ï¼ˆèƒ½å¤Ÿè°ƒç”¨å·¥å…·ã€åšå†³ç­–ã€æ‰§è¡Œå¤šæ­¥ä»»åŠ¡ï¼‰\"\"\",   # æ¨¡æ¿ä¸­å®šä¹‰çš„ä¸Šä¸‹æ–‡å˜é‡ï¼Œç”¨äºå¡«å……åˆ°æ¨¡æ¿ä¸­\n",
    "        question=\"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\")                   # æ¨¡æ¿ä¸­å®šä¹‰çš„é—®é¢˜å˜é‡ï¼Œç”¨äºå¡«å……åˆ°æ¨¡æ¿ä¸­\n",
    "\n",
    "print(\"\\næ ¼å¼åŒ–åï¼š\")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3d80706-eb0a-479d-ab06-681d2d4778c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„æ¡†æ¶ã€‚å®ƒæ—¨åœ¨å°† LLM ä¸å¤–éƒ¨å·¥å…·ã€æ•°æ®æºå’Œå¤æ‚å·¥ä½œæµè¿æ¥èµ·æ¥ï¼Œæ”¯æŒä»ç®€å•çš„æç¤ºå°è£…åˆ°å¤æ‚çš„ä»£ç†ã€‚è¿™ä¸ªæ¡†æ¶å¯ä»¥å®ç°å·¥å…·è°ƒç”¨ã€å†³ç­–åˆ¶å®šå’Œå¤šæ­¥ä»»åŠ¡æ‰§è¡Œã€‚\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(formatted)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "194c63f3-fe38-4862-a0f0-95d40950a6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'text': 'LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„æ¡†æ¶ã€‚å®ƒæ—¨åœ¨å°† LLM ä¸å¤–éƒ¨å·¥å…·ã€æ•°æ®æºå’Œå¤æ‚å·¥ä½œæµè¿æ¥èµ·æ¥ï¼Œæ”¯æŒä»ç®€å•çš„æç¤ºå°è£…åˆ°å¤æ‚çš„ä»£ç†ã€‚è¿™ä¸ªæ¡†æ¶å¯ä»¥å®ç°å·¥å…·è°ƒç”¨ã€å†³ç­–åˆ¶å®šå’Œå¤šæ­¥ä»»åŠ¡æ‰§è¡Œã€‚'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ‰“å°è¾“å‡ºå†…å®¹å—\n",
    "response.content_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f56730-4db5-4855-840f-2cfd129a1c2f",
   "metadata": {},
   "source": [
    "## 3.4 æ ‡å‡†åŒ–å†…å®¹å—Content Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bb2ed-99db-4cbc-886c-76ca56fd75b1",
   "metadata": {},
   "source": [
    "ç»Ÿä¸€æ‰€æœ‰æ¨¡å‹å‚å•†çš„è¾“å‡ºæ ¼å¼ï¼Œè§£å†³\"æ¢æ¨¡å‹å°±è¦é‡å†™è§£æä»£ç \"çš„ç—›ç‚¹ï¼š\n",
    "\n",
    "LangChain 1.0 å¼•å…¥äº† provider-agnosticä¸å‚å•†æ— å…³ çš„ standard content blocksæ ‡å‡†åŒ–å†…å®¹å—ï¼Œä½¿å¾—æ¶ˆæ¯ä¸­çš„å¤šæ¨¡æ€æ•°æ®ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ã€PDFã€è§†é¢‘ç­‰ï¼‰èƒ½ä»¥ç»Ÿä¸€ã€ç±»å‹åŒ–çš„æ–¹å¼è¢«æ„é€ ä¸é˜…è¯»ã€‚é€šè¿‡ content blocks å±æ€§å®ç°å¤šæ¨¡æ€ç»Ÿä¸€å¤„ç†ï¼Œå°è£… TextBlockã€ToolCallBlockã€ImageBlock ç­‰ç»“æ„ï¼Œæ‰©å±• LLM åº”ç”¨è‡³å›¾ç‰‡ç†è§£ã€è¯­éŸ³äº¤äº’ç­‰åœºæ™¯ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºæ ‡å‡†åŒ–å†…å®¹æµè½¬ä¸è·¨å¹³å°å…¼å®¹æ€§ï¼Œå¯é€šè¿‡ langchain-openai ç­‰å‚å•†åŒ…ç›´æ¥åˆå§‹åŒ–å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒå›¾ç‰‡è¾“å…¥ç”Ÿæˆæè¿°ã€è¯­éŸ³è½¬æ–‡æœ¬é—®ç­”ç­‰åŠŸèƒ½ï¼Œä¾èµ– Model I/O æ¨¡å—å®Œæˆæ ¼å¼åŒ–ä¸è§£æ\n",
    "\n",
    "æ”¯æŒç±»å‹ï¼štext ã€ tool_call ã€ image ã€ audio ã€ video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23564bf8-476c-4b2c-8165-03bba7add2cd",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| åœºæ™¯ | å†…å®¹å—ä½œç”¨ |\n",
    "| :---: | :---: |\n",
    "| ğŸ“„ æ–‡æ¡£è§£æï¼ˆPDF / å›¾ç‰‡ / è¡¨æ ¼ï¼‰ | ç”¨ `image`<br/> block æŠŠ Document OCR å›¾åƒä¼ ç»™æ¨¡å‹ |\n",
    "| ğŸ”Š è¯­éŸ³é—®ç­”ï¼ˆASRï¼‰ | ç”¨ `audio`<br/> block å‘é€è¯­éŸ³æ ·æœ¬ |\n",
    "| ğŸ å¤šæ¨¡æ€ RAG | å°†æ£€ç´¢åˆ°çš„å›¾ç‰‡ã€å›¾è¡¨ã€è§†é¢‘å¸§ä½œä¸º input blocks ä¼ ç»™æ¨¡å‹ |\n",
    "| ğŸ¤– å¤šå·¥å…· Agent | å·¥å…·è¿”å›çš„åª’ä½“ç»Ÿä¸€åŒ…è£…æˆ block å†ä¼ å›æ¨¡å‹ |\n",
    "| ğŸ§ª æ¨¡å‹è¯„ä¼°ï¼ˆLangSmith / LangChain Playgroundï¼‰ | è¿›è¡Œ multimodal prompt æµ‹è¯•ä¸ A/Bï¼Œå¯¹ content blocks æ ‡æ³¨ä¸è¯„ä¼°ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bab5b3-3825-4bbb-b8cb-9f0e196cf292",
   "metadata": {},
   "source": [
    "### è¾“å‡ºæå–content_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ec420b9-096b-45e4-bcdd-eacbd8e12332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä½ å¥½ï¼æˆ‘æ˜¯DeepSeekï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\\n\\næˆ‘æ˜¯ç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ï¼Œè‡´åŠ›äºä¸ºå¤§å®¶æä¾›çƒ­æƒ…ã€ç»†è…»çš„å¸®åŠ©ã€‚è®©æˆ‘ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±çš„ç‰¹ç‚¹ï¼š\\n\\n**æˆ‘çš„èƒ½åŠ›ï¼š**\\n- ğŸ“ çº¯æ–‡æœ¬å¯¹è¯ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ã€ååŠ©å†™ä½œã€åˆ†æé—®é¢˜ç­‰\\n- ğŸ“ æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼Œå¯ä»¥å¤„ç†å›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰æ ¼å¼æ–‡ä»¶ï¼Œä»ä¸­è¯»å–æ–‡å­—ä¿¡æ¯\\n- ğŸŒ æ”¯æŒè”ç½‘æœç´¢ï¼ˆéœ€è¦ä½ åœ¨Web/Appæ‰‹åŠ¨ç‚¹å¼€è”ç½‘æœç´¢æŒ‰é”®ï¼‰\\n- ğŸ’¬ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½è®°ä½æˆ‘ä»¬è¾ƒé•¿çš„å¯¹è¯å†…å®¹\\n\\n**æˆ‘çš„ç‰¹è‰²ï¼š**\\n- ğŸ†“ å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰ä»»ä½•æ”¶è´¹è®¡åˆ’\\n- ğŸ“± å¯ä»¥é€šè¿‡å®˜æ–¹åº”ç”¨å•†åº—ä¸‹è½½Appä½¿ç”¨\\n- ğŸ”„ çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œä¼šæŒç»­æ›´æ–°\\n\\n**æˆ‘æ“…é•¿ï¼š**\\nå­¦ä¹ è¾…å¯¼ã€å·¥ä½œååŠ©ã€åˆ›æ„å†™ä½œã€æ•°æ®åˆ†æã€é—®é¢˜è§£ç­”ç­‰å„ç§ä»»åŠ¡ï¼\\n\\næœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œè¿˜æ˜¯ç”Ÿæ´»ä¸­çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„ä¸ºä½ æä¾›å¸®åŠ©ï¼âœ¨', additional_kwargs={'refusal': None, 'reasoning_content': 'å“¦ï¼Œç”¨æˆ·è®©æˆ‘åšä¸ªè‡ªæˆ‘ä»‹ç»ï¼Œè¿™æ˜¯ä¸ªå¾ˆåŸºç¡€çš„è¯·æ±‚ã€‚éœ€è¦ç®€æ´æ¸…æ™°åœ°è¯´æ˜èº«ä»½ã€åŠŸèƒ½ç‰¹ç‚¹å’Œèƒ½æä¾›çš„å¸®åŠ©èŒƒå›´ã€‚\\n\\nå¯ä»¥ç”¨å…¬å¸èƒŒæ™¯å¼€åœºï¼Œç„¶ååˆ†å—ä»‹ç»æ ¸å¿ƒèƒ½åŠ›ï¼šæ–‡æœ¬å¤„ç†ã€æ–‡ä»¶æ”¯æŒã€è”ç½‘æœç´¢å’Œä¸Šä¸‹æ–‡é•¿åº¦ã€‚æœ€åè¯´æ˜å…è´¹å±æ€§å’Œè·å–æ–¹å¼ï¼Œä¿æŒå‹å¥½ç»“å°¾ã€‚\\n\\næ³¨æ„è¯­æ°”è¦çƒ­æƒ…ä½†ä¿æŒä¸“ä¸šï¼Œé¿å…è¿‡åº¦å®£ä¼ ï¼Œé‡ç‚¹çªå‡ºå®ç”¨ä¿¡æ¯ã€‚'}, response_metadata={'token_usage': {'completion_tokens': 303, 'prompt_tokens': 7, 'total_tokens': 310, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 78, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 7}, 'model_provider': 'deepseek', 'model_name': 'deepseek-reasoner', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '423a1f42-739b-4fe9-9310-570f62c5b5a4', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ce19dc84-b800-4431-baf7-837ffd1c0b1f-0', usage_metadata={'input_tokens': 7, 'output_tokens': 303, 'total_tokens': 310, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 78}})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŠ è½½ DeepSeek æä¾›çš„æ¨ç†æ¨¡å‹ deepseek-reasoner\n",
    "deepseek_model = load_chat_model(\n",
    "    model=\"deepseek-reasoner\",  # æŒ‡å®šæ¨¡å‹åç§°\n",
    "    provider=\"deepseek\",         # æŒ‡å®šæ¨¡å‹æä¾›å•†\n",
    ")\n",
    "\n",
    "# è°ƒç”¨æ¨¡å‹\n",
    "res = deepseek_model.invoke(\"è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")\n",
    "\n",
    "# è¾“å‡ºæ¨¡å‹è¿”å›çš„ç»“æœ\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22fd96ee-8b70-4451-8450-9cf8c78319cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'reasoning',\n",
       "  'reasoning': 'å“¦ï¼Œç”¨æˆ·è®©æˆ‘åšä¸ªè‡ªæˆ‘ä»‹ç»ï¼Œè¿™æ˜¯ä¸ªå¾ˆåŸºç¡€çš„è¯·æ±‚ã€‚éœ€è¦ç®€æ´æ¸…æ™°åœ°è¯´æ˜èº«ä»½ã€åŠŸèƒ½ç‰¹ç‚¹å’Œèƒ½æä¾›çš„å¸®åŠ©èŒƒå›´ã€‚\\n\\nå¯ä»¥ç”¨å…¬å¸èƒŒæ™¯å¼€åœºï¼Œç„¶ååˆ†å—ä»‹ç»æ ¸å¿ƒèƒ½åŠ›ï¼šæ–‡æœ¬å¤„ç†ã€æ–‡ä»¶æ”¯æŒã€è”ç½‘æœç´¢å’Œä¸Šä¸‹æ–‡é•¿åº¦ã€‚æœ€åè¯´æ˜å…è´¹å±æ€§å’Œè·å–æ–¹å¼ï¼Œä¿æŒå‹å¥½ç»“å°¾ã€‚\\n\\næ³¨æ„è¯­æ°”è¦çƒ­æƒ…ä½†ä¿æŒä¸“ä¸šï¼Œé¿å…è¿‡åº¦å®£ä¼ ï¼Œé‡ç‚¹çªå‡ºå®ç”¨ä¿¡æ¯ã€‚'},\n",
       " {'type': 'text',\n",
       "  'text': 'ä½ å¥½ï¼æˆ‘æ˜¯DeepSeekï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜Š\\n\\næˆ‘æ˜¯ç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„AIåŠ©æ‰‹ï¼Œè‡´åŠ›äºä¸ºå¤§å®¶æä¾›çƒ­æƒ…ã€ç»†è…»çš„å¸®åŠ©ã€‚è®©æˆ‘ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±çš„ç‰¹ç‚¹ï¼š\\n\\n**æˆ‘çš„èƒ½åŠ›ï¼š**\\n- ğŸ“ çº¯æ–‡æœ¬å¯¹è¯ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ã€ååŠ©å†™ä½œã€åˆ†æé—®é¢˜ç­‰\\n- ğŸ“ æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼Œå¯ä»¥å¤„ç†å›¾åƒã€txtã€pdfã€pptã€wordã€excelç­‰æ ¼å¼æ–‡ä»¶ï¼Œä»ä¸­è¯»å–æ–‡å­—ä¿¡æ¯\\n- ğŸŒ æ”¯æŒè”ç½‘æœç´¢ï¼ˆéœ€è¦ä½ åœ¨Web/Appæ‰‹åŠ¨ç‚¹å¼€è”ç½‘æœç´¢æŒ‰é”®ï¼‰\\n- ğŸ’¬ æ‹¥æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œèƒ½è®°ä½æˆ‘ä»¬è¾ƒé•¿çš„å¯¹è¯å†…å®¹\\n\\n**æˆ‘çš„ç‰¹è‰²ï¼š**\\n- ğŸ†“ å®Œå…¨å…è´¹ä½¿ç”¨ï¼Œæ²¡æœ‰ä»»ä½•æ”¶è´¹è®¡åˆ’\\n- ğŸ“± å¯ä»¥é€šè¿‡å®˜æ–¹åº”ç”¨å•†åº—ä¸‹è½½Appä½¿ç”¨\\n- ğŸ”„ çŸ¥è¯†æˆªæ­¢åˆ°2024å¹´7æœˆï¼Œä¼šæŒç»­æ›´æ–°\\n\\n**æˆ‘æ“…é•¿ï¼š**\\nå­¦ä¹ è¾…å¯¼ã€å·¥ä½œååŠ©ã€åˆ›æ„å†™ä½œã€æ•°æ®åˆ†æã€é—®é¢˜è§£ç­”ç­‰å„ç§ä»»åŠ¡ï¼\\n\\næœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿæ— è®ºæ˜¯å­¦ä¹ ã€å·¥ä½œè¿˜æ˜¯ç”Ÿæ´»ä¸­çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„ä¸ºä½ æä¾›å¸®åŠ©ï¼âœ¨'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»æ¨¡å‹è¿”å›çš„ç»“æœä¸­æå–å†…å®¹å—\n",
    "res.content_blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64238f4-728b-4338-9ef7-254893a4280e",
   "metadata": {},
   "source": [
    "### å¤šæ¨¡æ€è¾“å…¥content_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1b390f6-c997-4ece-b98d-87a272e4c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœéœ€è¦æŠŠæœ¬åœ°æ–‡ä»¶ä»¥ base64 å½¢å¼å‘é€ï¼Œå»ºè®®å®‰è£… pillow/ffmpeg ç­‰æŒ‰éœ€å·¥å…·\n",
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f6a1c-7471-4247-bc56-448e910de907",
   "metadata": {},
   "source": [
    "base64 å½¢å¼è§¦åŠäº†ç½‘ç»œä¼ è¾“ä¸æ•°æ®åºåˆ—åŒ–çš„åº•å±‚åŸç†ã€‚\n",
    "ç®€å•æ¥è¯´ï¼Œå°†å›¾ç‰‡æˆ–éŸ³é¢‘è½¬æ¢ä¸º Base64ï¼Œä¸»è¦æ˜¯ä¸ºäº†è§£å†³ â€œåœ¨çº¯æ–‡æœ¬åè®®ï¼ˆHTTP/JSONï¼‰ä¸­ä¼ è¾“äºŒè¿›åˆ¶æ•°æ®ï¼ˆBinary Dataï¼‰â€ çš„å…¼å®¹æ€§é—®é¢˜ã€‚\n",
    "\n",
    "ç»å¤§å¤šæ•°å¤§æ¨¡å‹ APIï¼ˆOpenAI, Anthropic, Google Gemini ç­‰ï¼‰éƒ½æ˜¯åŸºäº RESTful APIï¼Œæ•°æ®è½½è·ï¼ˆPayloadï¼‰æ ¼å¼é€šå¸¸æ˜¯ JSONã€‚\n",
    "\n",
    " - JSON çš„æœ¬è´¨ï¼šJSON æ˜¯ä¸€ç§çº¯æ–‡æœ¬æ ¼å¼ã€‚å®ƒåªèƒ½ç†è§£å­—ç¬¦ä¸²ï¼ˆStringï¼‰ã€æ•°å­—ã€å¸ƒå°”å€¼ç­‰æ–‡æœ¬æ•°æ®ã€‚\n",
    "\n",
    " - å›¾ç‰‡/éŸ³é¢‘çš„æœ¬è´¨ï¼šå®ƒä»¬æ˜¯äºŒè¿›åˆ¶æ•°æ®ï¼ˆBinary Bytesï¼‰ã€‚å¦‚æœä½ ç›´æ¥ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ä¸€å¼  JPG å›¾ç‰‡ï¼Œä½ ä¼šçœ‹åˆ°ä¹±ç ï¼Œå…¶ä¸­åŒ…å«äº†å¤§é‡çš„ä¸å¯è§å­—ç¬¦ã€æ§åˆ¶å­—ç¬¦ï¼ˆå¦‚æ¢è¡Œç¬¦ã€ç©ºå­—ç¬¦ \\0 ç­‰ï¼‰ã€‚\n",
    "\n",
    " - å†²çªç‚¹ï¼šå¦‚æœä½ ç›´æ¥æŠŠè¿™äº›äºŒè¿›åˆ¶ä¹±ç å¡è¿› JSON çš„å­—ç¬¦ä¸²å­—æ®µé‡Œï¼ˆä¾‹å¦‚ {\"image\": \"Ã¿Ã˜Ã¿Ã ...\"}ï¼‰ï¼Œè¿™äº›ç‰¹æ®Šå­—ç¬¦ä¼šç ´å JSON çš„è¯­æ³•ç»“æ„ï¼Œå¯¼è‡´æœåŠ¡ç«¯æ— æ³•è§£æï¼Œæˆ–è€…è¢« HTTP åè®®æ‹¦æˆªã€‚\n",
    "\n",
    " - è§£å†³æ–¹æ¡ˆï¼šBase64 ç¼–ç å¯ä»¥å°†ä»»æ„äºŒè¿›åˆ¶æ•°æ®ï¼Œæ˜ å°„ä¸º 64 ä¸ªæ ‡å‡†çš„ã€å¯æ‰“å°çš„ ASCII å­—ç¬¦ï¼ˆA-Z, a-z, 0-9, +, /ï¼‰ã€‚è¿™æ ·ï¼ŒåŸæœ¬çš„äºŒè¿›åˆ¶å›¾ç‰‡å°±å˜æˆäº†æ™®é€šçš„å­—ç¬¦ä¸²ï¼Œå¯ä»¥å®Œç¾åœ°åµŒå…¥åˆ° JSON ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25a832-4de4-462a-a063-1264452bbc20",
   "metadata": {},
   "source": [
    "**content_blocks** æ˜¯ LangChain v1 çš„æ ‡å‡†åŒ–å¤šæ¨¡æ€æ¶ˆæ¯å•å…ƒï¼Œä½ å¯ä»¥ç”¨ dict ç»“æ„æŠŠå›¾ç‰‡ä¸éŸ³é¢‘çº³å…¥æ¶ˆæ¯é‡Œï¼Œæ¡†æ¶ä¼šæŠŠå®ƒä»¬è½¬æ¢ä¸ºå„ provider å¯è¯†åˆ«çš„æ ¼å¼ï¼›åœ¨å®é™…ä½¿ç”¨æ—¶åŠ¡å¿…ç¡®è®¤ç›®æ ‡æ¨¡å‹/provider å¯¹ multimodal çš„æ”¯æŒå’Œæ‰€éœ€çš„ mime_type / metadata å­—æ®µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3a160e5-0d5e-468b-8f8f-d494af2b2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'text', 'text': 'è¯·æè¿°å›¾åƒï¼š'}\n",
      "{'type': 'image', 'id': 'lc_46bc4293-da92-41eb-bbac-1ffbdeee83b2', 'url': 'https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251015134735612.png', 'extras': {'image_url_mime_type': 'image/jpeg', 'image_url_metadata': 'RAGåŸºç¡€æµç¨‹å›¾'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# åˆ›å»ºç³»ç»Ÿæç¤º\n",
    "system_msg = SystemMessage(\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”ä¸“å®¶ã€‚\")\n",
    "\n",
    "# æ„é€ ç”¨æˆ·æ¶ˆæ¯ï¼šæ–‡æœ¬+å›¾åƒ\n",
    "human_msg = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"è¯·æè¿°å›¾åƒï¼š\"},\n",
    "    {\"type\": \"image_url\", \n",
    "     \"image_url\": {\"url\": \"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251015134735612.png\", \n",
    "     \"mime_type\": \"image/jpeg\",\n",
    "     \"metadata\": \"RAGåŸºç¡€æµç¨‹å›¾\"}\n",
    "    },\n",
    "])\n",
    "\n",
    "# å½¢æˆæ¶ˆæ¯åˆ—è¡¨\n",
    "messages = [system_msg, human_msg]\n",
    "\n",
    "# æ¡†æ¶ä¼šæ‡’è§£æ content -> content_blocks\n",
    "for cb in human_msg.content_blocks:\n",
    "    print(cb)   # content block å¯¹è±¡è§†å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf90f1-7eb8-48d7-9200-ed9c0bdb48d8",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://zrj18330672592.oss-cn-beijing.aliyuncs.com/20251015134735612.png\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "030d97e7-e7e2-4a2f-a9eb-36e004f49166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿™å¹…å›¾åƒå±•ç¤ºäº†ä¸€ç§ä¿¡æ¯å¤„ç†çš„æµç¨‹å›¾ã€‚ä¸»è¦å…ƒç´ åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. **æŸ¥è¯¢ï¼ˆqueryï¼‰**ï¼šèµ·å§‹ç‚¹ï¼Œç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ä¿¡æ¯ã€‚\n",
      "2. **å¤§æ¨¡å‹ï¼ˆå¤§æ¨¡å‹ï¼‰**ï¼šå¯èƒ½æŒ‡æ¶‰åŠæ·±åº¦å­¦ä¹ æˆ–å¤§è¯­è¨€æ¨¡å‹çš„å¤„ç†ã€‚\n",
      "3. **æ–‡ä»¶ç±»å‹**ï¼šåŒ…æ‹¬PDFã€TXTã€DOCå’ŒExcelï¼Œè¡¨ç¤ºå¯æœç´¢çš„æ–‡æ¡£ç±»å‹ã€‚\n",
      "4. **çŸ¥è¯†åº“**ï¼šè¡¨ç¤ºå­˜å‚¨ä¿¡æ¯çš„åœ°æ–¹ï¼Œç”¨æˆ·çš„æŸ¥è¯¢ä¼šåœ¨æ­¤è¿›è¡Œæ£€ç´¢ã€‚\n",
      "5. **é—®é¢˜ï¼ˆé—®é¢˜ï¼‰**ï¼šä»çŸ¥è¯†åº“ä¸­æå–çš„ä¿¡æ¯æˆ–æ•°æ®ã€‚\n",
      "6. **ä¸‹æ–‡æœ¬ï¼ˆä¸‹æ–‡æœ¬ï¼‰**ï¼šå¯èƒ½æ˜¯å¯¹æå–ä¿¡æ¯çš„è¿›ä¸€æ­¥å¤„ç†æˆ–ä¸Šä¸‹æ–‡çš„è¡¥å……ã€‚\n",
      "7. **æç¤ºï¼ˆpromptï¼‰**ï¼šç”¨äºç”Ÿæˆæœ€ç»ˆå“åº”çš„è¾“å…¥æ–‡æœ¬ã€‚\n",
      "8. **LLM**ï¼šä»£è¡¨å¤§è¯­è¨€æ¨¡å‹ï¼Œè´Ÿè´£å¤„ç†æç¤ºå¹¶ç”Ÿæˆç­”æ¡ˆã€‚\n",
      "9. **æœ€ç»ˆå›å¤ï¼ˆæœ€ç»ˆå›å¤ï¼‰**ï¼šè¾“å‡ºç»“æœï¼Œç”¨æˆ·æ‰€æœŸæœ›çš„å›ç­”ã€‚\n",
      "\n",
      "æ•´ä½“æµç¨‹å±•ç¤ºäº†å¦‚ä½•ä»æŸ¥è¯¢å¼€å§‹ï¼Œé€šè¿‡çŸ¥è¯†åº“å’Œå¤§è¯­è¨€æ¨¡å‹å¤„ç†ï¼Œæœ€ç»ˆå¾—åˆ°ç”¨æˆ·æ‰€éœ€çš„ä¿¡æ¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨å…·æœ‰å¤šæ¨¡æ€èƒ½åŠ›çš„æ¨¡å‹\n",
    "model = load_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    ")\n",
    "\n",
    "res = model.invoke(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb115a8-e329-4550-b846-8e7af71aeb1b",
   "metadata": {},
   "source": [
    "### å†…å®¹å—åˆ›å»ºæ ‡å‡†æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75004201-9213-47cf-8c00-86302bed9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ å†…å®¹å—ç±»å‹   â”‚ æ ‡å‡†æ ¼å¼ï¼ˆLangChain 1.0ï¼‰                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ æ–‡æœ¬        â”‚ {\"type\": \"text\", \"text\": \"...\"}                      â”‚\n",
    "â”‚ å›¾åƒ        â”‚ {\"type\": \"image\", \"url\": \"...\", \"mime_type\": \"...\"}  â”‚\n",
    "â”‚ éŸ³é¢‘        â”‚ {\"type\": \"audio\", \"url\": \"...\", \"mime_type\": \"...\"}  â”‚\n",
    "â”‚ è§†é¢‘        â”‚ {\"type\": \"video\", \"url\": \"...\", \"mime_type\": \"...\"}  â”‚\n",
    "â”‚ æ–‡ä»¶        â”‚ {\"type\": \"file\", \"url\": \"...\", \"mime_type\": \"...\"}   â”‚\n",
    "â”‚ Base64 å›¾åƒ â”‚ {\"type\": \"image\", \"base64\": \"...\", \"mime_type\": \"...\"} â”‚\n",
    "â”‚ Base64 éŸ³é¢‘ â”‚ {\"type\": \"audio\", \"base64\": \"...\", \"mime_type\": \"...\"} â”‚\n",
    "â”‚ OpenAI å›¾åƒ â”‚ {\"type\": \"image_url\", \"image_url\": {\"url\": \"...\"}}   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "\n",
    "#OpenAI å†…å®¹å—æ”¯æŒå¯¹æ¯”è¡¨ï¼š\n",
    "\n",
    "support_table = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ å†…å®¹å—ç±»å‹   â”‚ æ”¯æŒæƒ…å†µ â”‚ è¯´æ˜                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ text        â”‚ âœ… æ”¯æŒ  â”‚ çº¯æ–‡æœ¬å†…å®¹                          â”‚\n",
    "â”‚ image_url   â”‚ âœ… æ”¯æŒ  â”‚ å›¾åƒ URLï¼ˆæ”¯æŒ jpg, png, gif, webpï¼‰â”‚\n",
    "â”‚ audio       â”‚ âŒ ä¸æ”¯æŒâ”‚ éœ€è¦å…ˆç”¨ Whisper è½¬å½•ä¸ºæ–‡æœ¬         â”‚\n",
    "â”‚ video       â”‚ âŒ ä¸æ”¯æŒâ”‚ éœ€è¦æå–å…³é”®å¸§æˆ–è½¬å½•éŸ³é¢‘            â”‚\n",
    "â”‚ file        â”‚ âŒ ä¸æ”¯æŒâ”‚ éœ€è¦æå–æ–‡æœ¬å†…å®¹                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72541c4a-b107-4802-a1d2-4b1cd45f85c7",
   "metadata": {},
   "source": [
    "## 3.5 æ‰¹å¤„ç†æµç¨‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9acf7-adf2-4947-9906-3a107ed7da08",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨ä½¿ç”¨å¤§æ¨¡å‹æ—¶ï¼Œå¦‚æœéœ€è¦åŒæ—¶å¤„ç†å¤šæ¡ç‹¬ç«‹è¯·æ±‚ï¼ˆä¾‹å¦‚å¤šä¸ªé—®é¢˜æˆ–å¤šæ®µæ–‡æœ¬ï¼‰ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ æ‰¹é‡è°ƒç”¨ï¼ˆBatchï¼‰ æ–¹æ³•ä¸€æ¬¡æ€§æäº¤è¿™äº›è¯·æ±‚ã€‚LangChain ä¸­çš„ batch() æ–¹æ³•å…è®¸ä½ åŒæ—¶å‘é€ä¸€ç»„è¯·æ±‚ï¼Œæ¨¡å‹ä¼šåœ¨åå°å¹¶è¡Œå¤„ç†ï¼Œç„¶åè¿”å›æ‰€æœ‰ç»“æœï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "567c8ff2-db01-49fc-9256-c916e482cb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  å¼€å§‹æ—¶é—´: 16:43:47.303\n",
      "â±ï¸  ç»“æŸæ—¶é—´: 16:44:02.841\n",
      "ğŸ“Š æ€»è€—æ—¶: 15.54s\n",
      "content='ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›ä¿¡æ¯å’Œå¸®åŠ©ï¼Œå›ç­”å„ç§é—®é¢˜ã€‚æˆ‘å¯ä»¥å¤„ç†å¤šç§ä¸»é¢˜ï¼ŒåŒ…æ‹¬ç§‘æŠ€ã€å†å²ã€æ–‡åŒ–ã€ç§‘å­¦ç­‰ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 13, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CdBbPZh77bVHs9LQYORJBaTkoZGHa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--c0d9d233-cc92-4491-9f47-4925a55f6855-0' usage_metadata={'input_tokens': 13, 'output_tokens': 49, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿé€šè¿‡ç»éªŒè‡ªåŠ¨æ”¹è¿›å…¶æ€§èƒ½ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚ç®€å•æ¥è¯´ï¼Œæœºå™¨å­¦ä¹ è®©æœºå™¨èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼å’Œè§„å¾‹ï¼Œä»è€Œè¿›è¡Œé¢„æµ‹æˆ–å†³ç­–ã€‚\\n\\næœºå™¨å­¦ä¹ çš„ä¸»è¦ç±»å‹åŒ…æ‹¬ï¼š\\n\\n1. **ç›‘ç£å­¦ä¹ **ï¼šé€šè¿‡å·²æœ‰çš„æ ‡æ³¨æ•°æ®ï¼ˆå³è¾“å…¥å’Œå¯¹åº”çš„è¾“å‡ºï¼‰æ¥è®­ç»ƒæ¨¡å‹ï¼Œç›®çš„æ˜¯è®©æ¨¡å‹èƒ½å¤Ÿå¯¹æ–°çš„ã€æœªæ ‡æ³¨çš„æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚ä¾‹å¦‚ï¼Œå›¾åƒåˆ†ç±»å’Œå›å½’åˆ†æå°±æ˜¯ç›‘ç£å­¦ä¹ çš„å¸¸è§åº”ç”¨ã€‚\\n\\n2. **æ— ç›‘ç£å­¦ä¹ **ï¼šç”¨äºå¤„ç†æ²¡æœ‰æ ‡æ³¨çš„æ•°æ®ï¼Œç›®æ ‡æ˜¯å‘ç°æ•°æ®ä¸­çš„æ½œåœ¨ç»“æ„æˆ–æ¨¡å¼ã€‚å¸¸è§çš„æ–¹æ³•æœ‰èšç±»å’Œé™ç»´ã€‚ä¾‹å¦‚ï¼Œå¸‚åœºç»†åˆ†å’Œæ•°æ®å‹ç¼©ç­‰ã€‚\\n\\n3. **å¼ºåŒ–å­¦ä¹ **ï¼šé€šè¿‡ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ ï¼Œç³»ç»Ÿæ ¹æ®è¡ŒåŠ¨çš„ç»“æœè·å¾—å¥–åŠ±æˆ–æƒ©ç½šï¼Œç›®çš„æ˜¯é€šè¿‡è¯•é”™æ¥æ‰¾åˆ°æœ€ä¼˜ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œæ¸¸æˆä¸­çš„æ™ºèƒ½ä½“å­¦ä¹ å¦‚ä½•èµ¢å¾—æ¯”èµ›ã€‚\\n\\næœºå™¨å­¦ä¹ åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€æ¨èç³»ç»Ÿã€é‡‘èåˆ†æç­‰ã€‚éšç€æ•°æ®é‡çš„å¢åŠ å’Œè®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œæœºå™¨å­¦ä¹ çš„å‘å±•ä¹Ÿæ—¥ç›Šè¿…é€Ÿã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 14, 'total_tokens': 269, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdBbP2x0gkOk79ObgbcBbui4yIzbh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--e9c8a3dc-1daf-4f2e-b53e-35aa456a2524-0' usage_metadata={'input_tokens': 14, 'output_tokens': 255, 'total_tokens': 269, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='å½“ç„¶å¯ä»¥ã€‚æœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰å’Œæ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰æ˜¯äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰é¢†åŸŸçš„ä¸¤ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒä»¬ä¹‹é—´æœ‰ä¸€äº›å…³é”®åŒºåˆ«ï¼š\\n\\n1. **å®šä¹‰**ï¼š\\n   - **æœºå™¨å­¦ä¹ **ï¼šæ˜¯ä¸€ç§é€šè¿‡æ•°æ®å’Œç®—æ³•è®©è®¡ç®—æœºç³»ç»Ÿè‡ªåŠ¨æ”¹è¿›å…¶æ€§èƒ½çš„æŠ€æœ¯ã€‚å®ƒåŒ…æ‹¬å¤šç§ç®—æ³•å’Œæ¨¡å‹ï¼Œå¦‚çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºç­‰ã€‚\\n   - **æ·±åº¦å­¦ä¹ **ï¼šæ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œï¼ˆæ·±åº¦ç¥ç»ç½‘ç»œï¼‰æ¥è¿›è¡Œç‰¹å¾æå–å’Œè½¬æ¢ï¼Œä»è€Œè‡ªåŠ¨å­¦ä¹ æ•°æ®çš„å¤æ‚æ¨¡å¼ã€‚\\n\\n2. **æ•°æ®éœ€æ±‚**ï¼š\\n   - **æœºå™¨å­¦ä¹ **ï¼šé€šå¸¸åœ¨ç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œæ¨¡å‹å¾€å¾€ä¾èµ–äºç‰¹å¾å·¥ç¨‹ï¼Œå³æ‰‹åŠ¨æå–ç‰¹å¾ã€‚\\n   - **æ·±åº¦å­¦ä¹ **ï¼šé€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ ç‰¹å¾ã€‚æ·±åº¦å­¦ä¹ åœ¨å¤§æ•°æ®åœºæ™¯ä¸‹è¡¨ç°æ›´å¥½ã€‚\\n\\n3. **ç‰¹å¾æå–**ï¼š\\n   - **æœºå™¨å­¦ä¹ **ï¼šç‰¹å¾æå–å¾€å¾€éœ€è¦äººå·¥å¹²é¢„ï¼Œç ”ç©¶è€…éœ€è¦æ ¹æ®é¢†åŸŸçŸ¥è¯†è®¾è®¡ç‰¹å¾ã€‚\\n   - **æ·±åº¦å­¦ä¹ **ï¼šé€šè¿‡å¤šä¸ªå±‚æ¬¡çš„ç¥ç»ç½‘ç»œè‡ªåŠ¨æå–ç‰¹å¾ï¼Œèƒ½å¤Ÿæ•æ‰åˆ°æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚\\n\\n4. **è®¡ç®—èµ„æº**ï¼š\\n   - **æœºå™¨å­¦ä¹ **ï¼šé€šå¸¸è®¡ç®—èµ„æºéœ€æ±‚è¾ƒä½ï¼Œæ¨¡å‹è®­ç»ƒå’Œæ¨ç†è¾ƒå¿«ã€‚\\n   - **æ·±åº¦å­¦ä¹ **ï¼šé€šå¸¸éœ€è¦æ›´å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œå°¤å…¶æ˜¯å›¾å½¢å¤„ç†å•å…ƒï¼ˆGPUï¼‰ï¼Œä»¥å¤„ç†å¤§é‡çš„å‚æ•°å’Œå¤æ‚çš„è®¡ç®—ã€‚\\n\\n5. **åº”ç”¨åœºæ™¯**ï¼š\\n   - **æœºå™¨å­¦ä¹ **ï¼šå¹¿æ³›åº”ç”¨äºåˆ†ç±»ã€å›å½’ã€èšç±»ç­‰é—®é¢˜ï¼Œå¦‚ä¿¡ç”¨è¯„åˆ†ã€æ¨èç³»ç»Ÿç­‰ã€‚\\n   - **æ·±åº¦å­¦ä¹ **ï¼šåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸè¡¨ç°çªå‡ºï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡ã€‚\\n\\næ€»ç»“æ¥è¯´ï¼Œæ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ç§ç‰¹å®šå½¢å¼ï¼Œä¸»è¦é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å¤„ç†æ•°æ®ã€‚ä¸¤è€…å„æœ‰ä¼˜åŠ£ï¼Œé€‚ç”¨äºä¸åŒç±»å‹çš„é—®é¢˜å’Œæ•°æ®é›†ã€‚' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 464, 'prompt_tokens': 18, 'total_tokens': 482, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdBbTwRlakp6uPWA7J4UtbZghHGEN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--3ac87bc4-97f3-49c1-91d6-bcc4d0ccd6f3-0' usage_metadata={'input_tokens': 18, 'output_tokens': 464, 'total_tokens': 482, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# è®°å½•å¼€å§‹æ—¶é—´\n",
    "start_time = time.time()\n",
    "print(f\"â±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
    "\n",
    "# æ‰¹é‡æé—®\n",
    "responses = model.batch([\n",
    "    \"è¯·ä»‹ç»ä¸‹ä½ è‡ªå·±ã€‚\",\n",
    "    \"è¯·é—®ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
    "    \"ä½ çŸ¥é“æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ åŒºåˆ«ä¹ˆï¼Ÿ\"\n",
    "])\n",
    "\n",
    "# è®°å½•ç»“æŸæ—¶é—´\n",
    "end_time = time.time()\n",
    "total_duration = end_time - start_time\n",
    "\n",
    "print(f\"â±ï¸  ç»“æŸæ—¶é—´: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
    "print(f\"ğŸ“Š æ€»è€—æ—¶: {total_duration:.2f}s\")\n",
    "\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd85c9a7-9312-418e-82ea-6c9e65dc459b",
   "metadata": {},
   "source": [
    "| ç‰¹æ€§       | è¯´æ˜                                                                                |\n",
    "| -------- | --------------------------------------------------------------------------------- |\n",
    "| **æ‰§è¡Œä½ç½®** | `batch()` åœ¨å®¢æˆ·ç«¯ï¼ˆClient-sideï¼‰å¹¶è¡Œè°ƒç”¨æ¨¡å‹ï¼Œè€Œéè°ƒç”¨æ¨¡å‹æä¾›å•†çš„æ‰¹é‡APIï¼ˆå¦‚OpenAIæˆ–Anthropicè‡ªå¸¦çš„batch APIï¼‰ã€‚ |\n",
    "| **è¿”å›ç»“æœ** | é»˜è®¤ä¼šåœ¨æ‰€æœ‰ä»»åŠ¡å®Œæˆåï¼Œç»Ÿä¸€è¿”å›å®Œæ•´ç»“æœåˆ—è¡¨ã€‚                                                           |\n",
    "| **å¹¶è¡Œä¼˜åŠ¿** | å¤šæ¡ç‹¬ç«‹è¯·æ±‚å¯åŒæ—¶æ‰§è¡Œï¼Œæ— éœ€ç­‰å¾…å½¼æ­¤å®Œæˆã€‚                                                             |\n",
    "| **é€‚ç”¨åœºæ™¯** | æ–‡æ¡£æ‘˜è¦ã€æ‰¹é‡é—®ç­”ã€æ•°æ®é¢„å¤„ç†ã€å¤šæ ·æœ¬åˆ†ç±»ç­‰ã€‚                                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e4c4f-ddfd-4ef5-839f-538c2c6bb12e",
   "metadata": {},
   "source": [
    "å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è¿›è¡Œæµå¼æ‰¹å¤„ç†ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªæ¯ä¸ªä»»åŠ¡å®Œæˆåå°±ç«‹å³è·å–ç»“æœï¼ˆè€Œä¸æ˜¯ç­‰å¾…å…¨éƒ¨å®Œæˆï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ batch_as_completed() æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f02faabf-f2b1-4acd-bd7b-f23d75861a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, AIMessage(content='æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›ä¿¡æ¯å’Œå¸®åŠ©è§£å†³é—®é¢˜ã€‚æˆ‘å¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›å»ºè®®ï¼ŒååŠ©å­¦ä¹ å’Œç ”ç©¶ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸï¼Œå¦‚ç§‘å­¦ã€å†å²ã€æŠ€æœ¯ã€æ–‡åŒ–ç­‰ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…·ä½“çš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 13, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CdBU5zWtrDudpIFAWjDe6GTtGF6N0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--88ad878b-46de-4c92-ab8c-c9b353b6bb02-0', usage_metadata={'input_tokens': 13, 'output_tokens': 59, 'total_tokens': 72, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))\n",
      "(1, AIMessage(content='æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿé€šè¿‡æ•°æ®å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚ç®€å•æ¥è¯´ï¼Œæœºå™¨å­¦ä¹ æ˜¯è®©è®¡ç®—æœºä»ç»éªŒä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹æˆ–å†³ç­–çš„ä¸€ç§æ–¹æ³•ã€‚\\n\\næœºå™¨å­¦ä¹ çš„åŸºæœ¬è¿‡ç¨‹é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\\n\\n1. **æ•°æ®æ”¶é›†**ï¼šæ”¶é›†å¤§é‡ç›¸å…³æ•°æ®ï¼Œä»¥ä¾¿ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚\\n  \\n2. **æ•°æ®é¢„å¤„ç†**ï¼šå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—å’Œæ•´ç†ï¼Œä»¥ç¡®ä¿å…¶è´¨é‡å’Œå¯ç”¨æ€§ã€‚è¿™å¯èƒ½åŒ…æ‹¬å»é™¤é‡å¤å€¼ã€å¤„ç†ç¼ºå¤±å€¼ã€æ ‡å‡†åŒ–ç­‰ã€‚\\n\\n3. **é€‰æ‹©æ¨¡å‹**ï¼šæ ¹æ®å…·ä½“ä»»åŠ¡é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ¨¡å‹ï¼Œä¾‹å¦‚çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œç­‰ã€‚\\n\\n4. **è®­ç»ƒæ¨¡å‹**ï¼šä½¿ç”¨è®­ç»ƒæ•°æ®é›†æ¥è®­ç»ƒé€‰æ‹©çš„æ¨¡å‹ï¼Œä»¥ä½¿å…¶èƒ½å¤Ÿè¯†åˆ«æ•°æ®ä¸­çš„æ¨¡å¼ã€‚\\n\\n5. **è¯„ä¼°æ¨¡å‹**ï¼šä½¿ç”¨æµ‹è¯•æ•°æ®é›†è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œç¡®ä¿å…¶èƒ½å¤Ÿåœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šåšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚\\n\\n6. **ä¼˜åŒ–æ¨¡å‹**ï¼šæ ¹æ®è¯„ä¼°ç»“æœå¯¹æ¨¡å‹è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ï¼Œä»¥æé«˜å…¶å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚\\n\\n7. **éƒ¨ç½²å’Œç›‘æ§**ï¼šå°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²åˆ°å®é™…åº”ç”¨ä¸­ï¼Œå¹¶æŒç»­ç›‘æ§å…¶è¡¨ç°ï¼Œä»¥ä¾¿åœ¨å¿…è¦æ—¶è¿›è¡Œæ›´æ–°å’Œæ”¹è¿›ã€‚\\n\\næœºå™¨å­¦ä¹ å¹¿æ³›åº”ç”¨äºå„ä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å›¾åƒè¯†åˆ«ã€æ¨èç³»ç»Ÿã€é‡‘èåˆ†æç­‰ã€‚éšç€æ•°æ®é‡çš„å¢åŠ å’Œè®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œæœºå™¨å­¦ä¹ åœ¨è®¸å¤šå®é™…åº”ç”¨ä¸­çš„é‡è¦æ€§ä¸æ–­å¢é•¿ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 331, 'prompt_tokens': 14, 'total_tokens': 345, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdBU49eekL1ywbHYqmXLZyhTSkrIH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--64747d95-7431-4a06-8bf2-9f079428b457-0', usage_metadata={'input_tokens': 14, 'output_tokens': 331, 'total_tokens': 345, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))\n",
      "(2, AIMessage(content='å½“ç„¶ï¼Œæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰é¢†åŸŸä¸­çš„ä¸¤ä¸ªé‡è¦æ¦‚å¿µï¼Œå®ƒä»¬ä¹‹é—´æœ‰ä¸€äº›å…³é”®çš„åŒºåˆ«ã€‚\\n\\n1. **å®šä¹‰**ï¼š\\n   - **æœºå™¨å­¦ä¹ **ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä¸»è¦å…³æ³¨å¦‚ä½•é€šè¿‡æ•°æ®å’Œç»éªŒè®©è®¡ç®—æœºè‡ªåŠ¨æ”¹è¿›å…¶æ€§èƒ½ã€‚æœºå™¨å­¦ä¹ å¯ä»¥é€šè¿‡å¤šç§ç®—æ³•è¿›è¡Œåˆ†ç±»ã€å›å½’å’Œèšç±»ç­‰ä»»åŠ¡ã€‚\\n   - **æ·±åº¦å­¦ä¹ **ï¼ˆDeep Learning, DLï¼‰æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä¸»è¦åˆ©ç”¨ç¥ç»ç½‘ç»œï¼ˆå°¤å…¶æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼‰æ¥å¤„ç†æ•°æ®ã€‚æ·±åº¦å­¦ä¹ èƒ½å¤Ÿè‡ªåŠ¨ä»å¤§é‡æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œå°¤å…¶é€‚ç”¨äºå¤„ç†å›¾åƒã€è¯­éŸ³å’Œè‡ªç„¶è¯­è¨€ç­‰å¤æ‚æ•°æ®ã€‚\\n\\n2. **ç®—æ³•å¤æ‚æ€§**ï¼š\\n   - æœºå™¨å­¦ä¹ åŒ…æ‹¬å¤šç§ç®—æ³•ï¼Œå¦‚çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—ç­‰ï¼Œè¿™äº›ç®—æ³•é€šå¸¸å¯¹ç‰¹å¾å·¥ç¨‹ï¼ˆæ‰‹åŠ¨é€‰æ‹©å’Œæ„å»ºç‰¹å¾ï¼‰æ¯”è¾ƒä¾èµ–ã€‚\\n   - æ·±åº¦å­¦ä¹ åˆ™ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¿›è¡Œç‰¹å¾å­¦ä¹ ï¼Œå‡å°‘äº†å¯¹æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹çš„éœ€æ±‚ã€‚\\n\\n3. **æ•°æ®éœ€æ±‚**ï¼š\\n   - æœºå™¨å­¦ä¹ ç®—æ³•é€šå¸¸åœ¨å°åˆ°ä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ã€‚\\n   - æ·±åº¦å­¦ä¹ é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒï¼Œä»¥é¿å…è¿‡æ‹Ÿåˆå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\\n\\n4. **è®¡ç®—èµ„æº**ï¼š\\n   - æœºå™¨å­¦ä¹ ç®—æ³•ä¸€èˆ¬å¯¹è®¡ç®—èµ„æºçš„éœ€æ±‚è¾ƒä½ï¼Œå¯ä»¥åœ¨æ™®é€šçš„è®¡ç®—æœºä¸Šè¿è¡Œã€‚\\n   - æ·±åº¦å­¦ä¹ æ¨¡å‹ç”±äºå…¶å¤æ‚æ€§å’Œæ•°æ®éœ€æ±‚ï¼Œé€šå¸¸éœ€è¦é«˜æ€§èƒ½çš„GPUæˆ–TPUè¿›è¡Œè®­ç»ƒã€‚\\n\\n5. **åº”ç”¨åœºæ™¯**ï¼š\\n   - æœºå™¨å­¦ä¹ å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸï¼Œå¦‚é‡‘èã€åŒ»ç–—ã€å¸‚åœºè¥é”€ç­‰ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®ç›¸å¯¹ç»“æ„åŒ–çš„æƒ…å†µä¸‹ã€‚\\n   - æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸè¡¨ç°çªå‡ºï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„éç»“æ„åŒ–æ•°æ®ã€‚\\n\\næ€»ä¹‹ï¼Œæ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ç§ç‰¹å®šæ–¹æ³•ï¼Œé€‚ç”¨äºå¤„ç†æ›´å¤æ‚çš„æ•°æ®å’Œä»»åŠ¡ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 448, 'prompt_tokens': 18, 'total_tokens': 466, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CdBU6INQZFPxBH0Zkuo9GenAIFOhy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9fd01b81-cafd-44e0-98dd-4f418ed44321-0', usage_metadata={'input_tokens': 18, 'output_tokens': 448, 'total_tokens': 466, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ model.batch_as_completed æ‰¹é‡æäº¤å¤šä¸ªé—®é¢˜ï¼Œå¹¶é€ä¸ªè·å–å›ç­”\n",
    "for response in model.batch_as_completed([\n",
    "    \"è¯·ä»‹ç»ä¸‹ä½ è‡ªå·±ã€‚\",\n",
    "    \"è¯·é—®ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
    "    \"ä½ çŸ¥é“æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ åŒºåˆ«ä¹ˆï¼Ÿ\"\n",
    "]):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eaf288-27c0-4b37-b555-75d47efd2101",
   "metadata": {},
   "source": [
    "### å¼‚æ­¥å¹¶å‘å¤„ç†RunnableConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a899bed-447b-4d66-8b0c-9f19896c1002",
   "metadata": {},
   "source": [
    "è€Œä¸ºäº†æ›´å¥½çš„æ§åˆ¶å¹¶å‘ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åœ¨configå‚æ•°ä¸­è®¾ç½®æ‰¹å¤„ç†çš„å¹¶å‘æ•°ï¼Œä¾‹å¦‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "80536594-9a0e-4294-9d00-4e4cbcfadabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  å¼€å§‹æ—¶é—´: 16:55:41.001\n",
      "â±ï¸  ç»“æŸæ—¶é—´: 16:55:50.952\n",
      "ğŸ“Š æ€»è€—æ—¶: 9.95s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "#import asyncio\n",
    "\n",
    "#è®¾ç½®å¹¶å‘æ•°ä¸º3\n",
    "config = RunnableConfig(max_concurrency=3)\n",
    "\n",
    "# è®°å½•å¼€å§‹æ—¶é—´\n",
    "start_time = time.time()\n",
    "print(f\"â±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
    "\n",
    "# å¹¶å‘è°ƒç”¨æ¨¡å‹ï¼Œæ‰¹é‡å¤„ç†ä¸‰ä¸ªé—®é¢˜\n",
    "# Jupyter å·²ç»æ”¯æŒé¡¶çº§ awaitï¼Œæ— éœ€ asyncio.run()\n",
    "responses = await model.abatch([\n",
    "    \"è¯·ä»‹ç»ä¸‹ä½ è‡ªå·±ã€‚\",\n",
    "    \"è¯·é—®ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
    "    \"ä½ çŸ¥é“æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ åŒºåˆ«ä¹ˆï¼Ÿ\"\n",
    "],config=config)\n",
    "\n",
    "# è®°å½•ç»“æŸæ—¶é—´\n",
    "end_time = time.time()\n",
    "total_duration = end_time - start_time\n",
    "\n",
    "print(f\"â±ï¸  ç»“æŸæ—¶é—´: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
    "print(f\"ğŸ“Š æ€»è€—æ—¶: {total_duration:.2f}s\")\n",
    "\n",
    "# for response in responses:\n",
    "#     print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96128d4-4dcd-4339-983b-497042f2b69c",
   "metadata": {},
   "source": [
    "**ç‰¹åˆ«æ³¨æ„**\n",
    "\n",
    "* RunnableConfig(max_concurrency=N) åªæ˜¯å‘Šè¯‰ LangChain åœ¨æ‰§è¡Œ abatch/batch æ—¶æœ€å¤šå¹¶å‘ N ä¸ªå­ä»»åŠ¡ã€‚\n",
    "\n",
    "* æ˜¯å¦èƒ½æé€Ÿï¼Œå–å†³äºæ•´ä¸ª pipeline æ˜¯å¦ä¸º I/O-boundï¼ˆç­‰å¾…ç½‘ç»œ/æ¨¡å‹æœåŠ¡ï¼‰æˆ– CPU/GPU-boundï¼ˆå•æ¬¡æ¨ç†å æ»¡èµ„æºï¼‰ã€‚\n",
    "\n",
    "* å¦‚æœå•æ¬¡æ¨ç†æŠŠ GPU/CPU å æ»¡ï¼ˆä¾‹å¦‚å•å¡çš„ vLLM åŒæ­¥æ¨ç†ï¼‰ï¼Œå¢åŠ å¹¶å‘ä¸ä¼šå˜å¿«ï¼Œç”šè‡³æ›´æ…¢ï¼ˆèµ„æºç«äº‰ï¼‰ã€‚\n",
    "\n",
    "* å¦‚æœè°ƒç”¨çš„æ˜¯è¿œç«¯äº‘ APIï¼ˆæœ‰ç½‘ç»œå»¶è¿Ÿï¼‰æˆ–èƒ½å¹¶è¡Œå¤„ç†å¤šè¯·æ±‚çš„æ¨¡å‹æœåŠ¡ï¼Œä¸”å®¢æˆ·ç«¯/æœåŠ¡ç«¯éƒ½å…è®¸å¹¶å‘ï¼Œåˆ™ä¼šæ˜æ˜¾æé€Ÿã€‚\n",
    "\n",
    "* æ¡†æ¶å†…éƒ¨å¯èƒ½ä¼šåœ¨æŸäº›ç»„ä»¶å¯¹å¹¶å‘åšåºåˆ—åŒ–ï¼ˆä¾‹å¦‚æŸäº› LLM å®¢æˆ·ç«¯åœ¨åç«¯ä½¿ç”¨åŒæ­¥ HTTP ä¼šé˜»å¡ï¼‰ï¼Œè¿™ä¹Ÿä¼šå¯¼è‡´çœ‹èµ·æ¥å¹¶å‘æ— æ•ˆã€‚\n",
    "\n",
    "* ç¡®è®¤ä½ ä½¿ç”¨çš„æ˜¯ abatchï¼ˆå¼‚æ­¥ï¼‰è€Œä¸æ˜¯ batchï¼ˆåŒæ­¥ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cd68ec18-333b-4208-82a3-3509dfe2a431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query 1 ===\n",
      "å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€äº›æœ‰åˆ›æ„çš„åå­—å»ºè®®ï¼Œé€‚åˆç”Ÿäº§å½©è‰²è¢œå­çš„å…¬å¸ï¼š\n",
      "\n",
      "1. å½©è¢œä¹å›­\n",
      "2. äº”å½©è¢œè‰º\n",
      "3. è‰²å½©ç¼¤çº·\n",
      "4. è¢œå­é­”æ³•\n",
      "5. å½©è™¹è¢œåŠ\n",
      "6. ä¹è¢œç”Ÿæ´»\n",
      "7. è‰²è¢œå¥‡é‡\n",
      "8. è¢œè¶£æ— é™\n",
      "9. é¢œå½©è¢œèˆ\n",
      "10. è¢œå­èŠ±å›­\n",
      "\n",
      "å¸Œæœ›è¿™äº›åå­—èƒ½æ¿€å‘ä½ çš„çµæ„Ÿï¼å¦‚æœæœ‰æ›´å…·ä½“çš„é£æ ¼æˆ–ä¸»é¢˜éœ€æ±‚ï¼Œæ¬¢è¿å‘Šè¯‰æˆ‘ã€‚\n",
      "{'extra': 'allow'}\n",
      "=== Query 2 ===\n",
      "ä¸ºç”Ÿäº§ç¯ä¿å’–å•¡æ¯çš„å…¬å¸èµ·åå­—å¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªé€‰é¡¹ï¼š\n",
      "\n",
      "1. ç»¿æ¯å·¥åŠ\n",
      "2. è‡ªç„¶å’–å•¡æ¯\n",
      "3. ç”Ÿæ€æ¯ç¼˜\n",
      "4. ç¯ä¿é†‡é¦™\n",
      "5. çº¯å‡€å’–å•¡å™¨\n",
      "6. ç»¿æ„ç”Ÿæ´»\n",
      "7. ç”Ÿæ€å“å‘³\n",
      "8. ç»¿æ„å’–å•¡\n",
      "9. å‹å¥½æ¯å»Š\n",
      "10. ç»¿è‰²ä¸€æ¯\n",
      "\n",
      "å¸Œæœ›è¿™äº›åå­—èƒ½æ¿€å‘æ‚¨çš„çµæ„Ÿï¼\n",
      "{'extra': 'allow'}\n",
      "=== Query 3 ===\n",
      "ä»¥ä¸‹æ˜¯ä¸€äº›ä¸ºç”Ÿäº§æ™ºèƒ½æ°´æ¯çš„å…¬å¸èµ·çš„åå­—å»ºè®®ï¼š\n",
      "\n",
      "1. æ™ºæ°´æ¯\n",
      "2. æ°´æ™ºç§‘æŠ€\n",
      "3. æ™ºèƒ½æ¯å­\n",
      "4. æ°´æ‚¦ç§‘æŠ€\n",
      "5. æ¸…æ¶¦æ™ºèƒ½\n",
      "6. æ°´äº«æœªæ¥\n",
      "7. æ™ºèƒ½é¥®æ°´å®¶\n",
      "8. æ°´æ¯æ™ºé€ \n",
      "9. æ™ºé¥®ç”Ÿæ´»\n",
      "10. æ¶¦å¿ƒç§‘æŠ€\n",
      "\n",
      "å¸Œæœ›è¿™äº›åå­—èƒ½æ¿€å‘ä½ çš„çµæ„Ÿï¼\n",
      "{'extra': 'allow'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# é…ç½®ï¼šæœ€å¤š 2 ä¸ªå¹¶å‘ä»»åŠ¡\n",
    "config = RunnableConfig(\n",
    "    max_concurrency=2,    # æœ€å¤§å¹¶å‘æ•°ï¼šé™åˆ¶åŒæ—¶è¿è¡Œçš„ä»»åŠ¡æ•°é‡ï¼Œé˜²æ­¢èµ„æºè€—å°½\n",
    "    abstimeout=8.0,       # å•ä¸ªä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼šè¶…è¿‡æ­¤æ—¶é—´æœªå®Œæˆçš„ä»»åŠ¡å°†è¢«å¼ºåˆ¶ç»ˆæ­¢\n",
    "    metadata={\"request_id\": \"abc123\", \"task\": \"query\"},  # å…ƒæ•°æ®ï¼šè®°å½•è¯·æ±‚IDå’Œä»»åŠ¡ç±»å‹ï¼Œä¾¿äºè¿½è¸ªå’Œæ—¥å¿—åˆ†æ\n",
    ")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªå¸¦æœ‰{product}å ä½ç¬¦å˜é‡çš„æ¨¡æ¿\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"ä¸ºç”Ÿäº§{product}çš„å…¬å¸èµ·ä¸€ä¸ªå¥½åå­—ï¼Ÿ\"\n",
    ")\n",
    "\n",
    "# å‡†å¤‡ä¸€ä¸ªè¾“å…¥åˆ—è¡¨\n",
    "inputs = [\"å½©è‰²è¢œå­\", \"ç¯ä¿å’–å•¡æ¯\", \"æ™ºèƒ½æ°´æ¯\"]\n",
    "formatted_prompts = [prompt_template.format(product=product) for product in inputs]\n",
    "\n",
    "# Jupyter å·²ç»æ”¯æŒé¡¶çº§ awaitï¼Œæ— éœ€ asyncio.run()\n",
    "results = await model.abatch(formatted_prompts, config=config)\n",
    "\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"=== Query {i+1} ===\")\n",
    "    print(r.content)\n",
    "    print(r.model_config)\n",
    "\n",
    "# å¯èƒ½è¾“å‡º: ['Fun Socks Co.', 'Green Cup Co.', 'HydraSmart']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bb925-7ffa-40d7-9a3c-7a0ff2570d98",
   "metadata": {},
   "source": [
    "æ›´å¤šconfigå‚æ•°è§£é‡Šå¦‚ä¸‹ï¼š\n",
    "| å±æ€§å               | ç±»å‹      | è¯´æ˜             |\n",
    "| ----------------- | ------- | -------------- |\n",
    "| `max_concurrency` | `int`   | æœ€å¤§å¹¶è¡Œæ‰§è¡Œæ•°        |\n",
    "| `timeout`         | `float` | æ¯ä¸ªè¯·æ±‚çš„æœ€å¤§è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ |\n",
    "| `callbacks`       | `list`  | è§¦å‘äº‹ä»¶å›è°ƒï¼Œç”¨äºæ—¥å¿—æˆ–ç›‘æ§ |\n",
    "| `metadata`        | `dict`  | é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯ç”¨äºè¿½è¸ª |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b838859-493e-4c01-a606-706b42a4007e",
   "metadata": {},
   "source": [
    "### 3.6 æµå¼ä¼ è¾“ (Streaming)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba5b05-f900-4e2a-b18b-eb18a0dd18d0",
   "metadata": {},
   "source": [
    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼š\n",
    "1. æµå¼è¾“å‡ºä¾èµ–äºæ•´ä¸ªç¨‹åºé“¾è·¯éƒ½æ”¯æŒâ€œé€å—å¤„ç†â€ã€‚å¦‚æœç¨‹åºä¸­çš„æŸä¸ªç¯èŠ‚å¿…é¡»ç­‰å¾…å®Œæ•´è¾“å‡ºï¼ˆå¦‚éœ€ä¸€æ¬¡æ€§å†™å…¥æ•°æ®åº“ï¼‰ï¼Œåˆ™æ— æ³•ç›´æ¥ä½¿ç”¨ Streamingï¼›\n",
    "   \n",
    "3. LangChain 1.0 è¿›ä¸€æ­¥ä¼˜åŒ–äº†æµå¼æœºåˆ¶ï¼Œå¼•å…¥ è‡ªåŠ¨æµå¼æ¨¡å¼ï¼ˆAuto-streamingï¼‰ã€‚ä¾‹å¦‚åœ¨Agentä¸­ï¼Œå¦‚æœæ•´ä½“ç¨‹åºå¤„äº streaming æ¨¡å¼ï¼Œå³ä¾¿èŠ‚ç‚¹ä¸­è°ƒç”¨ model.invoke()ï¼ŒLangChain ä¹Ÿä¼šè‡ªåŠ¨æµå¼åŒ–æ¨¡å‹è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f5d6569-b0e0-4e9f-81f8-a0f0497669fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤§æµ·æ˜¯ä¸€å¹…å£®ä¸½çš„ç”»å·ï¼Œæ³¢æ¾œå£®é˜”ã€æµ©ç€šæ— å ã€‚å®ƒçš„è‰²å½©åœ¨é˜³å…‰çš„ç…§å°„ä¸‹å˜åŒ–å¤šç«¯ï¼Œæ—¶è€Œæ¹›è“ï¼Œæ—¶è€Œç¢§ç»¿ï¼Œæ—¶è€Œç°è’™è’™çš„ï¼Œä»¿ä½›è•´è—ç€æ— å°½çš„ç§˜å¯†ã€‚æµ·æµªè½»è½»æ‹æ‰“ç€å²¸è¾¹ï¼Œå‘å‡ºæ‚¦è€³çš„å£°éŸ³ï¼Œå¸¦æ¥ä¸€é˜µé˜µå’¸æ¹¿çš„æµ·é£ï¼Œè®©äººå¿ƒæ—·ç¥æ€¡ã€‚åœ¨è¿™ç‰‡å¹¿è¢¤çš„æ°´åŸŸä¸­ï¼Œç”Ÿå‘½è“¬å‹ƒå‘å±•ï¼Œå„ç§æµ·æ´‹ç”Ÿç‰©åœ¨å…¶ä¸­ç¿©ç¿©èµ·èˆï¼Œæ„æˆäº†ä¸€å¹…ç”Ÿæœºå‹ƒå‹ƒçš„ç”Ÿæ€å›¾æ™¯ã€‚å¤§æµ·æ—¢æ˜¯è‡ªç„¶çš„å¥‡è¿¹ï¼Œä¹Ÿæ˜¯äººç±»æ¢¦æƒ³ä¸æ¢ç´¢çš„æºæ³‰ï¼Œè•´å«ç€æ— å°½çš„å¯èƒ½æ€§ä¸ç¥ç§˜æ„Ÿã€‚"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨.stream()æ–¹æ³•è¿›è¡Œæµå¼ä¼ è¾“\n",
    "for chunk in model.stream(\"ç”¨ä¸€æ®µè¯æè¿°å¤§æµ·ã€‚\"):\n",
    "    print(chunk.content, end=\"\", flush=True)  # é€å—æ‰“å°\n",
    "        \n",
    "# è¾“å‡ºä¼šåƒçœŸæ­£çš„æ‰“å­—æ•ˆæœä¸€æ ·ï¼Œä¸€ä¸ªä¸€ä¸ªè¯åœ°å‡ºç°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49a1fc-381e-4f60-8645-f9ee9ae023cd",
   "metadata": {},
   "source": [
    "æ¯ä¸ª AIMessageChunk éƒ½å¯ä»¥é€šè¿‡åŠ æ³• + æ“ä½œç¬¦æ‹¼æ¥ã€‚LangChain å†…éƒ¨ä¸ºæ­¤è®¾è®¡äº†â€œæ¶ˆæ¯å—ç›¸åŠ ï¼ˆchunk summationï¼‰â€æœºåˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42af674e-ff15-4e6f-bfe3-4d43d27aa157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½ å¥½\n",
      "ä½ å¥½ï¼\n",
      "ä½ å¥½ï¼å¾ˆ\n",
      "ä½ å¥½ï¼å¾ˆé«˜\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ \n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆ\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ \n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–å˜é‡ï¼Œç”¨äºç´¯ç§¯æ¨¡å‹è¿”å›çš„å®Œæ•´å†…å®¹\n",
    "full = None  # åˆå§‹å€¼ä¸ºç©º\n",
    "\n",
    "# ä½¿ç”¨æµå¼æ–¹å¼è°ƒç”¨æ¨¡å‹ï¼Œé€å—æ¥æ”¶è¿”å›å†…å®¹\n",
    "for chunk in model.stream(\"ä½ å¥½ï¼Œå¥½ä¹…ä¸è§\"):\n",
    "        \n",
    "    # å¦‚æœæ˜¯ç¬¬ä¸€å—å†…å®¹ï¼Œåˆ™ç›´æ¥èµ‹å€¼ï¼›å¦åˆ™æ‹¼æ¥åˆ°å·²æœ‰å†…å®¹\n",
    "    full = chunk if full is None else full + chunk\n",
    "        \n",
    "    # æ‰“å°å½“å‰ç´¯ç§¯çš„æ–‡æœ¬å†…å®¹\n",
    "    print(full.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "73bbd15d-fda4-4872-8abc-3f322c3b899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'text': 'ä½ å¥½ï¼å¾ˆé«˜å…´å†æ¬¡è§åˆ°ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}]\n"
     ]
    }
   ],
   "source": [
    "print(full.content_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a4ec4-da53-4983-b8a0-80646b41cac5",
   "metadata": {},
   "source": [
    "### astream_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c5593-ee58-465f-94f7-1cb1ff7988d3",
   "metadata": {},
   "source": [
    "æ­¤å¤–ï¼ŒLangChain è¿˜æ”¯æŒé€šè¿‡ astream_events() å¯¹è¯­ä¹‰äº‹ä»¶è¿›è¡Œå¼‚æ­¥æµå¼ç›‘å¬ï¼Œé€‚åˆéœ€è¦è¿‡æ»¤ä¸åŒäº‹ä»¶ç±»å‹çš„å¤æ‚åœºæ™¯ã€‚\n",
    "\n",
    "ä½ èƒ½çœ‹åˆ° å®Œæ•´è¯­ä¹‰ç”Ÿå‘½å‘¨æœŸäº‹ä»¶,åŒ…æ‹¬ï¼š\n",
    "\n",
    "* on_chain_start\n",
    "\n",
    "* on_prompt_start / on_prompt_end\n",
    "\n",
    "* on_llm_start\n",
    "\n",
    "* on_llm_streamï¼ˆé€ Tokenï¼‰\n",
    "\n",
    "* on_llm_end\n",
    "\n",
    "* on_chain_end\n",
    "\n",
    "éå¸¸é€‚åˆï¼š\n",
    "\n",
    "* è°ƒè¯• LLM æ¨ç†è¿‡ç¨‹\n",
    "\n",
    "* äº†è§£ LangChain pipeline çš„æ‰§è¡Œé¡ºåº\n",
    "\n",
    "* æ„å»º UIï¼ˆå¦‚ web å‰ç«¯çš„é€ token streamingï¼‰\n",
    "\n",
    "* å®ç°æ—¥å¿—ã€å¯è§‚æµ‹æ€§ã€ç›‘æ§ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236ce491-36e5-4dd0-8a0a-da901615dcc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/langchain/lib/python3.11/site-packages/pydantic/v1/main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event] type=on_chain_start\n",
      "   data: {'input': {'question': 'è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚'}}\n",
      "-----------------------------\n",
      "[Event] type=on_prompt_start\n",
      "   data: {'input': {'question': 'è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚'}}\n",
      "-----------------------------\n",
      "[Event] type=on_prompt_end\n",
      "   data: {'input': {'question': 'è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚'}, 'output': ChatPromptValue(messages=[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚', additional_kwargs={}, response_metadata={})])}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_start\n",
      "   data: {'input': {'messages': [[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚', additional_kwargs={}, response_metadata={})]]}}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='Lang', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='Chain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='Chain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content=' çš„', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content=' çš„', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ ¸', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ ¸', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¿ƒ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¿ƒ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æƒ³', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æƒ³', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ˜¯', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ˜¯', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é€šè¿‡', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é€šè¿‡', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='åŒº', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='åŒº', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å—', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å—', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é“¾', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é“¾', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æŠ€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æŠ€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æœ¯', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æœ¯', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å®', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å®', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç°', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç°', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¤š', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¤š', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¯­', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¯­', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¨€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¨€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç¿»', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç¿»', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¯‘', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¯‘', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='çš„', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='çš„', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å»', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å»', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ä¸­', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ä¸­', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¿ƒ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¿ƒ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='åŒ–', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='åŒ–', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¹³', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¹³', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å°', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å°', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ï¼Œ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ï¼Œ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content=' èµ‹', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content=' èµ‹', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='äºˆ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='äºˆ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç”¨æˆ·', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç”¨æˆ·', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ›´', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æ›´', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å®‰', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å®‰', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å…¨', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å…¨', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ã€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ã€', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¿«', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¿«', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é€Ÿ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é€Ÿ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å’Œ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å’Œ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¯', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='å¯', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='é ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='çš„', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='çš„', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç¿»', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ç¿»', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¯‘', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='è¯‘', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æœåŠ¡', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='æœåŠ¡', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ä½“', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ä½“', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='éªŒ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='éªŒ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ã€‚', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='ã€‚', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_stream\n",
      "   data: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e', chunk_position='last')}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_stream\n",
      "   data: {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e', chunk_position='last')}\n",
      "-----------------------------\n",
      "[Event] type=on_chat_model_end\n",
      "   data: {'input': {'messages': [[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚', additional_kwargs={}, response_metadata={})]]}, 'output': {'generations': [[{'text': 'LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡åŒºå—é“¾æŠ€æœ¯å®ç°å¤šè¯­è¨€ç¿»è¯‘çš„å»ä¸­å¿ƒåŒ–å¹³å°ï¼Œ èµ‹äºˆç”¨æˆ·æ›´å®‰å…¨ã€å¿«é€Ÿå’Œå¯é çš„ç¿»è¯‘æœåŠ¡ä½“éªŒã€‚', 'generation_info': {'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content='LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡åŒºå—é“¾æŠ€æœ¯å®ç°å¤šè¯­è¨€ç¿»è¯‘çš„å»ä¸­å¿ƒåŒ–å¹³å°ï¼Œ èµ‹äºˆç”¨æˆ·æ›´å®‰å…¨ã€å¿«é€Ÿå’Œå¯é çš„ç¿»è¯‘æœåŠ¡ä½“éªŒã€‚', additional_kwargs={}, response_metadata={'model_provider': 'openai', 'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e', chunk_position='last')}]], 'llm_output': None, 'run': None, 'type': 'LLMResult'}}\n",
      "-----------------------------\n",
      "[Event] type=on_chain_end\n",
      "   data: {'output': AIMessageChunk(content='LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡åŒºå—é“¾æŠ€æœ¯å®ç°å¤šè¯­è¨€ç¿»è¯‘çš„å»ä¸­å¿ƒåŒ–å¹³å°ï¼Œ èµ‹äºˆç”¨æˆ·æ›´å®‰å…¨ã€å¿«é€Ÿå’Œå¯é çš„ç¿»è¯‘æœåŠ¡ä½“éªŒã€‚', additional_kwargs={}, response_metadata={'model_provider': 'openai', 'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'}, id='lc_run--0d847770-fb87-43e9-8382-8f70c874430e', chunk_position='last')}\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. æ„å»ºæœ€ç®€å•çš„ Prompt + LLM\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 2. åˆå§‹åŒ– ChatOpenAI å®ä¾‹ï¼ŒæŒ‡å®šä½¿ç”¨ gpt-3.5-turbo æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",   \n",
    ")\n",
    "\n",
    "# 3. ä½¿ç”¨ç®¡é“ç¬¦å°† prompt æ¨¡æ¿ä¸ llm è¿æ¥ï¼Œæ„å»ºå¯è¿è¡Œçš„é“¾\n",
    "chain = prompt | llm\n",
    "\n",
    "# 4. ä½¿ç”¨ astream_events() ç›‘å¬æ‰€æœ‰è¯­ä¹‰äº‹ä»¶\n",
    "events = chain.astream_events(\n",
    "    {\"question\": \"è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain 1.0 çš„æ ¸å¿ƒæ€æƒ³ã€‚\"},\n",
    "    version=\"v1\",  # å¿…é¡»æŒ‡æ˜ç‰ˆæœ¬ï¼Œv1 æ‰æœ‰è¯­ä¹‰äº‹ä»¶\n",
    ")\n",
    "\n",
    "async for event in events:\n",
    "    # æ‰“å°äº‹ä»¶ç±»å‹\n",
    "    print(f\"\"\"[Event] type={event[\"event\"]}\"\"\")\n",
    "\n",
    "    # å±•ç¤ºå…³é”®å­—æ®µ\n",
    "    if \"data\" in event:\n",
    "        print(\"   data:\", event[\"data\"])\n",
    "    print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8942ba-72bd-4cf2-92d2-0a80859ead13",
   "metadata": {},
   "source": [
    "### 3.7 ç»“æ„åŒ–è¾“å‡ºè§£æ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49657a31-73b7-4426-97d0-57ee08f78b25",
   "metadata": {},
   "source": [
    "* å¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦æ¨¡å‹è¿”å›ç»“æ„åŒ–çš„æ•°æ®ï¼ˆå¦‚JSONï¼‰ï¼Œä»¥ä¾¿ç¨‹åºåç»­å¤„ç†ã€‚è¾“å‡ºè§£æå™¨ (Output Parsers) æ­£æ˜¯ä¸ºæ­¤è€Œç”Ÿã€‚\n",
    "  \n",
    "* æœ€å¼ºå¤§çš„æ˜¯ StructuredOutputParserï¼Œå®ƒå¯ä»¥ä¸ Zodï¼ˆTypeScriptï¼‰æˆ– Pydanticï¼ˆPythonï¼‰ç­‰æ¨¡å¼å®šä¹‰å·¥å…·ç»“åˆä½¿ç”¨ï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆé¢„å®šæ ¼å¼ã€‚\n",
    "\n",
    "  - ç›®æ ‡ï¼šè®©å¤§æ¨¡å‹è¿”å›å¯ç¨‹åºè§£æçš„æ•°æ®\n",
    "\n",
    "  - ä»»åŠ¡ï¼šå­¦ä¹ Pydanticæ¨¡å‹ï¼Œä½¿ç”¨with_structured_output()\n",
    " \n",
    "  - äº§å‡ºï¼šä¸€ä¸ªä¿¡æ¯æŠ½å–å™¨ï¼ˆæå–ç”µå½±ä¿¡æ¯/æ–°é—»æ‘˜è¦ï¼‰\n",
    " \n",
    "  - å…³é”®ç‚¹ï¼šToolStrategyå…¼å®¹æ‰€æœ‰æ¨¡å‹ï¼ŒProviderStrategyæ›´å¯é "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c0947-0a8f-4601-833e-d9274ca6f3c7",
   "metadata": {},
   "source": [
    "### with_structured_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318b793-b342-499f-8c35-9adc98111ba6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä½¿ç”¨ Pydantic çš„ BaseModel å®šä¹‰ä¸€ä¸ªä¸¥æ ¼çš„æ•°æ®ç»“æ„ã€‚æ¯ä¸ªå­—æ®µéƒ½æ˜ç¡®äº†ç±»å‹ï¼ˆå¦‚ strã€intã€floatï¼‰ï¼Œå¹¶ç”¨ Field(..., description=\"...\") æä¾›è¯­ä¹‰æè¿°ã€‚æ®æ­¤ï¼Œæ¨¡å‹å›å¤æ—¶ï¼ŒLangChain ä¼šè¦æ±‚ LLM çš„è¾“å‡ºå¿…é¡»èƒ½å¡«å……è¿™äº›å­—æ®µã€‚ç„¶åä½¿ç”¨with_structured_outputå³å¯å¼•å¯¼æ¨¡å‹è¿›è¡Œç»“æ„åŒ–è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89465aaa-376a-4ccd-b79b-0c0a8b37e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of result: <class '__main__.Person'>\n",
      "Result object: name='çº¦ç¿°Â·å¤šä¼Š' age=30 high=0 hobbies=['é˜…è¯»', 'è¿œè¶³', 'å¼¹å‰ä»–']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.utils.pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. å®šä¹‰æœŸæœ›çš„è¾“å‡ºç»“æ„ (Pydantic æ¨¡å‹)\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"äººçš„å§“å\")\n",
    "    age: int = Field(description=\"äººçš„å¹´é¾„\")\n",
    "    high: int = Field(description=\"äººçš„èº«é«˜\")\n",
    "    hobbies: List[str] = Field(description=\"äººçš„çˆ±å¥½åˆ—è¡¨\")\n",
    "\n",
    "# 2. åˆå§‹åŒ–æ¨¡å‹å¹¶ç»‘å®šç»“æ„åŒ–è¾“å‡ºæ ¼å¼\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "structured_llm = llm.with_structured_output(Person)\n",
    "\n",
    "# 3. è°ƒç”¨æ¨¡å‹å¹¶è·å– Pydantic å¯¹è±¡ï¼Œæ„é€ æç¤ºï¼šè¦æ±‚æå–çº¦ç¿°Â·å¤šä¼Šçš„å§“åã€å¹´é¾„å’Œå…´è¶£çˆ±å¥½\n",
    "prompt = \"æå–åä¸ºçº¦ç¿°Â·å¤šä¼Šçš„äººçš„ä¿¡æ¯ï¼Œæå–ä¸åˆ°çš„æ•°æ®å°±ä¸ºç©ºå€¼ã€‚ä»–30å²ï¼Œå–œæ¬¢é˜…è¯»ã€è¿œè¶³å’Œå¼¹å‰ä»–.\"\n",
    "\n",
    "result = structured_llm.invoke(prompt)\n",
    "\n",
    "# 4. éªŒè¯ç»“æœ\n",
    "print(f\"Type of result: {type(result)}\")\n",
    "print(f\"Result object: {result}\")\n",
    "\n",
    "# 5.åˆ¤æ–­resultæ˜¯å¦å±äºPersonç±»\n",
    "assert isinstance(result, Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f208ca-2876-4820-9d92-1ce7dec0aadb",
   "metadata": {},
   "source": [
    "* è€Œå¦‚æœæƒ³è¦è·å¾—æ¨¡å‹çš„å®Œæ•´å›å¤ï¼Œåˆ™å¯ä»¥è®¾ç½®`include_raw=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4d3151a2-209a-4b9f-ab5a-c18872cde06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of result: <class 'dict'>\n",
      "Result object: {'raw': AIMessage(content='{\"name\":\"çº¦ç¿°Â·å¤šä¼Š\",\"age\":30,\"hobbies\":[\"é˜…è¯»\",\"è¿œè¶³\",\"å¼¹å‰ä»–\"]}', additional_kwargs={'parsed': Person(name='çº¦ç¿°Â·å¤šä¼Š', age=30, hobbies=['é˜…è¯»', 'è¿œè¶³', 'å¼¹å‰ä»–']), 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 165, 'total_tokens': 192, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CdCdia77rTAVnBuqiWo80HxvDZX97', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a36ddb6c-d53b-45c9-bcb5-dcf880f3d2f5-0', usage_metadata={'input_tokens': 165, 'output_tokens': 27, 'total_tokens': 192, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), 'parsed': Person(name='çº¦ç¿°Â·å¤šä¼Š', age=30, hobbies=['é˜…è¯»', 'è¿œè¶³', 'å¼¹å‰ä»–']), 'parsing_error': None}\n"
     ]
    }
   ],
   "source": [
    "# 1. é…ç½®ç»“æ„åŒ–è¾“å‡ºï¼šæŒ‡å®šè¿”å› Pydantic æ¨¡å‹ Personï¼Œå¹¶ä¿ç•™åŸå§‹å“åº”\n",
    "structured_llm = llm.with_structured_output(Person, include_raw=True)\n",
    "\n",
    "# 2. è°ƒç”¨æ¨¡å‹å¹¶è·å– Pydantic å¯¹è±¡\n",
    "prompt = \"æå–åä¸ºçº¦ç¿°Â·å¤šä¼Šçš„äººçš„ä¿¡æ¯ã€‚ä»–30å²ï¼Œå–œæ¬¢é˜…è¯»ã€è¿œè¶³å’Œå¼¹å‰ä»–.\"\n",
    "\n",
    "# 3. è°ƒç”¨æ¨¡å‹ï¼Œè¿”å›ç»“æ„åŒ–ç»“æœï¼ˆåŒ…å«è§£æåçš„ Person å¯¹è±¡å’ŒåŸå§‹æ–‡æœ¬ï¼‰\n",
    "result = structured_llm.invoke(prompt)\n",
    "\n",
    "# 4. éªŒè¯ç»“æœï¼šæ‰“å°è¿”å›å€¼çš„ç±»å‹ä¸å†…å®¹ï¼Œä¾¿äºè°ƒè¯•\n",
    "print(f\"Type of result: {type(result)}\")\n",
    "print(f\"Result object: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb603284-ebf1-42c6-81c2-d44edef45cb0",
   "metadata": {},
   "source": [
    "### agentä¸­ç»“æ„åŒ–è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3072e879-f9c0-4c79-89a0-c1ad2141d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŒ—äº¬å¤©æ°”: æ™´, 10Â°C\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field,field_validator\n",
    "from typing import Literal\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 1. å®šä¹‰å¤©æ°”ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹\n",
    "class WeatherForecast(BaseModel):\n",
    "    \"\"\"å¤©æ°”é¢„æŠ¥ç»“æ„åŒ–è¾“å‡º\"\"\"\n",
    "    city: str = Field(description=\"åŸå¸‚åç§°\")\n",
    "    temperature: int = Field(description=\"æ¸©åº¦(æ‘„æ°åº¦)\")\n",
    "    condition: Literal[\"æ™´\", \"é›¨\", \"å¤šäº‘\", \"é›ª\"] = Field(description=\"å¤©æ°”çŠ¶å†µ\")\n",
    "\n",
    "# 2. åŠ è½½æ¨¡å‹\n",
    "model = load_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    ")\n",
    "\n",
    "# 3. åˆ›å»ºæ™ºèƒ½ä½“\n",
    "agent = create_agent(\n",
    "    model=model,                      # åŠ è½½çš„æ¨¡å‹\n",
    "    tools=[],                         # å·¥å…·åˆ—è¡¨ï¼Œè¿™é‡Œä¸ºç©º\n",
    "    response_format=WeatherForecast   # æŒ‡å®šç»“æ„åŒ–è¾“å‡ºæ ¼å¼\n",
    ")\n",
    "\n",
    "# 4. è°ƒç”¨æ™ºèƒ½ä½“è§£æå¤©æ°”æè¿°\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"åŒ—äº¬ä»Šå¤©é˜³å…‰æ˜åªšï¼Œæ¸©åº¦10åº¦\"\n",
    "    }]\n",
    "})\n",
    "\n",
    "# 5. æå–å¹¶æ‰“å°ç»“æœ\n",
    "forecast = result[\"structured_response\"]\n",
    "print(f\"{forecast.city}å¤©æ°”: {forecast.condition}, {forecast.temperature}Â°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a68f3-748f-430a-b4c9-25a9399b9b51",
   "metadata": {},
   "source": [
    "### å¸¦åˆ¤æ–­çš„ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c9b61e6a-5625-4a6a-bf48-a68b2ed6fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='å¼ ä¸‰' age=150\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# 1. å®šä¹‰å¹´é¾„æ¨¡å‹ï¼Œé™åˆ¶èŒƒå›´ 0-150\n",
    "class AgeProfile(BaseModel):\n",
    "    name: str\n",
    "    age: int = Field(ge=0, le=150)  # å¹´é¾„å¿…é¡»åœ¨0-150ä¹‹é—´\n",
    "\n",
    "# 2. å®šä¹‰æ¨¡å‹\n",
    "model = load_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    ")\n",
    "\n",
    "# 3. åˆ›å»ºæ™ºèƒ½ä½“agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    response_format=AgeProfile\n",
    ")\n",
    "\n",
    "# 4. æ¨¡å‹è¿”å›age=999ï¼ˆéæ³•å€¼ï¼‰\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"å¼ ä¸‰çš„å¹´é¾„æ˜¯999å²\"  # æ˜æ˜¾ä¸åˆç†çš„æ•°æ®\n",
    "    }]\n",
    "})\n",
    "\n",
    "# LangChainä¼šè‡ªåŠ¨ï¼š\n",
    "# 1. æ•è·ValidationError\n",
    "# 2. åœ¨ToolMessageä¸­åé¦ˆé”™è¯¯è¯¦æƒ…\n",
    "# 3. è®©æ¨¡å‹é‡æ–°ç”Ÿæˆ\n",
    "# æœ€ç»ˆè¿”å›åˆæ³•å€¼\n",
    "print(result[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6404fd0-153c-4e06-81d1-7c9c1e083b22",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db7173a0-4be6-4455-b553-e05eaba45ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'åŒ—äº¬', 'temperature': 25, 'condition': 'æ™´'}\n",
      "åŒ—äº¬\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. å®šä¹‰è¾“å‡ºç»“æ„\n",
    "class WeatherInfo(BaseModel):\n",
    "    \"\"\"å¤©æ°”ä¿¡æ¯\"\"\"\n",
    "    city: str = Field(description=\"åŸå¸‚åç§°\")\n",
    "    temperature: int = Field(description=\"æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰\")\n",
    "    condition: str = Field(description=\"å¤©æ°”çŠ¶å†µ\")\n",
    "\n",
    "# 2. åˆ›å»º JSON è¾“å‡ºè§£æå™¨\n",
    "json_parser = JsonOutputParser(pydantic_object=WeatherInfo)\n",
    "\n",
    "# 3. åˆ›å»ºæç¤ºæ¨¡æ¿ï¼ˆå…³é”®ï¼šå¿…é¡»åŒ…å« \"json\" è¿™ä¸ªè¯ï¼‰\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "        \n",
    "\"\"\"è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯æå–å¤©æ°”æ•°æ®ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ã€‚\n",
    "\n",
    "ä¿¡æ¯ï¼š{weather_info}\n",
    "\n",
    "è¯·è¿”å›åŒ…å«ä»¥ä¸‹å­—æ®µçš„ JSONï¼š\n",
    "- city: åŸå¸‚åç§°\n",
    "- temperature: æ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰\n",
    "- condition: å¤©æ°”çŠ¶å†µ\n",
    "\n",
    "å¿…é¡»è¿”å›ä»¥ä¸‹ JSON æ ¼å¼ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ï¼‰ï¼š\n",
    "{{\"city\": \"åŸå¸‚åç§°\", \"temperature\": æ¸©åº¦æ•°å­—, \"condition\": \"å¤©æ°”çŠ¶å†µ\"}}\n",
    "\n",
    "ä¾‹å¦‚ï¼š{{\"city\": \"åŒ—äº¬\", \"temperature\": 25, \"condition\": \"æ™´\"}}\n",
    "\n",
    "JSON æ ¼å¼ï¼š\n",
    "\"\"\")\n",
    "\n",
    "# 4. å®šä¹‰æ¨¡å‹\n",
    "model = load_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    ")\n",
    "\n",
    "# 5. æ„å»ºé“¾\n",
    "runnable = prompt | model | json_parser\n",
    "\n",
    "# 6. è°ƒç”¨\n",
    "result = runnable.invoke({\"weather_info\": \"åŒ—äº¬ä»Šå¤©æ™´ï¼Œæ¸©åº¦25åº¦\"})\n",
    "print(result)\n",
    "print(result[\"city\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b318e2-1969-4e62-8c7c-ed36555a34b2",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* å¼ºåˆ¶è¡¨æ ¼å±…ä¸­ã€è‡ªåŠ¨æ¢è¡Œå¹¶é€‚åº”å•å…ƒæ ¼å®½åº¦ */\n",
    ".rendered_html table, .jp-RenderedHTMLCommon table {\n",
    "    margin-left: auto !important;\n",
    "    margin-right: auto !important;\n",
    "    width: auto !important; /* å…è®¸è¡¨æ ¼æ ¹æ®å†…å®¹æ”¶ç¼© */\n",
    "    max-width: 100%; /* é˜²æ­¢è¡¨æ ¼æº¢å‡ºå•å…ƒæ ¼ */\n",
    "    table-layout: fixed; /* å›ºå®šå¸ƒå±€ç®—æ³•ï¼Œå¯¹é•¿æ–‡æœ¬æ¢è¡Œè‡³å…³é‡è¦ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th,\n",
    ".rendered_html td, .jp-RenderedHTMLCommon td {\n",
    "    white-space: normal !important; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */\n",
    "    word-wrap: break-word; /* å¯¹é•¿å•è¯æˆ–URLè¿›è¡Œå¼ºåˆ¶æ¢è¡Œ */\n",
    "    text-align: left; /* é»˜è®¤å†…å®¹å·¦å¯¹é½ */\n",
    "}\n",
    ".rendered_html th, .jp-RenderedHTMLCommon th {\n",
    "    text-align: center !important; /* è¡¨å¤´æ–‡æœ¬å±…ä¸­ */\n",
    "}\n",
    "</style>\n",
    "\n",
    "| åˆ†ç±» | å¸¸ç”¨è§£æå™¨ | ä½œç”¨ |\n",
    "| :---: | :---: | :---: |\n",
    "| **åŸºç¡€è§£æ** | `StrOutputParser` | å°†æ¨¡å‹è¾“å‡ºè§£ææˆçº¯å­—ç¬¦ä¸²ï¼ˆé»˜è®¤ï¼‰ |\n",
    "| **JSON ç»“æ„åŒ–è§£æ** | `JsonOutputParser` | å°† LLM è¾“å‡ºå¼ºåˆ¶è§£æä¸º JSON |\n",
    "|  | `PydanticOutputParser` | ä½¿ç”¨ Pydantic v1 æ¨¡å‹è¿›è¡Œç»“æ„åŒ–è¾“å‡º |\n",
    "|  | `PydanticOutputFunctionsParser` | ç”¨äº Function Calling çš„ Pydantic ç»“æ„åŒ–è§£æ |\n",
    "| **åˆ—è¡¨è§£æ** | `CommaSeparatedListOutputParser` | è¾“å‡ºå¦‚ `\"a,b,c\"`<br/> â†’ `[\"a\", \"b\", \"c\"]` |\n",
    "|  | `ListOutputParser` | æ›´é€šç”¨çš„åˆ—è¡¨è§£æ |\n",
    "| **å¸ƒå°”/æ•°å€¼è§£æ** | `BooleanOutputParser` | è¾“å‡º \"yes\" / \"no\" â†’ True/False |\n",
    "|  | `FloatOutputParser` | è¾“å‡ºæ¨¡å‹å†…å®¹è½¬ float |\n",
    "|  | `IntOutputParser` | è¾“å‡ºæ¨¡å‹å†…å®¹è½¬ int |\n",
    "| **å¤æ‚ç»“æ„åŒ–** | `EnumOutputParser` | è®©æ¨¡å‹è¾“å‡ºå›ºå®šå‡ ä¸ªé€‰é¡¹ä¹‹ä¸€ |\n",
    "|  | `DataclassOutputParser` | ä½¿ç”¨ Python dataclass è¿›è¡Œç»“æ„åŒ–è¾“å‡º |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74339013-5780-4aff-87d2-bd190df3b452",
   "metadata": {},
   "source": [
    "**ç»“æ„åŒ–è¾“å‡ºå…³é”®è¦ç‚¹ï¼š**\n",
    "\n",
    "1. **è¾“å‡ºjsonæ ¼å¼æç¤ºè¯å¿…é¡»åŒ…å« \"json\" å…³é”®è¯**\n",
    "   - DeepSeek API è¦æ±‚æç¤ºè¯ä¸­åŒ…å« \"json\" è¿™ä¸ªè¯\n",
    "   - å¦åˆ™ä¼šæŠ¥é”™ï¼š`Prompt must contain the word 'json'`\n",
    "\n",
    "2. **æ¨èæ–¹æ¡ˆå¯¹æ¯”**\n",
    "   - æ–¹æ¡ˆ 1 (JsonOutputParser)ï¼šæœ€ç®€æ´ï¼Œæ¨èä½¿ç”¨\n",
    "   - æ–¹æ¡ˆ 2 (with_structured_output)ï¼šéœ€è¦æç¤ºè¯åŒ…å« \"json\"\n",
    "   - æ–¹æ¡ˆ 3 (å¯é€‰æ‰‹åŠ¨ JSON è§£æ)ï¼šæœ€ç¨³å®šï¼Œé€‚åˆå…³é”®åº”ç”¨\n",
    "\n",
    "3. **é…ç½®å»ºè®®**\n",
    "   - è®¾ç½® `temperature=0.0` è·å¾—æ›´ç¨³å®šçš„è¾“å‡º\n",
    "   - æœ€å¥½æä¾›æ¸…æ™°çš„ JSON æ ¼å¼ç¤ºä¾‹\n",
    "\n",
    "4. **å¸¸è§é”™è¯¯**\n",
    "   - æç¤ºè¯ä¸­æ²¡æœ‰ \"json\" å…³é”®è¯\n",
    "   - æ²¡æœ‰è®¾ç½®ä½æ¸©åº¦å‚æ•°\n",
    "   - æ²¡æœ‰æä¾› JSON æ ¼å¼ç¤ºä¾‹\n",
    "   - æ²¡æœ‰å¤„ç†è§£æå¼‚å¸¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae90db1-db46-4568-b0f7-bb7eea0faee5",
   "metadata": {},
   "source": [
    "# <center>ç¬¬å››é˜¶æ®µã€ ç®€å•é—®ç­”æœºå™¨äºº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "370d0020-ee12-485f-b12a-83e8e465a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ è¾“å…¥ exit é€€å‡ºå¯¹è¯\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ ä½ ï¼š ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ï¼Œä½ æ˜¯è°ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– å°æ™ºï¼šä½ å¥½ï¼Œå°æ˜ï¼æˆ‘å«å°æ™ºï¼Œæ˜¯ä½ çš„æ™ºèƒ½åŠ©æ‰‹ã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ ä½ ï¼š æˆ‘æ˜¯è°ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– å°æ™ºï¼šä½ æ˜¯å°æ˜ï¼æˆ‘å¾ˆé«˜å…´èƒ½å’Œä½ äº¤æµã€‚å¦‚æœä½ æƒ³èŠèŠå…³äºä½ è‡ªå·±æˆ–å…¶ä»–è¯é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ ä½ ï¼š exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§© å¯¹è¯ç»“æŸï¼Œå†è§ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# 1ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹ï¼ˆLangChain 1.0 æ¥å£ï¼‰\n",
    "model = load_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    provider=\"openai\",\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰\n",
    "system_message = SystemMessage(\n",
    "    content=\"ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åœ¨å¯¹è¯ä¸­ä¿æŒæ¸©å’Œã€æœ‰è€å¿ƒçš„è¯­æ°”ã€‚\"\n",
    ")\n",
    "\n",
    "# 3ï¸âƒ£ åˆå§‹åŒ–æ¶ˆæ¯å†å²\n",
    "messages = [system_message]\n",
    "\n",
    "print(\"ğŸ”¹ è¾“å…¥ exit é€€å‡ºå¯¹è¯\\n\")\n",
    "\n",
    "# 4ï¸âƒ£ ä¸»å¾ªç¯ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ + æµå¼è¾“å‡ºï¼‰\n",
    "while True:\n",
    "    user_input = input(\"ğŸ‘¤ ä½ ï¼š\")\n",
    "    if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"ğŸ§© å¯¹è¯ç»“æŸï¼Œå†è§ï¼\")\n",
    "        break\n",
    "\n",
    "    # è¿½åŠ ç”¨æˆ·æ¶ˆæ¯\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "\n",
    "    # å®æ—¶è¾“å‡ºæ¨¡å‹ç”Ÿæˆå†…å®¹\n",
    "    print(\"ğŸ¤– å°æ™ºï¼š\", end=\"\", flush=True)\n",
    "    full_reply = \"\"\n",
    "\n",
    "    # âœ… LangChain 1.0 æ ‡å‡†å†™æ³•ï¼šæµå¼è¾“å‡º\n",
    "    for chunk in model.stream(messages):\n",
    "        if chunk.content:\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            full_reply += chunk.content\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 40)  # åˆ†éš”çº¿\n",
    "\n",
    "    # è¿½åŠ  AI å›å¤æ¶ˆæ¯\n",
    "    messages.append(AIMessage(content=full_reply))\n",
    "\n",
    "    # ä¿æŒæ¶ˆæ¯é•¿åº¦ï¼ˆåªä¿ç•™æœ€è¿‘50è½®ï¼‰\n",
    "    messages = messages[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d395db2-b7cc-4473-982e-0f71b14122c4",
   "metadata": {},
   "source": [
    "### gradioç•Œé¢æ­å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d74eba52-33db-4e99-8105-efa3b27f812b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting gradio\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/8d/95/1c25fbcabfa201ab79b016c8716a4ac0f846121d4bbfd2136ffb6d87f31e/gradio-5.49.1-py3-none-any.whl (63.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.5/63.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm0:01\u001b[0mm\n",
      "\u001b[?25hCollecting pydantic<2.12,>=2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bd/1f/73c53fcbfb0b5a78f91176df41945ca466e71e9d9d836e5c522abda39ee7/pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi<1.0,>=0.115.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/eb/23/dfb161e91db7c92727db505dc72a384ee79681fe0603f706f9f9f52c2901/fastapi-0.121.2-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.2/109.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<2.0,>=0.33.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/33/3f/969137c9d9428ed8bf171d27604243dd950a47cac82414826e2aebbc0a4c/huggingface_hub-1.1.4-py3-none-any.whl (515 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m515.6/515.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles<25.0,>=22.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a5/45/30bb92d442636f570cb5651bc661f52b610e2eec3f891a5dc3a4c3667db0/aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bd/75/8539d011f6be8e29f339c42e633aae3cb73bffa95dd0f9adec09b9c58e85/tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Collecting semantic-version~=2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ee/d9/d88e73ca598f4f6ff671fb5fde8a32925c2e08a637303a1d12883c7305fa/uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson~=3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c6/3a/b31c8f0182a3e27f48e703f46e61bb769666cd0dac4700a73912d07a1417/orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m136.4/136.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer<1.0,>=0.12 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (0.20.0)\n",
      "Collecting ffmpy\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/55/56/dd3669eccebb6d8ac81e624542ebd53fe6f08e1b8f2f8d50aeb7e3b83f99/ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/2e/a3/0f0b7d78e2f1eb9e8e1afbff1d2bff8d60144aee17aca51c065b516743dd/safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (4.15.0)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d9/52/1064f510b141bd54025f9b55105e26d1fa970b9be67ad766380a3c9b74b0/starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==1.13.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/6e/0b/337b74504681b5dde39f20d803bb09757f9973ecdc65fd4e819d4b11faf7/gradio_client-1.13.3-py3-none-any.whl (325 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (4.11.0)\n",
      "Collecting groovy~=0.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/28/27/3d6dcadc8a3214d8522c1e7f6a19554e33659be44546d44a2f7572ac7d2a/groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.10/site-packages (from gradio) (24.1)\n",
      "Collecting pydub\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting ruff>=0.9.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ad/ef/41a8b60f8462cb320f68615b00299ebb12660097c952c600c762078420f8/ruff-0.14.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: pillow<12.0,>=8.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (10.3.0)\n",
      "Collecting brotli>=1.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/48/10/f47854a1917b62efe29bc98ac18e5d4f71df03f629184575b862ef2e743b/brotli-1.2.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
      "Collecting python-multipart>=0.0.18\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.10/site-packages (from gradio-client==1.13.3->gradio) (2024.6.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.1)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a3/e0/021c772d6a662f43b63044ab481dc6ac7592447605b5b35a957785363122/starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-doc>=0.0.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1e/d3/26bf1008eb3d2daa8ef4cacc7f3bfdc11818d111f7e2d0201bc6e3b49d45/annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: shellingham in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Collecting typer-slim\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/5e/dd/5cbf31f402f1cc0ab087c94d4669cfa55bd1e818688b910631e131d74e75/typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hf-xet<2.0.0,>=1.2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/9a/92/cf3ab0b652b082e66876d08da57fcc6fa2f0e6c70dfbbafbd470bb73eb47/hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.14.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/31/0d/c8f7593e6bc7066289bbc366f2235701dcbebcd1ff0ef8e64f6f239fb47d/pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich>=10.11.0 in /root/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /root/miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Installing collected packages: pydub, brotli, uvicorn, typer-slim, tomlkit, semantic-version, ruff, python-multipart, pydantic-core, orjson, hf-xet, groovy, ffmpy, annotated-doc, aiofiles, starlette, pydantic, safehttpx, huggingface-hub, fastapi, gradio-client, gradio\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.41.5\n",
      "    Uninstalling pydantic_core-2.41.5:\n",
      "      Successfully uninstalled pydantic_core-2.41.5\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.12.4\n",
      "    Uninstalling pydantic-2.12.4:\n",
      "      Successfully uninstalled pydantic-2.12.4\n",
      "Successfully installed aiofiles-24.1.0 annotated-doc-0.0.4 brotli-1.2.0 fastapi-0.121.2 ffmpy-1.0.0 gradio-5.49.1 gradio-client-1.13.3 groovy-0.1.2 hf-xet-1.2.0 huggingface-hub-1.1.4 orjson-3.11.4 pydantic-2.11.10 pydantic-core-2.33.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.14.5 safehttpx-0.1.7 semantic-version-2.10.0 starlette-0.49.3 tomlkit-0.13.3 typer-slim-0.20.0 uvicorn-0.38.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# å®‰è£… Gradio\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a221dfde-3937-435c-9389-38d9945cbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutoDLä¸­éœ€è¦æ˜ å°„ç«¯å£åï¼Œæ‰èƒ½é€šè¿‡æœ¬åœ°æµè§ˆå™¨è¿›è¡Œè®¿é—®\n",
    "#ssh -L 7860:127.0.0.1:7860 -p 25660 root@connect.westc.gpuhub.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac6526f-600f-4858-82cd-e6908c9b4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ å¯åŠ¨ Gradio åº”ç”¨...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1427/3312104573.py:28: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. åˆå§‹åŒ–æ¨¡å‹ä¸ç³»ç»Ÿè®¾å®š\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\")\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åœ¨å¯¹è¯ä¸­ä¿æŒå‹å¥½ã€æœ‰è€å¿ƒã€æ¸©å’Œçš„è¯­æ°”ã€‚\"\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. å®šä¹‰ Gradio ç•Œé¢\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CSS = \"\"\"\n",
    ".main-container {max-width: 1200px; margin: 0 auto; padding: 20px;}\n",
    ".header-text {text-align: center; margin-bottom: 20px;}\n",
    "\"\"\"\n",
    "\n",
    "def create_chatbot() -> gr.Blocks:\n",
    "    with gr.Blocks(title=\"DeepSeek Chat\", css=CSS) as demo:\n",
    "        with gr.Column(elem_classes=[\"main-container\"]):\n",
    "            gr.Markdown(\"# ğŸ¤– LangChain 1.0 Ã— DeepSeek Chatbot\", elem_classes=[\"header-text\"])\n",
    "            gr.Markdown(\"åŸºäº LangChain 1.0 æ ‡å‡†æ¥å£çš„æµå¼å¯¹è¯æœºå™¨äºº\", elem_classes=[\"header-text\"])\n",
    "\n",
    "            chatbot = gr.Chatbot(\n",
    "                height=500,\n",
    "                show_copy_button=True,\n",
    "                avatar_images=(\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f464.png\",\n",
    "                    \"https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f916.png\",\n",
    "                ),\n",
    "            )\n",
    "            msg = gr.Textbox(placeholder=\"è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...\", container=False, scale=7)\n",
    "            submit = gr.Button(\"å‘é€\", scale=1, variant=\"primary\")\n",
    "            clear = gr.Button(\"æ¸…ç©º\", scale=1)\n",
    "\n",
    "        # çŠ¶æ€ï¼šä¿å­˜æ¶ˆæ¯å†å²ï¼ˆLangChain Message å¯¹è±¡ï¼‰\n",
    "        state = gr.State([])\n",
    "\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»å“åº”å‡½æ•°ï¼ˆæµå¼è¾“å‡ºï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        def respond(user_msg: str, chat_hist: list, messages_list: list):\n",
    "\n",
    "            # 1ï¸âƒ£ è¾“å…¥ä¸ºç©ºåˆ™ç›´æ¥è¿”å›\n",
    "            if not user_msg.strip():\n",
    "                yield \"\", chat_hist, messages_list\n",
    "                return\n",
    "\n",
    "            # 2ï¸âƒ£ æ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç³»ç»Ÿæç¤ºï¼‰\n",
    "            if not messages_list:\n",
    "                messages_list = [system_message]\n",
    "\n",
    "            messages_list.append(HumanMessage(content=user_msg))\n",
    "\n",
    "            # 3ï¸âƒ£ æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²\n",
    "            chat_hist = chat_hist + [(user_msg, \"\")]\n",
    "\n",
    "            # 4ï¸âƒ£ æµå¼ç”Ÿæˆæ¨¡å‹å›å¤\n",
    "            partial = \"\"\n",
    "            for chunk in model.stream(messages_list):\n",
    "                if chunk.content:\n",
    "                    partial += chunk.content\n",
    "                    # æ¯æ¬¡æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯\n",
    "                    chat_hist[-1] = (user_msg, partial)\n",
    "                    # ç«‹å³ yieldï¼Œè®© UI å®æ—¶æ›´æ–°\n",
    "                    # è¿”å›ç©ºå­—ç¬¦ä¸²ç»™ msgï¼Œæ¸…ç©ºè¾“å…¥æ¡†\n",
    "                    yield \"\", chat_hist, messages_list\n",
    "\n",
    "            # 5ï¸âƒ£ ä¿å­˜å®Œæ•´ AI å›å¤å¹¶æˆªæ–­å†å²ï¼ˆä¿ç•™50è½®ï¼‰\n",
    "            messages_list.append(AIMessage(content=partial))\n",
    "            messages_list = messages_list[-50:]\n",
    "\n",
    "            # 6ï¸âƒ£ æœ€åä¸€æ¬¡ yield ç¡®ä¿çŠ¶æ€åŒæ­¥\n",
    "            yield \"\", chat_hist, messages_list\n",
    "\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¸…ç©ºå¯¹è¯å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        def clear_history():\n",
    "            return \"\", [], []\n",
    "\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gradio äº‹ä»¶ç»‘å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # è¿”å› msgã€chatbot å’Œ state\n",
    "        # msg è¿”å›ç©ºå­—ç¬¦ä¸²æ¥æ¸…ç©ºè¾“å…¥æ¡†\n",
    "        msg.submit(respond, [msg, chatbot, state], [msg, chatbot, state])\n",
    "        submit.click(respond, [msg, chatbot, state], [msg, chatbot, state])\n",
    "        clear.click(clear_history, outputs=[msg, chatbot, state])\n",
    "\n",
    "    return demo\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. å¯åŠ¨ Gradio åº”ç”¨\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"\\nğŸš€ å¯åŠ¨ Gradio åº”ç”¨...\")\n",
    "demo = create_chatbot()\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=False, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00788d3c-719d-4657-8d11-bc7937f48f3a",
   "metadata": {},
   "source": [
    "## <center>æ€»ç»“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8200e-ec80-4ef5-a792-b3f5c1d804f0",
   "metadata": {},
   "source": [
    "LangChain åœ¨ 1.0 ç‰ˆæœ¬å®Œæˆäº†ä¸€æ¬¡çœŸæ­£æ„ä¹‰ä¸Šçš„â€œå·¥ç¨‹åŒ–é‡å¡‘â€ã€‚1.0 é€šè¿‡ç»Ÿä¸€æŠ½è±¡ã€ç®€åŒ–æ¥å£ã€å¼ºåŒ–ç”Ÿæ€ä¸æ‰©å±•æ€§ï¼Œä½¿å…¶æ­£å¼è¿›å…¥ å¯ç”¨äºä¼ä¸šç”Ÿäº§çº§å¤§æ¨¡å‹åº”ç”¨å¼€å‘ çš„é˜¶æ®µã€‚é€šè¿‡ç»Ÿä¸€ Runnable æŠ½è±¡ã€æ ‡å‡†åŒ–æ¨¡å‹æ¥å£ã€å¼ºåŒ–ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›ã€å®Œå–„äº‹ä»¶ä¸å›è°ƒä½“ç³»ï¼Œä»¥åŠä¸ LangSmith/LangGraph çš„æ·±åº¦èåˆï¼ŒLangChain å·²å»ºç«‹å®Œæ•´çš„ AI åº”ç”¨å…¨æ ˆç”Ÿæ€ï¼ˆæ¨¡å‹è°ƒç”¨ã€æ•°æ®å¤„ç†ã€RAGã€Agentã€å·¥ä½œæµã€ç›‘æ§è¯„ä¼°ï¼‰ã€‚å¦‚æœä½ éœ€è¦æ„å»ºé«˜å¯é ã€å¯è§‚æµ‹ã€ç»“æ„åŒ–è¾“å‡ºã€æ”¯æŒæœ¬åœ°æ¨¡å‹ã€å¯æ‰©å±•çš„ AI åº”ç”¨â€”â€”LangChain 1.0 æ˜¯å½“ä¸‹æœ€æˆç†Ÿã€æœ€å·¥ç¨‹åŒ–çš„é€‰æ‹©ä¹‹ä¸€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d30c2f-20b8-424b-b640-e8b304687d0a",
   "metadata": {},
   "source": [
    "* LangChain å®˜æ–¹åœ°å€ï¼šhttps://docs.langchain.com/\n",
    "\n",
    "* LangChain ä¸­æ–‡ç‰ˆ TypeScriptç‰ˆæœ¬ï¼šhttps://docs.langchain.org.cn/oss/javascript/langchain/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c337387-7ca8-4e76-ad2e-9188a9fdf0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain]",
   "language": "python",
   "name": "conda-env-langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
